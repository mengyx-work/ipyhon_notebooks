{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "sys.path.append('/home/ymm/kaggle/xgboost_hyperopt')\n",
    "import utils.bosch_functions as bosch_functions\n",
    "from utils.wrapped_xgboost import xgboost_classifier\n",
    "from utils.validation_tools import score_MCC, MCC, create_validation_index\n",
    "from utils.models import CombinedModel\n",
    "from utils.data_munge import remove_single_value_columns\n",
    "from utils.feature_engineering import NumericalFeatureEngineering, getRelativeTimeColumns, BasicDate_FeatureEngineering\n",
    "from utils.feature_engineering import getTimeChangeColumns, getTimeSteps, build_IndexFeatures\n",
    "\n",
    "data_path = '/home/ymm/bosch/'\n",
    "\n",
    "train_num_file   = 'train_numeric.csv'\n",
    "train_cat_file   = 'train_categorical.csv'\n",
    "train_date_file  = 'train_date.csv'\n",
    "test_num_file    = 'test_numeric.csv'\n",
    "test_cat_file    = 'test_categorical.csv'\n",
    "test_date_file   = 'test_date.csv'\n",
    "\n",
    "sample_submission_file   = 'sample_submission.csv'\n",
    "\n",
    "start_time_column_name = 'L0_S0_D1'\n",
    "id_column_name = 'Id'\n",
    "dep_var_name = 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading date using 164.0 seconds\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "num_rows = 150000\n",
    "start_time = time.time()\n",
    "## loading the data by using the skipped_row_num list\n",
    "train_num = pd.read_csv(join(data_path, train_num_file),    index_col='Id', nrows=num_rows)\n",
    "train_dat = pd.read_csv(join(data_path, train_date_file),   index_col='Id', nrows=num_rows)\n",
    "train_cat = pd.read_csv(join(data_path, train_cat_file),    index_col='Id', nrows=num_rows)\n",
    "test_num = pd.read_csv(join(data_path, test_num_file),      index_col='Id', nrows=num_rows)\n",
    "test_dat = pd.read_csv(join(data_path, test_date_file),     index_col='Id', nrows=num_rows)\n",
    "test_cat = pd.read_csv(join(data_path, test_cat_file),      index_col='Id', nrows=num_rows)\n",
    "\n",
    "print 'finish loading date using {} seconds'.format(round(time.time() - start_time, 0))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbin_num = 1 ## number of bins to separate data by start_time\\ntmp_train, tmp_test, bins, bin_names = bosch_functions.create_grouped_index_df(bin_num)\\n#none_selected_window_num = ['0']\\nnone_selected_window_num = [np.NaN]\\nskipped_test_row_num = tmp_test.loc[tmp_test['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\\nskipped_train_row_num = tmp_train.loc[tmp_train['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\\n\\n\\nnum_rows = 50000\\nstart_time = time.time()\\n## loading the data by using the skipped_row_num list\\ntrain_num = pd.read_csv(join(data_path, train_num_file),    index_col='Id',  skiprows=skipped_train_row_num, nrows=num_rows)\\ntrain_dat = pd.read_csv(join(data_path, train_date_file),   index_col='Id',  skiprows=skipped_train_row_num, nrows=num_rows)\\ntest_num = pd.read_csv(join(data_path, test_num_file),      index_col='Id',  skiprows=skipped_test_row_num,  nrows=num_rows)\\ntest_dat = pd.read_csv(join(data_path, test_date_file),     index_col='Id',  skiprows=skipped_test_row_num,  nrows=num_rows)\\n\\nprint 'finish loading date using {} seconds'.format(round(time.time() - start_time, 0))\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "bin_num = 1 ## number of bins to separate data by start_time\n",
    "tmp_train, tmp_test, bins, bin_names = bosch_functions.create_grouped_index_df(bin_num)\n",
    "#none_selected_window_num = ['0']\n",
    "none_selected_window_num = [np.NaN]\n",
    "skipped_test_row_num = tmp_test.loc[tmp_test['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\n",
    "skipped_train_row_num = tmp_train.loc[tmp_train['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\n",
    "\n",
    "\n",
    "num_rows = 50000\n",
    "start_time = time.time()\n",
    "## loading the data by using the skipped_row_num list\n",
    "train_num = pd.read_csv(join(data_path, train_num_file),    index_col='Id',  skiprows=skipped_train_row_num, nrows=num_rows)\n",
    "train_dat = pd.read_csv(join(data_path, train_date_file),   index_col='Id',  skiprows=skipped_train_row_num, nrows=num_rows)\n",
    "test_num = pd.read_csv(join(data_path, test_num_file),      index_col='Id',  skiprows=skipped_test_row_num,  nrows=num_rows)\n",
    "test_dat = pd.read_csv(join(data_path, test_date_file),     index_col='Id',  skiprows=skipped_test_row_num,  nrows=num_rows)\n",
    "\n",
    "print 'finish loading date using {} seconds'.format(round(time.time() - start_time, 0))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (150000, 969)\n",
      "raw test data dimension:  (150000, 968)\n",
      "processed train data dimension:  (150000, 969)\n",
      "processed test data dimension:  (150000, 968)\n",
      "raw train data dimension:  (150000, 1156)\n",
      "raw test data dimension:  (150000, 1156)\n",
      "processed train data dimension:  (150000, 1150)\n",
      "processed test data dimension:  (150000, 1150)\n",
      "raw train data dimension:  (150000, 2140)\n",
      "raw test data dimension:  (150000, 2140)\n",
      "processed train data dimension:  (150000, 1294)\n",
      "processed test data dimension:  (150000, 1294)\n"
     ]
    }
   ],
   "source": [
    "remove_single_value_columns(train_num, 'Response', test=test_num)\n",
    "remove_single_value_columns(train_dat, test=test_dat)\n",
    "remove_single_value_columns(train_cat, test=test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_columns = train_dat.columns.tolist()\n",
    "num_columns = train_num.columns.tolist()\n",
    "num_columns.remove(dep_var_name)\n",
    "\n",
    "def build_column_dict(columns):\n",
    "    col_dict = {}\n",
    "    for col in columns:\n",
    "        tmpList = col.split('_')[0:2]\n",
    "        key = ('_').join(tmpList)\n",
    "        if key not in col_dict:\n",
    "            col_dict[key] = [col]\n",
    "        else:\n",
    "            col_dict[key].append(col)\n",
    "            \n",
    "    return col_dict\n",
    "\n",
    "\n",
    "def build_station_features(df, col_dict, prefix='dat'):\n",
    "    features = pd.DataFrame()\n",
    "    for key, value in col_dict.items():\n",
    "        features['{}_{}_{}'.format(prefix, key, 'mean')] = df[value].mean(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'max')] = df[value].max(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'min')] = df[value].min(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'var')] = df[value].var(axis=1)\n",
    "    return features\n",
    "    \n",
    "    \n",
    "dat_col_dict = build_column_dict(dat_columns)\n",
    "num_col_dict = build_column_dict(num_columns)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date station using 0.89 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_dat_stations = build_station_features(train_dat, dat_col_dict, 'dat')\n",
    "test_dat_stations = build_station_features(test_dat, dat_col_dict, 'dat')\n",
    "\n",
    "train_num_stations = build_station_features(train_num, num_col_dict, 'num')\n",
    "test_num_stations = build_station_features(test_num, num_col_dict, 'num')\n",
    "\n",
    "print 'finish feature engineering date station using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BasicCat_FeatureEngineering(train_cat):\n",
    "    ## feature engineering on the date features\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    column_names = train_cat.columns.tolist()\n",
    "    column_names.append('NaN')\n",
    "    encoder.fit(column_names)\n",
    "    dat_new_fea = pd.DataFrame()\n",
    "    dat_new_fea['cat_sum'] = train_cat.sum(axis=1)\n",
    "    dat_new_fea['cat_mean'] = train_cat.mean(axis=1)\n",
    "    dat_new_fea['cat_nan_count'] = train_cat.isnull().sum(axis=1)\n",
    "    dat_new_fea['cat_max'] = train_cat.max(axis=1)\n",
    "    dat_new_fea['cat_min'] = train_cat.min(axis=1)\n",
    "    dat_new_fea['cat_max_min_diff'] = dat_new_fea['cat_max'] - dat_new_fea['cat_min']\n",
    "    dat_new_fea['cat_max_min_ratio'] = dat_new_fea['cat_min'] / dat_new_fea['cat_max']\n",
    "\n",
    "    dat_new_fea['cat_idxmax'] = train_cat.idxmax(axis=1)\n",
    "    dat_new_fea['cat_idxmax'].fillna('NaN', inplace=True)\n",
    "    dat_new_fea['cat_idxmax'] = encoder.transform(dat_new_fea['cat_idxmax'])\n",
    "    dat_new_fea['cat_idxmin'] = train_cat.idxmin(axis=1)\n",
    "    dat_new_fea['cat_idxmin'].fillna('NaN', inplace=True)\n",
    "    dat_new_fea['cat_idxmin'] = encoder.transform(dat_new_fea['cat_idxmin'])\n",
    "    return dat_new_fea\n",
    "\n",
    "\n",
    "\n",
    "def encode_categorical_by_dep_var(train, test, dep_var_column='Response'):\n",
    "    for col_name in train.columns:\n",
    "        if col_name == dep_var_column:\n",
    "            continue\n",
    "        dep_var_mean = train[[col_name, dep_var_column]].groupby(col_name).mean()\n",
    "    \n",
    "        dep_var_dict = {}\n",
    "        for level in dep_var_mean.index.tolist():\n",
    "            dep_var_dict[level] = dep_var_mean.ix[level, dep_var_column]\n",
    "    \n",
    "        train[col_name] = train[col_name].replace(dep_var_dict)  \n",
    "        test[col_name] = test[col_name].replace(dep_var_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating categorical features using 68.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_cat['Response'] = train_num['Response']\n",
    "encode_categorical_by_dep_var(train_cat, test_cat)\n",
    "train_cat.drop('Response', axis=1, inplace=True)\n",
    "\n",
    "train_cat_Basics = BasicCat_FeatureEngineering(train_cat)\n",
    "test_cat_Basics  = BasicCat_FeatureEngineering(train_cat)\n",
    "\n",
    "print 'finish generating categorical features using {} seconds'.format(round(time.time() - start_time, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 1294) (150000, 1294)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "Id                                                                     \n",
       "4         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "6         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "7         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "9         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "11        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "    L0_S2_F37  L0_S2_F39  L0_S2_F41  L0_S2_F43      ...       L3_S49_F4225  \\\n",
       "Id                                                  ...                      \n",
       "4         NaN        NaN        NaN        NaN      ...                NaN   \n",
       "6         NaN        NaN        NaN        NaN      ...                NaN   \n",
       "7         NaN        NaN        NaN        NaN      ...                NaN   \n",
       "9         NaN        NaN        NaN        NaN      ...                NaN   \n",
       "11        NaN        NaN        NaN        NaN      ...                NaN   \n",
       "\n",
       "    L3_S49_F4227  L3_S49_F4229  L3_S49_F4230  L3_S49_F4232  L3_S49_F4234  \\\n",
       "Id                                                                         \n",
       "4            NaN           NaN           NaN           NaN           NaN   \n",
       "6            NaN           NaN           NaN           NaN           NaN   \n",
       "7            NaN           NaN           NaN           NaN           NaN   \n",
       "9            NaN           NaN           NaN           NaN           NaN   \n",
       "11           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "    L3_S49_F4235  L3_S49_F4237  L3_S49_F4239  L3_S49_F4240  \n",
       "Id                                                          \n",
       "4            NaN           NaN           NaN           NaN  \n",
       "6            NaN           NaN           NaN           NaN  \n",
       "7            NaN           NaN           NaN           NaN  \n",
       "9            NaN           NaN           NaN           NaN  \n",
       "11           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 1294 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_cat.shape, test_cat.shape\n",
    "train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date using 3.3 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_train_cat = pd.concat([train_cat, train_cat_Basics], axis=1)\n",
    "combined_test_cat  = pd.concat([test_cat, test_cat_Basics], axis=1)                                                                                                                                                 \n",
    "print 'finish feature engineering date using {} seconds'.format(round((time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined train numerical feature shape: (150000, 978), combined test numerical features shape: (150000, 977)\n"
     ]
    }
   ],
   "source": [
    "#### numerical feature engineering work\n",
    "train_num_Basics = NumericalFeatureEngineering(train_num)\n",
    "test_num_Basics = NumericalFeatureEngineering(test_num)\n",
    "\n",
    "combined_train_num = pd.concat([train_num, train_num_Basics], axis=1)\n",
    "combined_test_num  = pd.concat([test_num, test_num_Basics], axis=1)                                                                            \n",
    "print 'combined train numerical feature shape: {}, combined test numerical features shape: {}'.format(combined_train_num.shape, combined_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### section of date features\n",
    "\n",
    "## basic features from tmp_train_dat\n",
    "train_dat_Basics = BasicDate_FeatureEngineering(train_dat)\n",
    "test_dat_Basics  = BasicDate_FeatureEngineering(test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (150000, 1150)\n",
      "raw test data dimension:  (150000, 1150)\n",
      "processed train data dimension:  (150000, 1067)\n",
      "processed test data dimension:  (150000, 1067)\n"
     ]
    }
   ],
   "source": [
    "## normalized date columns\n",
    "train_dat_Norm = train_dat.apply(getRelativeTimeColumns, axis=1)\n",
    "test_dat_Norm  = test_dat.apply(getRelativeTimeColumns, axis=1)\n",
    "## remove single-valued columns\n",
    "remove_single_value_columns(train_dat_Norm, test=test_dat_Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "column_names = train_dat.columns.tolist()\n",
    "column_names.append('NaN')\n",
    "encoder.fit(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TimeDiff features\n",
    "train_dat_TimeDiff = train_dat.apply(getTimeChangeColumns, axis=1)\n",
    "test_dat_TimeDiff  = test_dat.apply(getTimeChangeColumns, axis=1)\n",
    "TimeDiff_ColumnNames = ['time_diff_start_col', 'time_diff_end_col', 'time_diff_value',\n",
    "                        'time_ratio_value', 'first_time_value', 'last_time_value', 'first_date_value']\n",
    "train_dat_TimeDiff.columns = TimeDiff_ColumnNames\n",
    "test_dat_TimeDiff.columns = TimeDiff_ColumnNames\n",
    "\n",
    "for column in ['time_diff_start_col', 'time_diff_end_col']:\n",
    "    train_dat_TimeDiff[column].fillna('NaN', inplace=True)\n",
    "    train_dat_TimeDiff[column] = encoder.transform(train_dat_TimeDiff[column])\n",
    "    \n",
    "    test_dat_TimeDiff[column].fillna('NaN', inplace=True)\n",
    "    test_dat_TimeDiff[column] = encoder.transform(test_dat_TimeDiff[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating TimeStep features using 860.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## section to create timeStep features\n",
    "\n",
    "unique_value_counts = 6\n",
    "timeStep_columnNames = []\n",
    "column_name_columns = []\n",
    "for i in xrange(unique_value_counts):\n",
    "    timeStep_columnNames.extend(['time_diff_step_{}'.format(i), 'column_counts_step_{}'.format(i),\n",
    "                                 'time_cost_step_{}'.format(i), 'first_column_step_{}'.format(i)])\n",
    "    column_name_columns.append('first_column_step_{}'.format(i))\n",
    "\n",
    "train_dat_TimeStep = train_dat_Norm.apply(getTimeSteps, axis=1)\n",
    "test_dat_TimeStep  = test_dat_Norm.apply(getTimeSteps, axis=1)\n",
    "train_dat_TimeStep.columns = timeStep_columnNames\n",
    "test_dat_TimeStep.columns  = timeStep_columnNames\n",
    "\n",
    "for column in column_name_columns:\n",
    "    train_dat_TimeStep[column].fillna('NaN', inplace=True)\n",
    "    test_dat_TimeStep[column].fillna('NaN', inplace=True)\n",
    "    train_dat_TimeStep[column] = encoder.transform(train_dat_TimeStep[column])\n",
    "    test_dat_TimeStep[column] = encoder.transform(test_dat_TimeStep[column])\n",
    "\n",
    "\n",
    "print 'finish generating TimeStep features using {} seconds'.format(round(time.time() - start_time, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date using 0.03 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_train_dat = pd.concat([train_dat_Norm, train_dat_Basics, train_dat_TimeDiff, train_dat_TimeStep], axis=1)\n",
    "combined_test_dat  = pd.concat([test_dat_Norm, test_dat_Basics, test_dat_TimeDiff, test_dat_TimeStep], axis=1)                                                                                                                                                 \n",
    "print 'finish feature engineering date using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 1108) (150000, 1108)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>L0_S0_D19</th>\n",
       "      <th>...</th>\n",
       "      <th>time_cost_step_3</th>\n",
       "      <th>first_column_step_3</th>\n",
       "      <th>time_diff_step_4</th>\n",
       "      <th>column_counts_step_4</th>\n",
       "      <th>time_cost_step_4</th>\n",
       "      <th>first_column_step_4</th>\n",
       "      <th>time_diff_step_5</th>\n",
       "      <th>column_counts_step_5</th>\n",
       "      <th>time_cost_step_5</th>\n",
       "      <th>first_column_step_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.257500</td>\n",
       "      <td>1013</td>\n",
       "      <td>5.04</td>\n",
       "      <td>15</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>1018</td>\n",
       "      <td>5.05</td>\n",
       "      <td>14</td>\n",
       "      <td>0.360714</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>945</td>\n",
       "      <td>5.72</td>\n",
       "      <td>29</td>\n",
       "      <td>0.197241</td>\n",
       "      <td>1018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072500</td>\n",
       "      <td>945</td>\n",
       "      <td>4.94</td>\n",
       "      <td>10</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>1018</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>1018</td>\n",
       "      <td>3.38</td>\n",
       "      <td>14</td>\n",
       "      <td>0.241429</td>\n",
       "      <td>1041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  L0_S0_D13  \\\n",
       "Id                                                                           \n",
       "4        0.0       0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "6        NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "7        0.0       0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "9        0.0       0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "11       0.0       0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "\n",
       "    L0_S0_D15  L0_S0_D17  L0_S0_D19         ...           time_cost_step_3  \\\n",
       "Id                                          ...                              \n",
       "4         0.0        0.0        0.0         ...                   1.257500   \n",
       "6         NaN        NaN        NaN         ...                   0.000000   \n",
       "7         0.0        0.0        0.0         ...                   0.083971   \n",
       "9         0.0        0.0        0.0         ...                   0.072500   \n",
       "11        0.0        0.0        0.0         ...                   0.224667   \n",
       "\n",
       "    first_column_step_3  time_diff_step_4  column_counts_step_4  \\\n",
       "Id                                                                \n",
       "4                  1013              5.04                    15   \n",
       "6                  1150               NaN                     0   \n",
       "7                   945              5.72                    29   \n",
       "9                   945              4.94                    10   \n",
       "11                 1018              3.38                    14   \n",
       "\n",
       "    time_cost_step_4  first_column_step_4  time_diff_step_5  \\\n",
       "Id                                                            \n",
       "4           0.336000                 1018              5.05   \n",
       "6           0.000000                 1150               NaN   \n",
       "7           0.197241                 1018               NaN   \n",
       "9           0.494000                 1018              4.95   \n",
       "11          0.241429                 1041               NaN   \n",
       "\n",
       "    column_counts_step_5  time_cost_step_5  first_column_step_5  \n",
       "Id                                                               \n",
       "4                     14          0.360714                 1033  \n",
       "6                      0          0.000000                 1150  \n",
       "7                      0          0.000000                 1150  \n",
       "9                      5          0.990000                 1028  \n",
       "11                     0          0.000000                 1150  \n",
       "\n",
       "[5 rows x 1108 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print combined_train_dat.shape, combined_test_dat.shape\n",
    "combined_train_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_datIndex_features = build_IndexFeatures(combined_train_dat, combined_test_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine all the features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combined_train = pd.concat([train_dat_stations, train_num_stations, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([test_dat_stations, test_num_stations, combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combined_train = pd.concat([combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## combined data with categorical features\n",
    "#combined_train = pd.concat([combined_train_cat, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([combined_test_cat,  combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## combined data with categorical features\n",
    "combined_train = pd.concat([train_dat_stations, combined_train_cat, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "combined_test  = pd.concat([test_dat_stations, combined_test_cat,  combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 3411)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <th>...</th>\n",
       "      <th>first_date_value_index_ratio_1</th>\n",
       "      <th>first_date_value_index_ratio_2</th>\n",
       "      <th>time_ratio_value_index_diff_0</th>\n",
       "      <th>time_ratio_value_index_diff_1</th>\n",
       "      <th>first_time_value_index_diff_0</th>\n",
       "      <th>first_time_value_index_diff_1</th>\n",
       "      <th>last_time_value_index_diff_0</th>\n",
       "      <th>last_time_value_index_diff_1</th>\n",
       "      <th>first_date_value_index_diff_0</th>\n",
       "      <th>first_date_value_index_diff_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>165388.000000</td>\n",
       "      <td>154442.000000</td>\n",
       "      <td>-178143.0</td>\n",
       "      <td>-3232.0</td>\n",
       "      <td>-297775.0</td>\n",
       "      <td>-3232.0</td>\n",
       "      <td>-138624.0</td>\n",
       "      <td>-3232.0</td>\n",
       "      <td>-64614.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>79723.500000</td>\n",
       "      <td>93350.500000</td>\n",
       "      <td>-208741.0</td>\n",
       "      <td>-62612.0</td>\n",
       "      <td>-274602.0</td>\n",
       "      <td>-5943.0</td>\n",
       "      <td>-274602.0</td>\n",
       "      <td>-61348.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13435.333333</td>\n",
       "      <td>68460.666667</td>\n",
       "      <td>-283350.0</td>\n",
       "      <td>-24124.0</td>\n",
       "      <td>-290694.0</td>\n",
       "      <td>-17769.0</td>\n",
       "      <td>-255142.0</td>\n",
       "      <td>-20967.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8061.000000</td>\n",
       "      <td>6311.800000</td>\n",
       "      <td>-254439.0</td>\n",
       "      <td>-140294.0</td>\n",
       "      <td>-296594.0</td>\n",
       "      <td>-130413.0</td>\n",
       "      <td>-299030.0</td>\n",
       "      <td>-4697.0</td>\n",
       "      <td>-296594.0</td>\n",
       "      <td>-33948.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "Id                                                                     \n",
       "1         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "2         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "3         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "5         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "    L0_S2_F37  L0_S2_F39  L0_S2_F41  L0_S2_F43              ...                \\\n",
       "Id                                                          ...                 \n",
       "1         NaN        NaN        NaN        NaN              ...                 \n",
       "2         NaN        NaN        NaN        NaN              ...                 \n",
       "3         NaN        NaN        NaN        NaN              ...                 \n",
       "4         NaN        NaN        NaN        NaN              ...                 \n",
       "5         NaN        NaN        NaN        NaN              ...                 \n",
       "\n",
       "    first_date_value_index_ratio_1  first_date_value_index_ratio_2  \\\n",
       "Id                                                                   \n",
       "1                    165388.000000                   154442.000000   \n",
       "2                     79723.500000                    93350.500000   \n",
       "3                     13435.333333                    68460.666667   \n",
       "4                              NaN                             NaN   \n",
       "5                      8061.000000                     6311.800000   \n",
       "\n",
       "    time_ratio_value_index_diff_0  time_ratio_value_index_diff_1  \\\n",
       "Id                                                                 \n",
       "1                       -178143.0                        -3232.0   \n",
       "2                       -208741.0                       -62612.0   \n",
       "3                       -283350.0                       -24124.0   \n",
       "4                             NaN                            NaN   \n",
       "5                       -254439.0                      -140294.0   \n",
       "\n",
       "    first_time_value_index_diff_0  first_time_value_index_diff_1  \\\n",
       "Id                                                                 \n",
       "1                       -297775.0                        -3232.0   \n",
       "2                       -274602.0                        -5943.0   \n",
       "3                       -290694.0                       -17769.0   \n",
       "4                             NaN                            NaN   \n",
       "5                       -296594.0                      -130413.0   \n",
       "\n",
       "    last_time_value_index_diff_0  last_time_value_index_diff_1  \\\n",
       "Id                                                               \n",
       "1                      -138624.0                       -3232.0   \n",
       "2                      -274602.0                      -61348.0   \n",
       "3                      -255142.0                      -20967.0   \n",
       "4                            NaN                           NaN   \n",
       "5                      -299030.0                       -4697.0   \n",
       "\n",
       "    first_date_value_index_diff_0  first_date_value_index_diff_1  \n",
       "Id                                                                \n",
       "1                        -64614.0                           -1.0  \n",
       "2                             1.0                           -1.0  \n",
       "3                             1.0                           -3.0  \n",
       "4                             NaN                            NaN  \n",
       "5                       -296594.0                       -33948.0  \n",
       "\n",
       "[5 rows x 3411 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print combined_test.shape\n",
    "combined_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 3412)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <th>...</th>\n",
       "      <th>first_date_value_index_ratio_1</th>\n",
       "      <th>first_date_value_index_ratio_2</th>\n",
       "      <th>time_ratio_value_index_diff_0</th>\n",
       "      <th>time_ratio_value_index_diff_1</th>\n",
       "      <th>first_time_value_index_diff_0</th>\n",
       "      <th>first_time_value_index_diff_1</th>\n",
       "      <th>last_time_value_index_diff_0</th>\n",
       "      <th>last_time_value_index_diff_1</th>\n",
       "      <th>first_date_value_index_diff_0</th>\n",
       "      <th>first_date_value_index_diff_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>66236.500000</td>\n",
       "      <td>70779.000000</td>\n",
       "      <td>-249490</td>\n",
       "      <td>-232358</td>\n",
       "      <td>-270686</td>\n",
       "      <td>-47255</td>\n",
       "      <td>-290018</td>\n",
       "      <td>-3482</td>\n",
       "      <td>-298351</td>\n",
       "      <td>-224451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45512.000000</td>\n",
       "      <td>46202.666667</td>\n",
       "      <td>-174409</td>\n",
       "      <td>-79568</td>\n",
       "      <td>-299900</td>\n",
       "      <td>-67530</td>\n",
       "      <td>-244431</td>\n",
       "      <td>-58861</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39010.428571</td>\n",
       "      <td>40557.857143</td>\n",
       "      <td>-284206</td>\n",
       "      <td>-38624</td>\n",
       "      <td>-242935</td>\n",
       "      <td>-26876</td>\n",
       "      <td>-211070</td>\n",
       "      <td>-13283</td>\n",
       "      <td>-242935</td>\n",
       "      <td>-26876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13113.000000</td>\n",
       "      <td>13969.333333</td>\n",
       "      <td>-299775</td>\n",
       "      <td>-3564</td>\n",
       "      <td>-297979</td>\n",
       "      <td>-3564</td>\n",
       "      <td>-297979</td>\n",
       "      <td>-3564</td>\n",
       "      <td>-297979</td>\n",
       "      <td>-3564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10598.181818</td>\n",
       "      <td>12043.727273</td>\n",
       "      <td>-61721</td>\n",
       "      <td>-13963</td>\n",
       "      <td>-111468</td>\n",
       "      <td>-1</td>\n",
       "      <td>-62044</td>\n",
       "      <td>-13963</td>\n",
       "      <td>-111468</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3412 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "Id                                                                     \n",
       "4         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "6         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "7         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "9         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "11        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "    L0_S2_F37  L0_S2_F39  L0_S2_F41  L0_S2_F43              ...                \\\n",
       "Id                                                          ...                 \n",
       "4         NaN        NaN        NaN        NaN              ...                 \n",
       "6         NaN        NaN        NaN        NaN              ...                 \n",
       "7         NaN        NaN        NaN        NaN              ...                 \n",
       "9         NaN        NaN        NaN        NaN              ...                 \n",
       "11        NaN        NaN        NaN        NaN              ...                 \n",
       "\n",
       "    first_date_value_index_ratio_1  first_date_value_index_ratio_2  \\\n",
       "Id                                                                   \n",
       "4                     66236.500000                    70779.000000   \n",
       "6                     45512.000000                    46202.666667   \n",
       "7                     39010.428571                    40557.857143   \n",
       "9                     13113.000000                    13969.333333   \n",
       "11                    10598.181818                    12043.727273   \n",
       "\n",
       "    time_ratio_value_index_diff_0  time_ratio_value_index_diff_1  \\\n",
       "Id                                                                 \n",
       "4                         -249490                        -232358   \n",
       "6                         -174409                         -79568   \n",
       "7                         -284206                         -38624   \n",
       "9                         -299775                          -3564   \n",
       "11                         -61721                         -13963   \n",
       "\n",
       "    first_time_value_index_diff_0  first_time_value_index_diff_1  \\\n",
       "Id                                                                 \n",
       "4                         -270686                         -47255   \n",
       "6                         -299900                         -67530   \n",
       "7                         -242935                         -26876   \n",
       "9                         -297979                          -3564   \n",
       "11                        -111468                             -1   \n",
       "\n",
       "    last_time_value_index_diff_0  last_time_value_index_diff_1  \\\n",
       "Id                                                               \n",
       "4                        -290018                         -3482   \n",
       "6                        -244431                        -58861   \n",
       "7                        -211070                        -13283   \n",
       "9                        -297979                         -3564   \n",
       "11                        -62044                        -13963   \n",
       "\n",
       "    first_date_value_index_diff_0  first_date_value_index_diff_1  \n",
       "Id                                                                \n",
       "4                         -298351                        -224451  \n",
       "6                               3                             -2  \n",
       "7                         -242935                         -26876  \n",
       "9                         -297979                          -3564  \n",
       "11                        -111468                             -1  \n",
       "\n",
       "[5 rows x 3412 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print combined_train.shape\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"eta\"]                      = 0.0075\n",
    "params[\"subsample\"]                = 0.8\n",
    "params[\"colsample_bytree\"]         = 0.8\n",
    "params[\"num_round\"]                = 501\n",
    "params[\"max_depth\"]                = 5\n",
    "params[\"gamma\"]                    = 0\n",
    "params[\"metrics\"]                  = 'auc'\n",
    "params['eval_metric']              = 'auc'\n",
    "params[\"seed\"]                     = 999\n",
    "params['verbose_eval']             = 50\n",
    "## whether to use weights\n",
    "params['use_base_score']           = True\n",
    "params['use_weights']              = True\n",
    "#params['use_scale_pos_weight']     = True\n",
    "params[\"val\"]                      = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 178.854316547\n",
      "a base_score 0.00556005560056 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.896441\n",
      "[50]\ttrain-auc:0.937568\n",
      "[100]\ttrain-auc:0.943275\n",
      "[150]\ttrain-auc:0.94911\n",
      "[200]\ttrain-auc:0.955527\n",
      "[250]\ttrain-auc:0.960549\n",
      "[300]\ttrain-auc:0.964863\n",
      "[350]\ttrain-auc:0.968634\n",
      "[400]\ttrain-auc:0.972311\n",
      "[450]\ttrain-auc:0.975426\n",
      "[500]\ttrain-auc:0.978361\n",
      "the xgboost fit is finished by using 450.512493134 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00557988840223\n",
      "threshold for preds: 0.0800262535407\n",
      "0.293549122368\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.39161689425379753, 0.2355901300907135)\n",
      "scale_pos_weight: 178.533213645\n",
      "a base_score 0.00557 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.896704\n",
      "[50]\ttrain-auc:0.933447\n",
      "[100]\ttrain-auc:0.945668\n",
      "[150]\ttrain-auc:0.952298\n",
      "[200]\ttrain-auc:0.958971\n",
      "[250]\ttrain-auc:0.964867\n",
      "[300]\ttrain-auc:0.969198\n",
      "[350]\ttrain-auc:0.973281\n",
      "[400]\ttrain-auc:0.976447\n",
      "[450]\ttrain-auc:0.979087\n",
      "[500]\ttrain-auc:0.981173\n",
      "the xgboost fit is finished by using 444.810596943 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00556\n",
      "threshold for preds: 0.101060003942\n",
      "0.305491048214\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.4295261215878571, 0.3729596436023712)\n",
      "scale_pos_weight: 178.535008977\n",
      "a base_score 0.00556994430056 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.856659\n",
      "[50]\ttrain-auc:0.934926\n",
      "[100]\ttrain-auc:0.944973\n",
      "[150]\ttrain-auc:0.954006\n",
      "[200]\ttrain-auc:0.960216\n",
      "[250]\ttrain-auc:0.965486\n",
      "[300]\ttrain-auc:0.970324\n",
      "[350]\ttrain-auc:0.974069\n",
      "[400]\ttrain-auc:0.977672\n",
      "[450]\ttrain-auc:0.980344\n",
      "[500]\ttrain-auc:0.982367\n",
      "the xgboost fit is finished by using 453.477813959 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00556011120222\n",
      "threshold for preds: 0.0743836304009\n",
      "0.319959908664\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.46605411329989066, 0.2215878814458847)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(combined_train[dep_var_name], 4)\n",
    "\n",
    "for train_index, valid_index in skf:\n",
    "    valid_data = combined_train.iloc[valid_index]\n",
    "    tmp_train  = combined_train.iloc[train_index]\n",
    "\n",
    "    y = tmp_train[dep_var_name].values\n",
    "    X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "    valid_y = valid_data[dep_var_name].values\n",
    "    valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "    \n",
    "    model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='test_bosch_xgb_model')\n",
    "    model.fit(tmp_train, dep_var_name)\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "    print '\\n'\n",
    "    print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 178.488888889\n",
      "a base_score 0.00557137551071 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.894678\n",
      "[50]\ttrain-auc:0.935115\n",
      "[100]\ttrain-auc:0.942989\n",
      "[150]\ttrain-auc:0.948968\n",
      "[200]\ttrain-auc:0.953416\n",
      "[250]\ttrain-auc:0.959547\n",
      "[300]\ttrain-auc:0.964845\n",
      "[350]\ttrain-auc:0.969812\n",
      "[400]\ttrain-auc:0.973346\n",
      "[450]\ttrain-auc:0.976445\n",
      "[500]\ttrain-auc:0.978809\n",
      "the xgboost fit is finished by using 114.877979994 seconds, saved into bosch_xgb_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.wrapped_xgboost.xgboost_classifier at 0x7f89e5cd0dd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params[\"eta\"]                      = 0.0075\n",
    "params[\"subsample\"]                = 0.8\n",
    "params[\"colsample_bytree\"]         = 0.8\n",
    "params[\"num_round\"]                = 501\n",
    "params[\"max_depth\"]                = 5\n",
    "params[\"gamma\"]                    = 0\n",
    "params[\"metrics\"]                  = 'auc'\n",
    "params['eval_metric']              = 'auc'\n",
    "params[\"seed\"]                     = 999\n",
    "params['verbose_eval']             = 50\n",
    "## whether to use weights\n",
    "params['use_base_score']           = True\n",
    "params['use_weights']              = True\n",
    "#params['use_scale_pos_weight']     = True\n",
    "params[\"val\"]                      = False\n",
    "\n",
    "model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='bosch_xgb_model')\n",
    "model.fit(tmp_train, dep_var_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00555567901509\n",
      "threshold for preds: 0.0849152385588\n",
      "0.308156338689\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.4084263987220095, 0.24640917778015137)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(valid_X)\n",
    "\n",
    "print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 178.488888889\n",
      "a base_score 0.00557137551071 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.894655\n",
      "[50]\ttrain-auc:0.93618\n",
      "[100]\ttrain-auc:0.941446\n",
      "[150]\ttrain-auc:0.948078\n",
      "[200]\ttrain-auc:0.952912\n",
      "[250]\ttrain-auc:0.959198\n",
      "[300]\ttrain-auc:0.965078\n",
      "[350]\ttrain-auc:0.969878\n",
      "[400]\ttrain-auc:0.973686\n",
      "[450]\ttrain-auc:0.976669\n",
      "[500]\ttrain-auc:0.978909\n",
      "the xgboost fit is finished by using 115.617825031 seconds, saved into bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00555567901509\n",
      "threshold for preds: 0.0845989154543\n",
      "0.324245726161\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.4084263987220095, 0.269706666469574)\n"
     ]
    }
   ],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "\n",
    "model.fit(tmp_train, dep_var_name)\n",
    "pred = model.predict(valid_X)\n",
    "\n",
    "print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 178.488888889\n",
      "a base_score 0.00557137551071 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.884097\n",
      "[50]\ttrain-auc:0.934309\n",
      "[100]\ttrain-auc:0.944087\n",
      "[150]\ttrain-auc:0.949238\n",
      "[200]\ttrain-auc:0.953798\n",
      "[250]\ttrain-auc:0.959454\n",
      "[300]\ttrain-auc:0.965253\n",
      "[350]\ttrain-auc:0.970138\n",
      "[400]\ttrain-auc:0.973685\n",
      "[450]\ttrain-auc:0.976442\n",
      "[500]\ttrain-auc:0.978809\n",
      "the xgboost fit is finished by using 232.534298897 seconds, saved into bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00555567901509\n",
      "threshold for preds: 0.0861773046355\n",
      "0.300111644953\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.4084263987220095, 0.27156344056129456)\n"
     ]
    }
   ],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "\n",
    "model.fit(tmp_train, dep_var_name)\n",
    "pred = model.predict(valid_X)\n",
    "\n",
    "print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
