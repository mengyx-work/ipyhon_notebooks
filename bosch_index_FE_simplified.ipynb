{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "sys.path.append('/home/ymm/kaggle/xgboost_hyperopt')\n",
    "import utils.bosch_functions as bosch_functions\n",
    "from utils.wrapped_xgboost import xgboost_classifier\n",
    "from utils.validation_tools import score_MCC, MCC, create_validation_index\n",
    "from utils.models import CombinedModel\n",
    "from utils.data_munge import remove_single_value_columns\n",
    "from utils.feature_engineering import NumericalFeatureEngineering, getRelativeTimeColumns, BasicDate_FeatureEngineering\n",
    "from utils.feature_engineering import getTimeChangeColumns, getTimeSteps, build_IndexFeatures, build_sortedData_indexDiff\n",
    "\n",
    "data_path = '/home/ymm/bosch/'\n",
    "\n",
    "train_num_file   = 'train_numeric.csv'\n",
    "train_cat_file   = 'train_categorical.csv'\n",
    "train_date_file  = 'train_date.csv'\n",
    "test_num_file    = 'test_numeric.csv'\n",
    "test_cat_file    = 'test_categorical.csv'\n",
    "test_date_file   = 'test_date.csv'\n",
    "\n",
    "sample_submission_file   = 'sample_submission.csv'\n",
    "\n",
    "start_time_column_name = 'L0_S0_D1'\n",
    "id_column_name = 'Id'\n",
    "dep_var_name = 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tot_row_num = 1183747\n",
    "num_rows = 5000\n",
    "skip = sorted(random.sample(xrange(1,tot_row_num + 1),tot_row_num - num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading date using 88.0 seconds\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "start_time = time.time()\n",
    "## loading the data by using the skipped_row_num list\n",
    "#train_num = pd.read_csv(join(data_path, train_num_file),    index_col='Id', nrows=num_rows)\n",
    "#train_dat = pd.read_csv(join(data_path, train_date_file),   index_col='Id', nrows=num_rows)\n",
    "#train_cat = pd.read_csv(join(data_path, train_cat_file),    index_col='Id', nrows=num_rows)\n",
    "\n",
    "## randomly select certain rows\n",
    "train_num = pd.read_csv(join(data_path, train_num_file),    index_col='Id', skiprows=skip, nrows=num_rows)\n",
    "train_dat = pd.read_csv(join(data_path, train_date_file),   index_col='Id', skiprows=skip, nrows=num_rows)\n",
    "train_cat = pd.read_csv(join(data_path, train_cat_file),    index_col='Id', skiprows=skip, nrows=num_rows)\n",
    "\n",
    "test_num = pd.read_csv(join(data_path, test_num_file),      index_col='Id', nrows=num_rows)\n",
    "test_dat = pd.read_csv(join(data_path, test_date_file),     index_col='Id', nrows=num_rows)\n",
    "test_cat = pd.read_csv(join(data_path, test_cat_file),      index_col='Id', nrows=num_rows)\n",
    "\n",
    "print 'finish loading date using {} seconds'.format(round(time.time() - start_time, 0))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (5000, 969)\n",
      "raw test data dimension:  (5000, 968)\n",
      "processed train data dimension:  (5000, 969)\n",
      "processed test data dimension:  (5000, 968)\n",
      "raw train data dimension:  (5000, 1156)\n",
      "raw test data dimension:  (5000, 1156)\n",
      "processed train data dimension:  (5000, 1145)\n",
      "processed test data dimension:  (5000, 1145)\n",
      "raw train data dimension:  (5000, 2140)\n",
      "raw test data dimension:  (5000, 2140)\n",
      "processed train data dimension:  (5000, 750)\n",
      "processed test data dimension:  (5000, 750)\n"
     ]
    }
   ],
   "source": [
    "remove_single_value_columns(train_num, 'Response', test=test_num)\n",
    "remove_single_value_columns(train_dat, test=test_dat)\n",
    "remove_single_value_columns(train_cat, test=test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_columns = train_dat.columns.tolist()\n",
    "num_columns = train_num.columns.tolist()\n",
    "num_columns.remove(dep_var_name)\n",
    "\n",
    "def build_column_dict(columns):\n",
    "    station_dict = {}\n",
    "    line_dict = {}\n",
    "    for col in columns:\n",
    "        stationList = col.split('_')[0:2]\n",
    "        stationKey = ('_').join(stationList)\n",
    "        lineKey = col.split('_')[0]\n",
    "        \n",
    "        if lineKey not in line_dict:\n",
    "            line_dict[lineKey] = [col]\n",
    "        else:\n",
    "            line_dict[lineKey].append(col)\n",
    "                    \n",
    "        if stationKey not in station_dict:\n",
    "            station_dict[stationKey] = [col]\n",
    "        else:\n",
    "            station_dict[stationKey].append(col)\n",
    "            \n",
    "    return station_dict, line_dict\n",
    "\n",
    "\n",
    "def build_station_features(df, col_dict, prefix='dat'):\n",
    "    features = pd.DataFrame()\n",
    "    for key, value in col_dict.items():\n",
    "        features['{}_{}_{}'.format(prefix, key, 'mean')] = df[value].mean(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'max')] = df[value].max(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'min')] = df[value].min(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'var')] = df[value].var(axis=1)\n",
    "    return features\n",
    "\n",
    "\n",
    "def build_station_index_features(train, test = None):\n",
    "    selected_columns = []\n",
    "    for col in train.columns:\n",
    "        if 'mean' in col or 'var' in col:\n",
    "            selected_columns.append(col)\n",
    "            \n",
    "    if test is not None:\n",
    "        train_test = pd.concat([train[selected_columns], test[selected_columns]], axis=0)\n",
    "    else:\n",
    "        train_test = train[selected_columns]\n",
    "        \n",
    "    train_test['index'] = train_test.index\n",
    "    #new_fea = pd.DataFrame()\n",
    "    ## function to build index based on the given columns\n",
    "    new_fea = build_sortedData_indexDiff(train_test, selected_columns, index_col_name = 'index')\n",
    "    \n",
    "    return new_fea\n",
    "\n",
    "\n",
    "dat_col_dict, dat_line_dict = build_column_dict(dat_columns)\n",
    "num_col_dict, num_line_dict = build_column_dict(num_columns)\n",
    "\n",
    "dat_col_dict.update(dat_line_dict)\n",
    "num_col_dict.update(num_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date station using 0.05 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_dat_stations = build_station_features(train_dat, dat_col_dict, 'dat')\n",
    "test_dat_stations = build_station_features(test_dat, dat_col_dict, 'dat')\n",
    "\n",
    "train_num_stations = build_station_features(train_num, num_col_dict, 'num')\n",
    "test_num_stations = build_station_features(test_num, num_col_dict, 'num')\n",
    "\n",
    "print 'finish feature engineering date station using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_station_index = build_station_index_features(train_num_stations, test_num_stations)\n",
    "dat_station_index = build_station_index_features(train_dat_stations, test_dat_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_train_station_num = pd.concat([train_num_stations, num_station_index.ix[train_num_stations.index]], axis=1)\n",
    "combined_train_station_dat = pd.concat([train_dat_stations, dat_station_index.ix[train_dat_stations.index]], axis=1)\n",
    "\n",
    "combined_test_station_num = pd.concat([test_num_stations, num_station_index.ix[train_num_stations.index]], axis=1)\n",
    "combined_test_station_dat = pd.concat([test_dat_stations, dat_station_index.ix[train_dat_stations.index]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_L0_mean_index_diff_0\n",
      "num_L0_mean_index_diff_1\n"
     ]
    }
   ],
   "source": [
    "for col in num_station_index.columns:\n",
    "    if 'num_L0_mean' in col:\n",
    "        print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_important_features  =['L3_S30_F3754', 'L3_S30_F3759', 'L3_S33_F3857', 'L3_S33_F3859', \n",
    "                             'L3_S30_F3744', 'L3_S30_F3749', 'L3_S30_F3704', 'L3_S33_F3865']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BasicCat_FeatureEngineering(train_cat):\n",
    "    ## feature engineering on the date features\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    column_names = train_cat.columns.tolist()\n",
    "    column_names.append('NaN')\n",
    "    encoder.fit(column_names)\n",
    "    dat_new_fea = pd.DataFrame()\n",
    "    dat_new_fea['cat_sum'] = train_cat.sum(axis=1)\n",
    "    dat_new_fea['cat_mean'] = train_cat.mean(axis=1)\n",
    "    dat_new_fea['cat_nan_count'] = train_cat.isnull().sum(axis=1)\n",
    "    dat_new_fea['cat_max'] = train_cat.max(axis=1)\n",
    "    dat_new_fea['cat_min'] = train_cat.min(axis=1)\n",
    "    dat_new_fea['cat_max_min_diff'] = dat_new_fea['cat_max'] - dat_new_fea['cat_min']\n",
    "    dat_new_fea['cat_max_min_ratio'] = dat_new_fea['cat_min'] / dat_new_fea['cat_max']\n",
    "\n",
    "    dat_new_fea['cat_idxmax'] = train_cat.idxmax(axis=1)\n",
    "    dat_new_fea['cat_idxmax'].fillna('NaN', inplace=True)\n",
    "    dat_new_fea['cat_idxmax'] = encoder.transform(dat_new_fea['cat_idxmax'])\n",
    "    dat_new_fea['cat_idxmin'] = train_cat.idxmin(axis=1)\n",
    "    dat_new_fea['cat_idxmin'].fillna('NaN', inplace=True)\n",
    "    dat_new_fea['cat_idxmin'] = encoder.transform(dat_new_fea['cat_idxmin'])\n",
    "    return dat_new_fea\n",
    "\n",
    "\n",
    "\n",
    "def encode_categorical_by_dep_var(train, test, dep_var_column='Response'):\n",
    "    for col_name in train.columns:\n",
    "        if col_name == dep_var_column:\n",
    "            continue\n",
    "        dep_var_mean = train[[col_name, dep_var_column]].groupby(col_name).mean()\n",
    "    \n",
    "        dep_var_dict = {}\n",
    "        for level in dep_var_mean.index.tolist():\n",
    "            dep_var_dict[level] = dep_var_mean.ix[level, dep_var_column]\n",
    "    \n",
    "        train[col_name] = train[col_name].replace(dep_var_dict)  \n",
    "        test[col_name] = test[col_name].replace(dep_var_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating categorical features using 16.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_cat['Response'] = train_num['Response']\n",
    "encode_categorical_by_dep_var(train_cat, test_cat)\n",
    "train_cat.drop('Response', axis=1, inplace=True)\n",
    "\n",
    "train_cat_Basics = BasicCat_FeatureEngineering(train_cat)\n",
    "test_cat_Basics  = BasicCat_FeatureEngineering(train_cat)\n",
    "\n",
    "print 'finish generating categorical features using {} seconds'.format(round(time.time() - start_time, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1111) (50000, 1111)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4217</th>\n",
       "      <th>L3_S49_F4220</th>\n",
       "      <th>L3_S49_F4222</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "Id                                                                      \n",
       "7          NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "63         NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "401        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "471        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "519        NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "     L0_S2_F37  L0_S2_F39  L0_S2_F41  L0_S2_F43      ...       L3_S49_F4217  \\\n",
       "Id                                                   ...                      \n",
       "7          NaN        NaN        NaN        NaN      ...                NaN   \n",
       "63         NaN        NaN        NaN        NaN      ...                NaN   \n",
       "401        NaN        NaN        NaN        NaN      ...                NaN   \n",
       "471        NaN        NaN        NaN        NaN      ...                NaN   \n",
       "519        NaN        NaN        NaN        NaN      ...                NaN   \n",
       "\n",
       "     L3_S49_F4220  L3_S49_F4222  L3_S49_F4225  L3_S49_F4227  L3_S49_F4230  \\\n",
       "Id                                                                          \n",
       "7             NaN           NaN           NaN           NaN           NaN   \n",
       "63            NaN           NaN           NaN           NaN           NaN   \n",
       "401           NaN           NaN           NaN           NaN           NaN   \n",
       "471           NaN           NaN           NaN           NaN           NaN   \n",
       "519           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "     L3_S49_F4232  L3_S49_F4235  L3_S49_F4237  L3_S49_F4240  \n",
       "Id                                                           \n",
       "7             NaN           NaN           NaN           NaN  \n",
       "63            NaN           NaN           NaN           NaN  \n",
       "401           NaN           NaN           NaN           NaN  \n",
       "471           NaN           NaN           NaN           NaN  \n",
       "519           NaN           NaN           NaN           NaN  \n",
       "\n",
       "[5 rows x 1111 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_cat.shape, test_cat.shape\n",
    "train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date using 0.51 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_train_cat = pd.concat([train_cat, train_cat_Basics], axis=1)\n",
    "combined_test_cat  = pd.concat([test_cat, test_cat_Basics], axis=1)                                                                                                                                                 \n",
    "print 'finish feature engineering date using {} seconds'.format(round((time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined train numerical feature shape: (50000, 978), combined test numerical features shape: (50000, 977)\n"
     ]
    }
   ],
   "source": [
    "#### numerical feature engineering work\n",
    "train_num_Basics = NumericalFeatureEngineering(train_num)\n",
    "test_num_Basics = NumericalFeatureEngineering(test_num)\n",
    "\n",
    "combined_train_num = pd.concat([train_num, train_num_Basics], axis=1)\n",
    "combined_test_num  = pd.concat([test_num, test_num_Basics], axis=1)                                                                            \n",
    "print 'combined train numerical feature shape: {}, combined test numerical features shape: {}'.format(combined_train_num.shape, combined_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### section of date features\n",
    "\n",
    "## basic features from tmp_train_dat\n",
    "train_dat_Basics = BasicDate_FeatureEngineering(train_dat)\n",
    "test_dat_Basics  = BasicDate_FeatureEngineering(test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (50000, 1154)\n",
      "raw test data dimension:  (50000, 1154)\n",
      "processed train data dimension:  (50000, 972)\n",
      "processed test data dimension:  (50000, 972)\n"
     ]
    }
   ],
   "source": [
    "## normalized date columns\n",
    "train_dat_Norm = train_dat.apply(getRelativeTimeColumns, axis=1)\n",
    "test_dat_Norm  = test_dat.apply(getRelativeTimeColumns, axis=1)\n",
    "## remove single-valued columns\n",
    "remove_single_value_columns(train_dat_Norm, test=test_dat_Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "column_names = train_dat.columns.tolist()\n",
    "column_names.append('NaN')\n",
    "encoder.fit(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TimeDiff features\n",
    "train_dat_TimeDiff = train_dat.apply(getTimeChangeColumns, axis=1)\n",
    "test_dat_TimeDiff  = test_dat.apply(getTimeChangeColumns, axis=1)\n",
    "TimeDiff_ColumnNames = ['time_diff_start_col', 'time_diff_end_col', 'time_diff_value',\n",
    "                        'time_ratio_value', 'first_time_value', 'last_time_value', 'first_date_value']\n",
    "\n",
    "train_dat_TimeDiff.columns = TimeDiff_ColumnNames\n",
    "test_dat_TimeDiff.columns = TimeDiff_ColumnNames\n",
    "\n",
    "for column in ['time_diff_start_col', 'time_diff_end_col']:\n",
    "    train_dat_TimeDiff[column].fillna('NaN', inplace=True)\n",
    "    train_dat_TimeDiff[column] = encoder.transform(train_dat_TimeDiff[column])\n",
    "    \n",
    "    test_dat_TimeDiff[column].fillna('NaN', inplace=True)\n",
    "    test_dat_TimeDiff[column] = encoder.transform(test_dat_TimeDiff[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish generating TimeStep features using 605.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## section to create timeStep features\n",
    "\n",
    "unique_value_counts = 6\n",
    "timeStep_columnNames = []\n",
    "column_name_columns = []\n",
    "for i in xrange(unique_value_counts):\n",
    "    timeStep_columnNames.extend(['time_diff_step_{}'.format(i), 'column_counts_step_{}'.format(i),\n",
    "                                 'time_cost_step_{}'.format(i), 'first_column_step_{}'.format(i)])\n",
    "    column_name_columns.append('first_column_step_{}'.format(i))\n",
    "\n",
    "train_dat_TimeStep = train_dat_Norm.apply(getTimeSteps, axis=1)\n",
    "test_dat_TimeStep  = test_dat_Norm.apply(getTimeSteps, axis=1)\n",
    "train_dat_TimeStep.columns = timeStep_columnNames\n",
    "test_dat_TimeStep.columns  = timeStep_columnNames\n",
    "\n",
    "for column in column_name_columns:\n",
    "    train_dat_TimeStep[column].fillna('NaN', inplace=True)\n",
    "    test_dat_TimeStep[column].fillna('NaN', inplace=True)\n",
    "    train_dat_TimeStep[column] = encoder.transform(train_dat_TimeStep[column])\n",
    "    test_dat_TimeStep[column] = encoder.transform(test_dat_TimeStep[column])\n",
    "\n",
    "\n",
    "print 'finish generating TimeStep features using {} seconds'.format(round(time.time() - start_time, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date using 0.01 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_train_dat = pd.concat([train_dat_Norm, train_dat_Basics, train_dat_TimeDiff, train_dat_TimeStep], axis=1)\n",
    "combined_test_dat  = pd.concat([test_dat_Norm, test_dat_Basics, test_dat_TimeDiff, test_dat_TimeStep], axis=1)                                                                                                                                                 \n",
    "print 'finish feature engineering date using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1013) (50000, 1013)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>L0_S0_D19</th>\n",
       "      <th>...</th>\n",
       "      <th>time_cost_step_3</th>\n",
       "      <th>first_column_step_3</th>\n",
       "      <th>time_diff_step_4</th>\n",
       "      <th>column_counts_step_4</th>\n",
       "      <th>time_cost_step_4</th>\n",
       "      <th>first_column_step_4</th>\n",
       "      <th>time_diff_step_5</th>\n",
       "      <th>column_counts_step_5</th>\n",
       "      <th>time_cost_step_5</th>\n",
       "      <th>first_column_step_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>945</td>\n",
       "      <td>5.72</td>\n",
       "      <td>29</td>\n",
       "      <td>0.197241</td>\n",
       "      <td>1018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050385</td>\n",
       "      <td>945</td>\n",
       "      <td>3.94</td>\n",
       "      <td>19</td>\n",
       "      <td>0.207368</td>\n",
       "      <td>1028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  L0_S0_D13  \\\n",
       "Id                                                                            \n",
       "7         0.0       0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "63        NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "401       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "471       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "519       0.0       0.0       0.0       0.0       0.0        0.0        0.0   \n",
       "\n",
       "     L0_S0_D15  L0_S0_D17  L0_S0_D19         ...           time_cost_step_3  \\\n",
       "Id                                           ...                              \n",
       "7          0.0        0.0        0.0         ...                   0.083971   \n",
       "63         NaN        NaN        NaN         ...                   0.000000   \n",
       "401        NaN        NaN        NaN         ...                   0.000000   \n",
       "471        NaN        NaN        NaN         ...                   0.000000   \n",
       "519        0.0        0.0        0.0         ...                   0.050385   \n",
       "\n",
       "     first_column_step_3  time_diff_step_4  column_counts_step_4  \\\n",
       "Id                                                                 \n",
       "7                    945              5.72                    29   \n",
       "63                  1154               NaN                     0   \n",
       "401                 1154               NaN                     0   \n",
       "471                 1154               NaN                     0   \n",
       "519                  945              3.94                    19   \n",
       "\n",
       "     time_cost_step_4  first_column_step_4  time_diff_step_5  \\\n",
       "Id                                                             \n",
       "7            0.197241                 1018               NaN   \n",
       "63           0.000000                 1154               NaN   \n",
       "401          0.000000                 1154               NaN   \n",
       "471          0.000000                 1154               NaN   \n",
       "519          0.207368                 1028               NaN   \n",
       "\n",
       "     column_counts_step_5  time_cost_step_5  first_column_step_5  \n",
       "Id                                                                \n",
       "7                       0               0.0                 1154  \n",
       "63                      0               0.0                 1154  \n",
       "401                     0               0.0                 1154  \n",
       "471                     0               0.0                 1154  \n",
       "519                     0               0.0                 1154  \n",
       "\n",
       "[5 rows x 1013 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print combined_train_dat.shape, combined_test_dat.shape\n",
    "combined_train_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_datIndex_features = build_IndexFeatures(combined_train_dat, combined_test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the feature importances from xgboost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_feature_imp = pd.read_csv('/home/ymm/full_data_xgb_feature_importance.csv', index_col='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fscore_0</th>\n",
       "      <th>norm_fscore_0</th>\n",
       "      <th>fscore_1</th>\n",
       "      <th>norm_fscore_1</th>\n",
       "      <th>fscore_2</th>\n",
       "      <th>norm_fscore_2</th>\n",
       "      <th>fscore_3</th>\n",
       "      <th>norm_fscore_3</th>\n",
       "      <th>fscore_4</th>\n",
       "      <th>norm_fscore_4</th>\n",
       "      <th>...</th>\n",
       "      <th>fscore_8</th>\n",
       "      <th>norm_fscore_8</th>\n",
       "      <th>fscore_9</th>\n",
       "      <th>norm_fscore_9</th>\n",
       "      <th>fscore_10</th>\n",
       "      <th>norm_fscore_10</th>\n",
       "      <th>fscore_11</th>\n",
       "      <th>norm_fscore_11</th>\n",
       "      <th>fscore_sum</th>\n",
       "      <th>norm_fscore_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first_time_value_index_diff_1</th>\n",
       "      <td>1357.0</td>\n",
       "      <td>0.013342</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>773.0</td>\n",
       "      <td>0.032962</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>...</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>747.0</td>\n",
       "      <td>0.031607</td>\n",
       "      <td>1671.0</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>15033.0</td>\n",
       "      <td>0.228153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S33_F3857</th>\n",
       "      <td>1317.0</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0.013475</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>648.0</td>\n",
       "      <td>0.010175</td>\n",
       "      <td>...</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>12276.0</td>\n",
       "      <td>0.149472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_time_value_index_diff_1</th>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.009979</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.013189</td>\n",
       "      <td>...</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>382.0</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.011768</td>\n",
       "      <td>10737.0</td>\n",
       "      <td>0.145426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S33_F3859</th>\n",
       "      <td>1223.0</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>0.012147</td>\n",
       "      <td>744.0</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>...</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>375.0</td>\n",
       "      <td>0.015867</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>786.0</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>0.144343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_time_value_index_diff_0</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>0.009530</td>\n",
       "      <td>707.0</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>...</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>10258.0</td>\n",
       "      <td>0.132143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               fscore_0  norm_fscore_0  fscore_1  \\\n",
       "feature                                                            \n",
       "first_time_value_index_diff_1    1357.0       0.013342    1480.0   \n",
       "L3_S33_F3857                     1317.0       0.012948    1226.0   \n",
       "last_time_value_index_diff_1     1015.0       0.009979    1059.0   \n",
       "L3_S33_F3859                     1223.0       0.012024    1161.0   \n",
       "last_time_value_index_diff_0     1020.0       0.010028    1087.0   \n",
       "\n",
       "                               norm_fscore_1  fscore_2  norm_fscore_2  \\\n",
       "feature                                                                 \n",
       "first_time_value_index_diff_1       0.014495     773.0       0.032962   \n",
       "L3_S33_F3857                        0.012007     316.0       0.013475   \n",
       "last_time_value_index_diff_1        0.010372     410.0       0.017483   \n",
       "L3_S33_F3859                        0.011371     264.0       0.011258   \n",
       "last_time_value_index_diff_0        0.010646     350.0       0.014925   \n",
       "\n",
       "                               fscore_3  norm_fscore_3  fscore_4  \\\n",
       "feature                                                            \n",
       "first_time_value_index_diff_1    1701.0       0.011999    1198.0   \n",
       "L3_S33_F3857                     1797.0       0.012676     648.0   \n",
       "last_time_value_index_diff_1     1310.0       0.009241     840.0   \n",
       "L3_S33_F3859                     1722.0       0.012147     744.0   \n",
       "last_time_value_index_diff_0     1351.0       0.009530     707.0   \n",
       "\n",
       "                               norm_fscore_4       ...         fscore_8  \\\n",
       "feature                                            ...                    \n",
       "first_time_value_index_diff_1       0.018810       ...           1723.0   \n",
       "L3_S33_F3857                        0.010175       ...           1745.0   \n",
       "last_time_value_index_diff_1        0.013189       ...           1488.0   \n",
       "L3_S33_F3859                        0.011682       ...           1556.0   \n",
       "last_time_value_index_diff_0        0.011101       ...           1391.0   \n",
       "\n",
       "                               norm_fscore_8  fscore_9  norm_fscore_9  \\\n",
       "feature                                                                 \n",
       "first_time_value_index_diff_1       0.012308     747.0       0.031607   \n",
       "L3_S33_F3857                        0.012465     391.0       0.016544   \n",
       "last_time_value_index_diff_1        0.010629     382.0       0.016163   \n",
       "L3_S33_F3859                        0.011115     375.0       0.015867   \n",
       "last_time_value_index_diff_0        0.009937     310.0       0.013117   \n",
       "\n",
       "                               fscore_10  norm_fscore_10  fscore_11  \\\n",
       "feature                                                               \n",
       "first_time_value_index_diff_1     1671.0        0.011886     1152.0   \n",
       "L3_S33_F3857                      1874.0        0.013330      708.0   \n",
       "last_time_value_index_diff_1      1329.0        0.009453      743.0   \n",
       "L3_S33_F3859                      1649.0        0.011729      786.0   \n",
       "last_time_value_index_diff_0      1320.0        0.009389      612.0   \n",
       "\n",
       "                               norm_fscore_11  fscore_sum  norm_fscore_sum  \n",
       "feature                                                                     \n",
       "first_time_value_index_diff_1        0.018246     15033.0         0.228153  \n",
       "L3_S33_F3857                         0.011214     12276.0         0.149472  \n",
       "last_time_value_index_diff_1         0.011768     10737.0         0.145426  \n",
       "L3_S33_F3859                         0.012449     11676.0         0.144343  \n",
       "last_time_value_index_diff_0         0.009693     10258.0         0.132143  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_feature_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sort by the norm_fscore_sum\n",
    "sorted_combined_imp = xgb_feature_imp.sort_values(by=['norm_fscore_sum'], ascending=False)\n",
    "#imp_feature = sorted_combined_imp.index[sorted_combined_imp['norm_fscore_sum'] >= 0.005].tolist()\n",
    "imp_feature = sorted_combined_imp.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_important_features(df, imp_feature, test_df = None, dep_var_name = 'Response'):\n",
    "    imp_col_names = [col for col in df.columns if col in imp_feature]\n",
    "    print 'total {} columns in original DataFrame, select {} columns'.format(df.shape[1], len(imp_col_names))\n",
    "    train_col_names = imp_col_names[:]\n",
    "    test_col_names = imp_col_names[:]\n",
    "    if dep_var_name in df.columns:    \n",
    "        train_col_names.append(dep_var_name)\n",
    "    if test_df is None:\n",
    "        return df[train_col_names]\n",
    "    else:\n",
    "        return df[train_col_names], test_df[test_col_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 978 columns in original DataFrame, select 691 columns\n",
      "total 1013 columns in original DataFrame, select 108 columns\n",
      "total 23 columns in original DataFrame, select 22 columns\n"
     ]
    }
   ],
   "source": [
    "combined_train_num, combined_test_num  = select_important_features(combined_train_num, imp_feature, combined_test_num)\n",
    "combined_train_dat, combined_test_dat  = select_important_features(combined_train_dat, imp_feature, combined_test_dat)\n",
    "train_test_datIndex_features = select_important_features(train_test_datIndex_features, imp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine all the features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## combined data with station features\n",
    "#combined_train = pd.concat([train_dat_stations, train_num_stations, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([test_dat_stations, test_num_stations, combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combined_train = pd.concat([combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## combined data with categorical features\n",
    "#combined_train = pd.concat([combined_train_cat, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([combined_test_cat,  combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_train_station_dat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ed9ce5decf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## combined data with all features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcombined_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_train_station_dat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_train_station_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_train_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_train_dat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_datIndex_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_train_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcombined_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_test_station_dat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_test_station_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_test_cat\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcombined_test_num\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcombined_test_dat\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtrain_test_datIndex_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombined_test_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_train_station_dat' is not defined"
     ]
    }
   ],
   "source": [
    "## combined data with all features\n",
    "combined_train = pd.concat([combined_train_station_dat, combined_train_station_num, combined_train_cat, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "combined_test  = pd.concat([combined_test_station_dat, combined_test_station_num, combined_test_cat,  combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 2813)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dat_L2_S28_mean</th>\n",
       "      <th>dat_L2_S28_max</th>\n",
       "      <th>dat_L2_S28_min</th>\n",
       "      <th>dat_L2_S28_var</th>\n",
       "      <th>dat_L3_S31_mean</th>\n",
       "      <th>dat_L3_S31_max</th>\n",
       "      <th>dat_L3_S31_min</th>\n",
       "      <th>dat_L3_S31_var</th>\n",
       "      <th>dat_L2_S26_mean</th>\n",
       "      <th>dat_L2_S26_max</th>\n",
       "      <th>...</th>\n",
       "      <th>first_date_value_index_ratio_1</th>\n",
       "      <th>first_date_value_index_ratio_2</th>\n",
       "      <th>time_ratio_value_index_diff_0</th>\n",
       "      <th>time_ratio_value_index_diff_1</th>\n",
       "      <th>first_time_value_index_diff_0</th>\n",
       "      <th>first_time_value_index_diff_1</th>\n",
       "      <th>last_time_value_index_diff_0</th>\n",
       "      <th>last_time_value_index_diff_1</th>\n",
       "      <th>first_date_value_index_diff_0</th>\n",
       "      <th>first_date_value_index_diff_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>90086.000000</td>\n",
       "      <td>45481.0</td>\n",
       "      <td>-60087.0</td>\n",
       "      <td>-3232.0</td>\n",
       "      <td>-371803.0</td>\n",
       "      <td>-3232.0</td>\n",
       "      <td>-68013.0</td>\n",
       "      <td>-3232.0</td>\n",
       "      <td>-203442.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37387.000000</td>\n",
       "      <td>46999.5</td>\n",
       "      <td>-1365451.0</td>\n",
       "      <td>-62612.0</td>\n",
       "      <td>-2299392.0</td>\n",
       "      <td>-5943.0</td>\n",
       "      <td>-407847.0</td>\n",
       "      <td>-61348.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>704.11</td>\n",
       "      <td>704.11</td>\n",
       "      <td>...</td>\n",
       "      <td>21175.333333</td>\n",
       "      <td>666.0</td>\n",
       "      <td>-1962074.0</td>\n",
       "      <td>-24124.0</td>\n",
       "      <td>-1748713.0</td>\n",
       "      <td>-24124.0</td>\n",
       "      <td>-95311.0</td>\n",
       "      <td>-24124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.50</td>\n",
       "      <td>255.50</td>\n",
       "      <td>...</td>\n",
       "      <td>18799.800000</td>\n",
       "      <td>18017.2</td>\n",
       "      <td>-88702.0</td>\n",
       "      <td>-2088727.0</td>\n",
       "      <td>-74259.0</td>\n",
       "      <td>-2088727.0</td>\n",
       "      <td>-74259.0</td>\n",
       "      <td>-61577.0</td>\n",
       "      <td>-74259.0</td>\n",
       "      <td>-63560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dat_L2_S28_mean  dat_L2_S28_max  dat_L2_S28_min  dat_L2_S28_var  \\\n",
       "Id                                                                    \n",
       "1               NaN             NaN             NaN             NaN   \n",
       "2               NaN             NaN             NaN             NaN   \n",
       "3               NaN             NaN             NaN             NaN   \n",
       "5               NaN             NaN             NaN             NaN   \n",
       "7               NaN             NaN             NaN             NaN   \n",
       "\n",
       "    dat_L3_S31_mean  dat_L3_S31_max  dat_L3_S31_min  dat_L3_S31_var  \\\n",
       "Id                                                                    \n",
       "1               NaN             NaN             NaN             NaN   \n",
       "2               NaN             NaN             NaN             NaN   \n",
       "3               NaN             NaN             NaN             NaN   \n",
       "5               NaN             NaN             NaN             NaN   \n",
       "7               NaN             NaN             NaN             NaN   \n",
       "\n",
       "    dat_L2_S26_mean  dat_L2_S26_max              ...                \\\n",
       "Id                                               ...                 \n",
       "1               NaN             NaN              ...                 \n",
       "2               NaN             NaN              ...                 \n",
       "3            704.11          704.11              ...                 \n",
       "5            255.50          255.50              ...                 \n",
       "7               NaN             NaN              ...                 \n",
       "\n",
       "    first_date_value_index_ratio_1  first_date_value_index_ratio_2  \\\n",
       "Id                                                                   \n",
       "1                     90086.000000                         45481.0   \n",
       "2                     37387.000000                         46999.5   \n",
       "3                     21175.333333                           666.0   \n",
       "5                     18799.800000                         18017.2   \n",
       "7                              NaN                             NaN   \n",
       "\n",
       "    time_ratio_value_index_diff_0  time_ratio_value_index_diff_1  \\\n",
       "Id                                                                 \n",
       "1                        -60087.0                        -3232.0   \n",
       "2                      -1365451.0                       -62612.0   \n",
       "3                      -1962074.0                       -24124.0   \n",
       "5                        -88702.0                     -2088727.0   \n",
       "7                             NaN                            NaN   \n",
       "\n",
       "    first_time_value_index_diff_0  first_time_value_index_diff_1  \\\n",
       "Id                                                                 \n",
       "1                       -371803.0                        -3232.0   \n",
       "2                      -2299392.0                        -5943.0   \n",
       "3                      -1748713.0                       -24124.0   \n",
       "5                        -74259.0                     -2088727.0   \n",
       "7                             NaN                            NaN   \n",
       "\n",
       "    last_time_value_index_diff_0  last_time_value_index_diff_1  \\\n",
       "Id                                                               \n",
       "1                       -68013.0                       -3232.0   \n",
       "2                      -407847.0                      -61348.0   \n",
       "3                       -95311.0                      -24124.0   \n",
       "5                       -74259.0                      -61577.0   \n",
       "7                            NaN                           NaN   \n",
       "\n",
       "    first_date_value_index_diff_0  first_date_value_index_diff_1  \n",
       "Id                                                                \n",
       "1                       -203442.0                           -1.0  \n",
       "2                             1.0                           -1.0  \n",
       "3                             1.0                           -5.0  \n",
       "5                        -74259.0                       -63560.0  \n",
       "7                             NaN                            NaN  \n",
       "\n",
       "[5 rows x 2813 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print combined_test.shape\n",
    "combined_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3bc3c132d729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcombined_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcombined_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_train' is not defined"
     ]
    }
   ],
   "source": [
    "print combined_train.shape\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"eta\"]                      = 0.0075\n",
    "params[\"subsample\"]                = 0.8\n",
    "params[\"colsample_bytree\"]         = 0.8\n",
    "params[\"num_round\"]                = 501\n",
    "params[\"max_depth\"]                = 5\n",
    "params[\"gamma\"]                    = 0\n",
    "params[\"metrics\"]                  = 'auc'\n",
    "params['eval_metric']              = 'auc'\n",
    "params[\"seed\"]                     = 999\n",
    "params['verbose_eval']             = 50\n",
    "## whether to use weights\n",
    "params['use_base_score']           = True\n",
    "params['use_weights']              = True\n",
    "#params['use_scale_pos_weight']     = True\n",
    "params[\"val\"]                      = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 170.228310502\n",
      "a base_score 0.00584015573749 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.69995\n",
      "[50]\ttrain-auc:0.921853\n",
      "[100]\ttrain-auc:0.948515\n",
      "[150]\ttrain-auc:0.970543\n",
      "[200]\ttrain-auc:0.98424\n",
      "[250]\ttrain-auc:0.991027\n",
      "[300]\ttrain-auc:0.994345\n",
      "[350]\ttrain-auc:0.996518\n",
      "[400]\ttrain-auc:0.997822\n",
      "[450]\ttrain-auc:0.998533\n",
      "[500]\ttrain-auc:0.998926\n",
      "the xgboost fit is finished by using 115.074739933 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00591952643788\n",
      "threshold for preds: 0.0261300979575\n",
      "0.170767009063\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.24373954271718642, 0.09077711403369904)\n",
      "scale_pos_weight: 169.454545455\n",
      "a base_score 0.00586666666667 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.667435\n",
      "[50]\ttrain-auc:0.927524\n",
      "[100]\ttrain-auc:0.946623\n",
      "[150]\ttrain-auc:0.970011\n",
      "[200]\ttrain-auc:0.985635\n",
      "[250]\ttrain-auc:0.991749\n",
      "[300]\ttrain-auc:0.995536\n",
      "[350]\ttrain-auc:0.997345\n",
      "[400]\ttrain-auc:0.99832\n",
      "[450]\ttrain-auc:0.998861\n",
      "[500]\ttrain-auc:0.999199\n",
      "the xgboost fit is finished by using 70.169508934 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00584\n",
      "threshold for preds: 0.0296218443333\n",
      "0.159474895031\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.20817584490475483, 0.06661496311426163)\n",
      "scale_pos_weight: 169.454545455\n",
      "a base_score 0.00586666666667 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.651507\n",
      "[50]\ttrain-auc:0.902859\n",
      "[100]\ttrain-auc:0.927081\n",
      "[150]\ttrain-auc:0.955421\n",
      "[200]\ttrain-auc:0.974134\n",
      "[250]\ttrain-auc:0.984803\n",
      "[300]\ttrain-auc:0.989923\n",
      "[350]\ttrain-auc:0.994493\n",
      "[400]\ttrain-auc:0.996617\n",
      "[450]\ttrain-auc:0.997861\n",
      "[500]\ttrain-auc:0.99858\n",
      "the xgboost fit is finished by using 69.8084080219 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00584\n",
      "threshold for preds: 0.0210679047887\n",
      "0.159474895031\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.1785420249134118, 0.029079917818307877)\n",
      "scale_pos_weight: 169.459090909\n",
      "a base_score 0.00586651022639 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.75029\n",
      "[50]\ttrain-auc:0.907086\n",
      "[100]\ttrain-auc:0.938593\n",
      "[150]\ttrain-auc:0.964457\n",
      "[200]\ttrain-auc:0.978273\n",
      "[250]\ttrain-auc:0.986418\n",
      "[300]\ttrain-auc:0.991929\n",
      "[350]\ttrain-auc:0.99486\n",
      "[400]\ttrain-auc:0.996692\n",
      "[450]\ttrain-auc:0.99765\n",
      "[500]\ttrain-auc:0.998312\n",
      "the xgboost fit is finished by using 99.1968438625 seconds, saved into test_bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00584046723738\n",
      "threshold for preds: 0.0221525590278\n",
      "0.145695393442\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.20841519980584888, 0.048034001141786575)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(combined_train[dep_var_name], 4)\n",
    "\n",
    "for train_index, valid_index in skf:\n",
    "    valid_data = combined_train.iloc[valid_index]\n",
    "    tmp_train  = combined_train.iloc[train_index]\n",
    "\n",
    "    y = tmp_train[dep_var_name].values\n",
    "    X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "    valid_y = valid_data[dep_var_name].values\n",
    "    valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "    \n",
    "    model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='test_bosch_xgb_model')\n",
    "    model.fit(tmp_train, dep_var_name)\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "    print '\\n'\n",
    "    print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c771855ac38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m############## Section of regular validation #######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_validation_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_var_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtmp_train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcombined_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_train' is not defined"
     ]
    }
   ],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "\n",
    "model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='test_bosch_xgb_model')\n",
    "model.fit(tmp_train, dep_var_name)\n",
    "pred = model.predict(valid_X)\n",
    "\n",
    "print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
