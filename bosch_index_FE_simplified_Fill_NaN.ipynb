{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, time, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "sys.path.append('/home/ymm/kaggle/xgboost_hyperopt')\n",
    "import utils.bosch_functions as bosch_functions\n",
    "from utils.wrapped_xgboost import xgboost_classifier\n",
    "from utils.validation_tools import score_MCC, MCC, create_validation_index\n",
    "from utils.models import CombinedModel\n",
    "from utils.data_munge import remove_single_value_columns\n",
    "from utils.feature_engineering import NumericalFeatureEngineering, getRelativeTimeColumns, BasicDate_FeatureEngineering\n",
    "from utils.feature_engineering import getTimeChangeColumns, getTimeSteps, build_IndexFeatures, build_sortedData_indexDiff\n",
    "from utils.feature_engineering import BasicCat_FeatureEngineering, encode_categorical_by_dep_var\n",
    "\n",
    "\n",
    "data_path = '/home/ymm/bosch/'\n",
    "\n",
    "train_num_file   = 'train_numeric.csv'\n",
    "train_cat_file   = 'train_categorical.csv'\n",
    "train_date_file  = 'train_date.csv'\n",
    "test_num_file    = 'test_numeric.csv'\n",
    "test_cat_file    = 'test_categorical.csv'\n",
    "test_date_file   = 'test_date.csv'\n",
    "\n",
    "sample_submission_file   = 'sample_submission.csv'\n",
    "\n",
    "start_time_column_name = 'L0_S0_D1'\n",
    "id_column_name = 'Id'\n",
    "dep_var_name = 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tot_row_num = 1183747\n",
    "num_rows = 50000\n",
    "skip = sorted(random.sample(xrange(1,tot_row_num + 1),tot_row_num - num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading date using 90.0 seconds\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "start_time = time.time()\n",
    "## randomly select certain rows\n",
    "train_num = pd.read_csv(join(data_path, train_num_file),    index_col='Id', skiprows=skip, nrows=num_rows)\n",
    "train_dat = pd.read_csv(join(data_path, train_date_file),   index_col='Id', skiprows=skip, nrows=num_rows)\n",
    "train_cat = pd.read_csv(join(data_path, train_cat_file),    index_col='Id', skiprows=skip, nrows=num_rows)\n",
    "\n",
    "test_num = pd.read_csv(join(data_path, test_num_file),      index_col='Id', nrows=num_rows)\n",
    "test_dat = pd.read_csv(join(data_path, test_date_file),     index_col='Id', nrows=num_rows)\n",
    "test_cat = pd.read_csv(join(data_path, test_cat_file),      index_col='Id', nrows=num_rows)\n",
    "\n",
    "print 'finish loading date using {} seconds'.format(round(time.time() - start_time, 0))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (50000, 969)\n",
      "raw test data dimension:  (50000, 968)\n",
      "processed train data dimension:  (50000, 969)\n",
      "processed test data dimension:  (50000, 968)\n",
      "raw train data dimension:  (50000, 1156)\n",
      "raw test data dimension:  (50000, 1156)\n",
      "processed train data dimension:  (50000, 1146)\n",
      "processed test data dimension:  (50000, 1146)\n",
      "raw train data dimension:  (50000, 2140)\n",
      "raw test data dimension:  (50000, 2140)\n",
      "processed train data dimension:  (50000, 1311)\n",
      "processed test data dimension:  (50000, 1311)\n"
     ]
    }
   ],
   "source": [
    "remove_single_value_columns(train_num, 'Response', test=test_num)\n",
    "remove_single_value_columns(train_dat, test=test_dat)\n",
    "remove_single_value_columns(train_cat, test=test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_columns = train_dat.columns.tolist()\n",
    "num_columns = train_num.columns.tolist()\n",
    "num_columns.remove(dep_var_name)\n",
    "\n",
    "def build_column_dict(columns):\n",
    "    station_dict = {}\n",
    "    line_dict = {}\n",
    "    for col in columns:\n",
    "        stationList = col.split('_')[0:2]\n",
    "        stationKey = ('_').join(stationList)\n",
    "        lineKey = col.split('_')[0]\n",
    "        \n",
    "        if lineKey not in line_dict:\n",
    "            line_dict[lineKey] = [col]\n",
    "        else:\n",
    "            line_dict[lineKey].append(col)\n",
    "                    \n",
    "        if stationKey not in station_dict:\n",
    "            station_dict[stationKey] = [col]\n",
    "        else:\n",
    "            station_dict[stationKey].append(col)\n",
    "            \n",
    "    return station_dict, line_dict\n",
    "\n",
    "\n",
    "def build_station_features(df, col_dict, prefix='dat'):\n",
    "    features = pd.DataFrame()\n",
    "    for key, value in col_dict.items():\n",
    "        features['{}_{}_{}'.format(prefix, key, 'mean')] = df[value].mean(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'max')] = df[value].max(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'min')] = df[value].min(axis=1)\n",
    "        features['{}_{}_{}'.format(prefix, key, 'var')] = df[value].var(axis=1)\n",
    "    return features\n",
    "\n",
    "\n",
    "def build_station_index_features(train, test = None):\n",
    "    selected_columns = []\n",
    "    for col in train.columns:\n",
    "        if 'mean' in col or 'var' in col:\n",
    "            selected_columns.append(col)\n",
    "            \n",
    "    if test is not None:\n",
    "        train_test = pd.concat([train[selected_columns], test[selected_columns]], axis=0)\n",
    "    else:\n",
    "        train_test = train[selected_columns]\n",
    "        \n",
    "    train_test['index'] = train_test.index\n",
    "    new_fea = pd.DataFrame()\n",
    "    ## function to build index based on the given columns\n",
    "    build_sortedData_indexDiff(train_test, new_fea, selected_columns)\n",
    "    \n",
    "    return new_fea\n",
    "\n",
    "\n",
    "dat_col_dict, dat_line_dict = build_column_dict(dat_columns)\n",
    "num_col_dict, num_line_dict = build_column_dict(num_columns)\n",
    "\n",
    "dat_col_dict.update(dat_line_dict)\n",
    "num_col_dict.update(num_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date station using 0.95 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_dat_stations = build_station_features(train_dat, dat_col_dict, 'dat')\n",
    "test_dat_stations = build_station_features(test_dat, dat_col_dict, 'dat')\n",
    "\n",
    "train_num_stations = build_station_features(train_num, num_col_dict, 'num')\n",
    "test_num_stations = build_station_features(test_num, num_col_dict, 'num')\n",
    "\n",
    "num_station_index = build_station_index_features(train_num_stations, test_num_stations)\n",
    "dat_station_index = build_station_index_features(train_dat_stations, test_dat_stations)\n",
    "\n",
    "print 'finish feature engineering date station using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_station_num = pd.concat([train_num_stations, num_station_index.ix[train_num_stations.index]], axis=1)\n",
    "combined_train_station_dat = pd.concat([train_dat_stations, dat_station_index.ix[train_dat_stations.index]], axis=1)\n",
    "\n",
    "combined_test_station_num = pd.concat([test_num_stations, num_station_index.ix[test_num_stations.index]], axis=1)\n",
    "combined_test_station_dat = pd.concat([test_dat_stations, dat_station_index.ix[test_num_stations.index]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7909914 7909914\n"
     ]
    }
   ],
   "source": [
    "print combined_train_station_num.isnull().sum().sum(), combined_train_station_dat.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7908313 7908313\n"
     ]
    }
   ],
   "source": [
    "print combined_test_station_num.isnull().sum().sum(), combined_test_station_dat.isnull().sum().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (50000, 432)\n",
      "raw test data dimension:  (50000, 432)\n",
      "processed train data dimension:  (50000, 431)\n",
      "processed test data dimension:  (50000, 431)\n",
      "raw train data dimension:  (50000, 432)\n",
      "raw test data dimension:  (50000, 432)\n",
      "processed train data dimension:  (50000, 431)\n",
      "processed test data dimension:  (50000, 431)\n"
     ]
    }
   ],
   "source": [
    "remove_single_value_columns(combined_train_station_num, test=combined_test_station_num)\n",
    "remove_single_value_columns(combined_train_station_dat, test=combined_test_station_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_fillna_value = 9999999\n",
    "combined_train_station_num.fillna(station_fillna_value, inplace=True)\n",
    "combined_test_station_num.fillna(station_fillna_value, inplace=True)\n",
    "combined_train_station_dat.fillna(station_fillna_value, inplace=True)\n",
    "combined_test_station_dat.fillna(station_fillna_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_L2_S28_mean</th>\n",
       "      <th>num_L2_S28_max</th>\n",
       "      <th>num_L2_S28_min</th>\n",
       "      <th>num_L2_S28_var</th>\n",
       "      <th>num_L3_S31_mean</th>\n",
       "      <th>num_L3_S31_max</th>\n",
       "      <th>num_L3_S31_min</th>\n",
       "      <th>num_L3_S31_var</th>\n",
       "      <th>num_L2_S26_mean</th>\n",
       "      <th>num_L2_S26_max</th>\n",
       "      <th>...</th>\n",
       "      <th>num_L1_S25_var_index_diff_0</th>\n",
       "      <th>num_L1_S25_var_index_diff_1</th>\n",
       "      <th>num_L1_S24_mean_index_diff_0</th>\n",
       "      <th>num_L1_S24_mean_index_diff_1</th>\n",
       "      <th>num_L1_S24_var_index_diff_0</th>\n",
       "      <th>num_L1_S24_var_index_diff_1</th>\n",
       "      <th>num_L3_S39_mean_index_diff_0</th>\n",
       "      <th>num_L3_S39_mean_index_diff_1</th>\n",
       "      <th>num_L3_S39_var_index_diff_0</th>\n",
       "      <th>num_L3_S39_var_index_diff_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9.999999e+06</td>\n",
       "      <td>9999999.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9.999999e+06</td>\n",
       "      <td>9999999.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>-7</td>\n",
       "      <td>31</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9.999999e+06</td>\n",
       "      <td>9999999.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9.999999e+06</td>\n",
       "      <td>9999999.000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>9999999.0</td>\n",
       "      <td>5.971429e-02</td>\n",
       "      <td>0.299</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2069228</td>\n",
       "      <td>-67667</td>\n",
       "      <td>-308753</td>\n",
       "      <td>-274481</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_L2_S28_mean  num_L2_S28_max  num_L2_S28_min  num_L2_S28_var  \\\n",
       "Id                                                                     \n",
       "28         9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "140        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "175        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "245        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "339        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "\n",
       "     num_L3_S31_mean  num_L3_S31_max  num_L3_S31_min  num_L3_S31_var  \\\n",
       "Id                                                                     \n",
       "28         9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "140        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "175        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "245        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "339        9999999.0       9999999.0       9999999.0       9999999.0   \n",
       "\n",
       "     num_L2_S26_mean  num_L2_S26_max             ...               \\\n",
       "Id                                               ...                \n",
       "28      9.999999e+06     9999999.000             ...                \n",
       "140     9.999999e+06     9999999.000             ...                \n",
       "175     9.999999e+06     9999999.000             ...                \n",
       "245     9.999999e+06     9999999.000             ...                \n",
       "339     5.971429e-02           0.299             ...                \n",
       "\n",
       "     num_L1_S25_var_index_diff_0  num_L1_S25_var_index_diff_1  \\\n",
       "Id                                                              \n",
       "28                             3                           -1   \n",
       "140                            1                           -1   \n",
       "175                            3                           -3   \n",
       "245                            2                           -6   \n",
       "339                            1                           -1   \n",
       "\n",
       "     num_L1_S24_mean_index_diff_0  num_L1_S24_mean_index_diff_1  \\\n",
       "Id                                                                \n",
       "28                              3                            -1   \n",
       "140                             1                            -1   \n",
       "175                             2                            -3   \n",
       "245                             2                            -6   \n",
       "339                      -2069228                        -67667   \n",
       "\n",
       "     num_L1_S24_var_index_diff_0  num_L1_S24_var_index_diff_1  \\\n",
       "Id                                                              \n",
       "28                             3                           -1   \n",
       "140                            1                           -1   \n",
       "175                            2                           -3   \n",
       "245                            2                           -6   \n",
       "339                      -308753                      -274481   \n",
       "\n",
       "     num_L3_S39_mean_index_diff_0  num_L3_S39_mean_index_diff_1  \\\n",
       "Id                                                                \n",
       "28                              3                            -1   \n",
       "140                            31                            -7   \n",
       "175                             2                            -3   \n",
       "245                             2                            -6   \n",
       "339                             1                            -1   \n",
       "\n",
       "     num_L3_S39_var_index_diff_0  num_L3_S39_var_index_diff_1  \n",
       "Id                                                             \n",
       "28                             3                           -1  \n",
       "140                           31                           -7  \n",
       "175                            2                           -3  \n",
       "245                            2                           -6  \n",
       "339                            1                           -1  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_station_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print combined_train_station_num.isnull().sum().sum(), combined_train_station_dat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef BasicCat_FeatureEngineering(train_cat):\\n    ## feature engineering on the date features\\n    encoder = preprocessing.LabelEncoder()\\n    column_names = train_cat.columns.tolist()\\n    column_names.append('NaN')\\n    encoder.fit(column_names)\\n    dat_new_fea = pd.DataFrame()\\n    dat_new_fea['cat_sum'] = train_cat.sum(axis=1)\\n    dat_new_fea['cat_mean'] = train_cat.mean(axis=1)\\n    dat_new_fea['cat_nan_count'] = train_cat.isnull().sum(axis=1)\\n    dat_new_fea['cat_max'] = train_cat.max(axis=1)\\n    dat_new_fea['cat_min'] = train_cat.min(axis=1)\\n    dat_new_fea['cat_max_min_diff'] = dat_new_fea['cat_max'] - dat_new_fea['cat_min']\\n    dat_new_fea['cat_max_min_ratio'] = dat_new_fea['cat_min'] / dat_new_fea['cat_max']\\n\\n    dat_new_fea['cat_idxmax'] = train_cat.idxmax(axis=1)\\n    dat_new_fea['cat_idxmax'].fillna('NaN', inplace=True)\\n    dat_new_fea['cat_idxmax'] = encoder.transform(dat_new_fea['cat_idxmax'])\\n    dat_new_fea['cat_idxmin'] = train_cat.idxmin(axis=1)\\n    dat_new_fea['cat_idxmin'].fillna('NaN', inplace=True)\\n    dat_new_fea['cat_idxmin'] = encoder.transform(dat_new_fea['cat_idxmin'])\\n    return dat_new_fea\\n\\n\\n\\ndef encode_categorical_by_dep_var(train, test, dep_var_column='Response'):\\n    for col_name in train.columns:\\n        if col_name == dep_var_column:\\n            continue\\n        \\n        train[col_name] = train[col_name].astype(str)\\n        test[col_name] = test[col_name].astype(str)\\n        dep_var_mean = train[[col_name, dep_var_column]].groupby(col_name).mean()\\n    \\n        dep_var_dict = {}\\n        for level in dep_var_mean.index.tolist():\\n            dep_var_dict[level] = dep_var_mean.ix[level, dep_var_column]\\n    \\n        train[col_name] = train[col_name].replace(dep_var_dict)  \\n        test[col_name] = test[col_name].replace(dep_var_dict)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def BasicCat_FeatureEngineering(train_cat):\n",
    "    ## feature engineering on the date features\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    column_names = train_cat.columns.tolist()\n",
    "    column_names.append('NaN')\n",
    "    encoder.fit(column_names)\n",
    "    dat_new_fea = pd.DataFrame()\n",
    "    dat_new_fea['cat_sum'] = train_cat.sum(axis=1)\n",
    "    dat_new_fea['cat_mean'] = train_cat.mean(axis=1)\n",
    "    dat_new_fea['cat_nan_count'] = train_cat.isnull().sum(axis=1)\n",
    "    dat_new_fea['cat_max'] = train_cat.max(axis=1)\n",
    "    dat_new_fea['cat_min'] = train_cat.min(axis=1)\n",
    "    dat_new_fea['cat_max_min_diff'] = dat_new_fea['cat_max'] - dat_new_fea['cat_min']\n",
    "    dat_new_fea['cat_max_min_ratio'] = dat_new_fea['cat_min'] / dat_new_fea['cat_max']\n",
    "\n",
    "    dat_new_fea['cat_idxmax'] = train_cat.idxmax(axis=1)\n",
    "    dat_new_fea['cat_idxmax'].fillna('NaN', inplace=True)\n",
    "    dat_new_fea['cat_idxmax'] = encoder.transform(dat_new_fea['cat_idxmax'])\n",
    "    dat_new_fea['cat_idxmin'] = train_cat.idxmin(axis=1)\n",
    "    dat_new_fea['cat_idxmin'].fillna('NaN', inplace=True)\n",
    "    dat_new_fea['cat_idxmin'] = encoder.transform(dat_new_fea['cat_idxmin'])\n",
    "    return dat_new_fea\n",
    "\n",
    "\n",
    "\n",
    "def encode_categorical_by_dep_var(train, test, dep_var_column='Response'):\n",
    "    for col_name in train.columns:\n",
    "        if col_name == dep_var_column:\n",
    "            continue\n",
    "        \n",
    "        train[col_name] = train[col_name].astype(str)\n",
    "        test[col_name] = test[col_name].astype(str)\n",
    "        dep_var_mean = train[[col_name, dep_var_column]].groupby(col_name).mean()\n",
    "    \n",
    "        dep_var_dict = {}\n",
    "        for level in dep_var_mean.index.tolist():\n",
    "            dep_var_dict[level] = dep_var_mean.ix[level, dep_var_column]\n",
    "    \n",
    "        train[col_name] = train[col_name].replace(dep_var_dict)  \n",
    "        test[col_name] = test[col_name].replace(dep_var_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish encoding categorical features using 9.0 seconds\n",
      "finish generating all categorical features using 24.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_cat['Response'] = train_num['Response']\n",
    "encode_categorical_by_dep_var(train_cat, test_cat, dep_var_column='Response', fill_missing=True)\n",
    "train_cat.drop('Response', axis=1, inplace=True)\n",
    "\n",
    "print 'finish encoding categorical features using {} seconds'.format(round(time.time() - start_time, 0))\n",
    "\n",
    "train_cat_Basics = BasicCat_FeatureEngineering(train_cat)\n",
    "test_cat_Basics  = BasicCat_FeatureEngineering(test_cat)\n",
    "\n",
    "print 'finish generating all categorical features using {} seconds'.format(round(time.time() - start_time, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1311) (50000, 1311)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "Id                                                                      \n",
       "28        5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "140       5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "175       5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "245       5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "339       5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "\n",
       "     L0_S2_F37  L0_S2_F39  L0_S2_F41  L0_S2_F43      ...       L3_S49_F4225  \\\n",
       "Id                                                   ...                      \n",
       "28       5.421      5.421      5.421      5.421      ...               5.42   \n",
       "140      5.421      5.421      5.421      5.421      ...               5.42   \n",
       "175      5.421      5.421      5.421      5.421      ...               5.42   \n",
       "245      5.421      5.421      5.421      5.421      ...               5.42   \n",
       "339      5.421      5.421      5.421      5.421      ...               5.42   \n",
       "\n",
       "     L3_S49_F4227  L3_S49_F4229  L3_S49_F4230  L3_S49_F4232  L3_S49_F4234  \\\n",
       "Id                                                                          \n",
       "28           5.42          5.42          5.42          5.42          5.42   \n",
       "140          5.42          5.42          5.42          5.42          5.42   \n",
       "175          5.42          5.42          5.42          5.42          5.42   \n",
       "245          5.42          5.42          5.42          5.42          5.42   \n",
       "339          5.42          5.42          5.42          5.42          5.42   \n",
       "\n",
       "     L3_S49_F4235  L3_S49_F4237  L3_S49_F4239  L3_S49_F4240  \n",
       "Id                                                           \n",
       "28           5.42          5.42          5.42          5.42  \n",
       "140          5.42          5.42          5.42          5.42  \n",
       "175          5.42          5.42          5.42          5.42  \n",
       "245          5.42          5.42          5.42          5.42  \n",
       "339          5.42          5.42          5.42          5.42  \n",
       "\n",
       "[5 rows x 1311 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_cat.shape, test_cat.shape\n",
    "train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering date using 0.52 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_train_cat = pd.concat([train_cat, train_cat_Basics], axis=1)\n",
    "combined_test_cat  = pd.concat([test_cat, test_cat_Basics], axis=1)                                                                                                                                                 \n",
    "print 'finish feature engineering date using {} seconds'.format(round((time.time() - start_time), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print combined_train_cat.isnull().sum(axis=0).sum(), combined_test_cat.isnull().sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>L0_S2_F43</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "      <th>cat_sum</th>\n",
       "      <th>cat_mean</th>\n",
       "      <th>cat_nan_count</th>\n",
       "      <th>cat_max</th>\n",
       "      <th>cat_min</th>\n",
       "      <th>cat_max_min_diff</th>\n",
       "      <th>cat_max_min_ratio</th>\n",
       "      <th>cat_idxmax</th>\n",
       "      <th>cat_idxmin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>7227.472</td>\n",
       "      <td>5.512946</td>\n",
       "      <td>0</td>\n",
       "      <td>8.555</td>\n",
       "      <td>4.867</td>\n",
       "      <td>3.688</td>\n",
       "      <td>0.568907</td>\n",
       "      <td>388</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>6929.384</td>\n",
       "      <td>5.285571</td>\n",
       "      <td>0</td>\n",
       "      <td>5.574</td>\n",
       "      <td>1.883</td>\n",
       "      <td>3.691</td>\n",
       "      <td>0.337818</td>\n",
       "      <td>1091</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>7281.905</td>\n",
       "      <td>5.554466</td>\n",
       "      <td>0</td>\n",
       "      <td>19.685</td>\n",
       "      <td>4.867</td>\n",
       "      <td>14.818</td>\n",
       "      <td>0.247244</td>\n",
       "      <td>389</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>7089.684</td>\n",
       "      <td>5.407844</td>\n",
       "      <td>0</td>\n",
       "      <td>6.440</td>\n",
       "      <td>4.267</td>\n",
       "      <td>2.173</td>\n",
       "      <td>0.662578</td>\n",
       "      <td>1038</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>5.421</td>\n",
       "      <td>...</td>\n",
       "      <td>5.42</td>\n",
       "      <td>7338.145</td>\n",
       "      <td>5.597365</td>\n",
       "      <td>0</td>\n",
       "      <td>19.685</td>\n",
       "      <td>4.867</td>\n",
       "      <td>14.818</td>\n",
       "      <td>0.247244</td>\n",
       "      <td>389</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S1_F25  L0_S1_F27  L0_S1_F29  L0_S1_F31  L0_S2_F33  L0_S2_F35  \\\n",
       "Id                                                                     \n",
       "1        5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "2        5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "3        5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "5        5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "8        5.42       5.42       5.42       5.42      5.421      5.421   \n",
       "\n",
       "    L0_S2_F37  L0_S2_F39  L0_S2_F41  L0_S2_F43     ...      L3_S49_F4240  \\\n",
       "Id                                                 ...                     \n",
       "1       5.421      5.421      5.421      5.421     ...              5.42   \n",
       "2       5.421      5.421      5.421      5.421     ...              5.42   \n",
       "3       5.421      5.421      5.421      5.421     ...              5.42   \n",
       "5       5.421      5.421      5.421      5.421     ...              5.42   \n",
       "8       5.421      5.421      5.421      5.421     ...              5.42   \n",
       "\n",
       "     cat_sum  cat_mean  cat_nan_count  cat_max  cat_min  cat_max_min_diff  \\\n",
       "Id                                                                          \n",
       "1   7227.472  5.512946              0    8.555    4.867             3.688   \n",
       "2   6929.384  5.285571              0    5.574    1.883             3.691   \n",
       "3   7281.905  5.554466              0   19.685    4.867            14.818   \n",
       "5   7089.684  5.407844              0    6.440    4.267             2.173   \n",
       "8   7338.145  5.597365              0   19.685    4.867            14.818   \n",
       "\n",
       "    cat_max_min_ratio  cat_idxmax  cat_idxmin  \n",
       "Id                                             \n",
       "1            0.568907         388        1234  \n",
       "2            0.337818        1091         529  \n",
       "3            0.247244         389        1234  \n",
       "5            0.662578        1038        1074  \n",
       "8            0.247244         389        1234  \n",
       "\n",
       "[5 rows x 1320 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test_cat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish feature engineering numercical using 23.32 seconds\n",
      "combined train numerical feature shape: (50000, 978), combined test numerical features shape: (50000, 977)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#### numerical feature engineering work\n",
    "train_num_Basics = NumericalFeatureEngineering(train_num)\n",
    "test_num_Basics = NumericalFeatureEngineering(test_num)\n",
    "\n",
    "missing_value= -1.5\n",
    "train_num_Basics.fillna(missing_value, inplace=True)\n",
    "test_num_Basics.fillna(missing_value, inplace=True)\n",
    "\n",
    "train_num.fillna(missing_value, inplace=True)\n",
    "test_num.fillna(missing_value, inplace=True)\n",
    "\n",
    "combined_train_num = pd.concat([train_num, train_num_Basics], axis=1)\n",
    "combined_test_num  = pd.concat([test_num, test_num_Basics], axis=1)\n",
    "print 'finish feature engineering numercical using {} seconds'.format(round((time.time() - start_time), 2))\n",
    "print 'combined train numerical feature shape: {}, combined test numerical features shape: {}'.format(combined_train_num.shape, combined_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print combined_train_num.isnull().sum().sum(), combined_test_num.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### section of date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## basic features from tmp_train_dat\n",
    "train_dat_Basics = BasicDate_FeatureEngineering(train_dat)\n",
    "test_dat_Basics  = BasicDate_FeatureEngineering(test_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train data dimension:  (50000, 1146)\n",
      "raw test data dimension:  (50000, 1146)\n",
      "processed train data dimension:  (50000, 960)\n",
      "processed test data dimension:  (50000, 960)\n"
     ]
    }
   ],
   "source": [
    "## normalized date columns\n",
    "train_dat_Norm = train_dat.apply(getRelativeTimeColumns, axis=1)\n",
    "test_dat_Norm  = test_dat.apply(getRelativeTimeColumns, axis=1)\n",
    "## remove single-valued columns\n",
    "remove_single_value_columns(train_dat_Norm, test=test_dat_Norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "column_names = train_dat.columns.tolist()\n",
    "column_names.append('NaN')\n",
    "encoder.fit(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TimeDiff features\n",
    "train_dat_TimeDiff = train_dat.apply(getTimeChangeColumns, axis=1)\n",
    "test_dat_TimeDiff  = test_dat.apply(getTimeChangeColumns, axis=1)\n",
    "TimeDiff_ColumnNames = ['time_diff_start_col', 'time_diff_end_col', 'time_diff_value',\n",
    "                        'time_ratio_value', 'first_time_value', 'last_time_value', 'first_date_value']\n",
    "\n",
    "train_dat_TimeDiff.columns = TimeDiff_ColumnNames\n",
    "test_dat_TimeDiff.columns = TimeDiff_ColumnNames\n",
    "\n",
    "for column in ['time_diff_start_col', 'time_diff_end_col']:\n",
    "    train_dat_TimeDiff[column].fillna('NaN', inplace=True)\n",
    "    train_dat_TimeDiff[column] = encoder.transform(train_dat_TimeDiff[column])\n",
    "    \n",
    "    test_dat_TimeDiff[column].fillna('NaN', inplace=True)\n",
    "    test_dat_TimeDiff[column] = encoder.transform(test_dat_TimeDiff[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## section to create timeStep features\n",
    "unique_value_counts = 6\n",
    "timeStep_columnNames = []\n",
    "column_name_columns = []\n",
    "for i in xrange(unique_value_counts):\n",
    "    timeStep_columnNames.extend(['time_diff_step_{}'.format(i), 'column_counts_step_{}'.format(i),\n",
    "                                 'time_cost_step_{}'.format(i), 'first_column_step_{}'.format(i)])\n",
    "    column_name_columns.append('first_column_step_{}'.format(i))\n",
    "\n",
    "train_dat_TimeStep = train_dat_Norm.apply(getTimeSteps, axis=1)\n",
    "test_dat_TimeStep  = test_dat_Norm.apply(getTimeSteps, axis=1)\n",
    "train_dat_TimeStep.columns = timeStep_columnNames\n",
    "test_dat_TimeStep.columns  = timeStep_columnNames\n",
    "\n",
    "for column in column_name_columns:\n",
    "    train_dat_TimeStep[column].fillna('NaN', inplace=True)\n",
    "    test_dat_TimeStep[column].fillna('NaN', inplace=True)\n",
    "    train_dat_TimeStep[column] = encoder.transform(train_dat_TimeStep[column])\n",
    "    test_dat_TimeStep[column] = encoder.transform(test_dat_TimeStep[column])\n",
    "\n",
    "\n",
    "print 'finish generating TimeStep features using {} minutes'.format(round((time.time() - start_time)/60, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print train_dat_Norm.isnull().sum().sum(), train_dat_Basics.isnull().sum().sum(), train_dat_TimeStep.isnull().sum().sum(), train_dat_TimeDiff.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fill up missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "tmp_train_dat = train_dat_TimeDiff.copy()\n",
    "tmp_test_dat = test_dat_TimeDiff.copy()\n",
    "\n",
    "if 'start_time' in train_dat_Basics:\n",
    "    tmp_train_dat['start_time'] = train_dat_Basics['start_time']\n",
    "    tmp_test_dat['start_time']  = test_dat_Basics['start_time']\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "combined_train_dat = pd.concat([train_dat_Norm, train_dat_Basics, train_dat_TimeDiff, train_dat_TimeStep], axis=1)\n",
    "combined_test_dat  = pd.concat([test_dat_Norm, test_dat_Basics, test_dat_TimeDiff, test_dat_TimeStep], axis=1)                                                                                                                                                 \n",
    "print 'finish feature engineering date using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "train_test_datIndex_features = build_IndexFeatures(combined_train_dat, combined_test_dat)\n",
    "print 'finish feature engineering date index using {} minutes'.format(round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### index columns fill up missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_datIndex_features.fillna(-1., inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### after filling up missing, re-create the date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print combined_train_dat.shape, combined_test_dat.shape\n",
    "combined_train_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dat_Norm.fillna(-1., inplace=True)\n",
    "test_dat_Norm.fillna(-1., inplace=True)\n",
    "\n",
    "train_dat_Basics.fillna(-1., inplace=True)\n",
    "test_dat_Basics.fillna(-1., inplace=True)\n",
    "\n",
    "train_dat_TimeStep.fillna(0, inplace=True)\n",
    "test_dat_TimeStep.fillna(0, inplace=True)\n",
    "\n",
    "train_dat_TimeDiff.fillna(0, inplace=True)\n",
    "test_dat_TimeDiff.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train_dat = pd.concat([train_dat_Norm, train_dat_Basics, train_dat_TimeDiff, train_dat_TimeStep], axis=1)\n",
    "combined_test_dat  = pd.concat([test_dat_Norm, test_dat_Basics, test_dat_TimeDiff, test_dat_TimeStep], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print combined_test_dat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_test_datIndex_features['index_ratio'].min()\n",
    "#train_test_datIndex_features.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the feature importances from xgboost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_feature_imp = pd.read_csv('/home/ymm/full_data_xgb_feature_importance.csv', index_col='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_feature_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sort by the norm_fscore_sum\n",
    "sorted_combined_imp = xgb_feature_imp.sort_values(by=['norm_fscore_sum'], ascending=False)\n",
    "#imp_feature = sorted_combined_imp.index[sorted_combined_imp['norm_fscore_sum'] >= 0.005].tolist()\n",
    "imp_feature = sorted_combined_imp.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_important_features(df, imp_feature, test_df = None, dep_var_name = 'Response'):\n",
    "    imp_col_names = [col for col in df.columns if col in imp_feature]\n",
    "    print 'total {} columns in original DataFrame, select {} columns'.format(df.shape[1], len(imp_col_names))\n",
    "    train_col_names = imp_col_names[:]\n",
    "    test_col_names = imp_col_names[:]\n",
    "    if dep_var_name in df.columns:    \n",
    "        train_col_names.append(dep_var_name)\n",
    "    if test_df is None:\n",
    "        return df[train_col_names]\n",
    "    else:\n",
    "        return df[train_col_names], test_df[test_col_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_train_num, combined_test_num  = select_important_features(combined_train_num, imp_feature, combined_test_num)\n",
    "combined_train_dat, combined_test_dat  = select_important_features(combined_train_dat, imp_feature, combined_test_dat)\n",
    "train_test_datIndex_features = select_important_features(train_test_datIndex_features, imp_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine all the features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## combined data with station features\n",
    "#combined_train = pd.concat([train_dat_stations, train_num_stations, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([test_dat_stations, test_num_stations, combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combined_train = pd.concat([combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## combined data with categorical features\n",
    "#combined_train = pd.concat([combined_train_cat, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "#combined_test  = pd.concat([combined_test_cat,  combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## combined data with all features\n",
    "combined_train = pd.concat([combined_train_station_dat, combined_train_station_num, combined_train_cat, combined_train_num, combined_train_dat, train_test_datIndex_features.ix[combined_train_num.index, :]], axis=1)\n",
    "combined_test  = pd.concat([combined_test_station_dat, combined_test_station_num, combined_test_cat,  combined_test_num,  combined_test_dat,  train_test_datIndex_features.ix[combined_test_num.index, :]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print combined_test_cat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print combined_train.isnull().sum().sum(), combined_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print combined_test.shape\n",
    "combined_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print combined_train.shape\n",
    "combined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"eta\"]                      = 0.0075\n",
    "params[\"subsample\"]                = 0.8\n",
    "params[\"colsample_bytree\"]         = 0.8\n",
    "params[\"num_round\"]                = 501\n",
    "params[\"max_depth\"]                = 5\n",
    "params[\"gamma\"]                    = 0\n",
    "params[\"metrics\"]                  = 'auc'\n",
    "params['eval_metric']              = 'auc'\n",
    "params[\"seed\"]                     = 999\n",
    "params['verbose_eval']             = 50\n",
    "## whether to use weights\n",
    "params['use_base_score']           = True\n",
    "params['use_weights']              = True\n",
    "#params['use_scale_pos_weight']     = True\n",
    "params[\"val\"]                      = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "skf = StratifiedKFold(combined_train[dep_var_name], 4)\n",
    "\n",
    "for train_index, valid_index in skf:\n",
    "    valid_data = combined_train.iloc[valid_index]\n",
    "    tmp_train  = combined_train.iloc[train_index]\n",
    "\n",
    "    y = tmp_train[dep_var_name].values\n",
    "    X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "    valid_y = valid_data[dep_var_name].values\n",
    "    valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "    \n",
    "    model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='test_bosch_xgb_model')\n",
    "    model.fit(tmp_train, dep_var_name)\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "    print '\\n'\n",
    "    print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regular models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print tmp_train['index_ratio'].min(), tmp_train['index_ratio'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_params = {'random_state' : 9999, 'n_estimators' : 2000, 'max_depth' : 5, 'criterion' : 'gini', 'n_jobs' : -1}\n",
    "et_params = {'random_state' : 9999, 'n_estimators' : 200, 'max_depth' : 5, 'criterion' : 'gini', 'n_jobs' : -1}\n",
    "rf_clf = RandomForestClassifier(**rf_params)\n",
    "rf_clf = rf_clf.fit(X, y)\n",
    "\n",
    "et_clf = RandomForestClassifier(**et_params)\n",
    "et_clf = et_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_pred = rf_clf.predict_proba(valid_X)[:, 1]\n",
    "et_pred = et_clf.predict_proba(valid_X)[:, 1]\n",
    "\n",
    "print 'result from using constant fraction: \\n'\n",
    "print score_MCC(valid_y, rf_pred)\n",
    "print score_MCC(valid_y, et_pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:'\n",
    "print CombinedModel.mcc_eval_func(valid_y, rf_pred)\n",
    "print CombinedModel.mcc_eval_func(valid_y, et_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "\n",
    "model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='test_bosch_xgb_model')\n",
    "model.fit(tmp_train, dep_var_name)\n",
    "pred = model.predict(valid_X)\n",
    "\n",
    "print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
