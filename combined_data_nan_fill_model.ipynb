{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, time, random\n",
    "from os.path import join\n",
    "import yaml\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "sys.path.append('/home/ymm/kaggle/xgboost_hyperopt')\n",
    "from utils.bosch_functions import load_processed_bosch_data\n",
    "from utils.wrapped_xgboost import xgboost_classifier\n",
    "\n",
    "from utils.models import CombinedModel\n",
    "from utils.validation_tools import score_MCC, MCC, create_validation_index, cross_validate_model\n",
    "from utils.validation_tools import get_combinedFeaImp_fromProj\n",
    "from utils.feature_engineering import encode_categorical_by_dep_var\n",
    "\n",
    "dep_var_name = 'Response'\n",
    "project_name = 'processed_subsample_250k_data_xgb'\n",
    "                                                                                                                                               \n",
    "\n",
    "feature_data_path = '/home/ymm/kaggle/xgboost_hyperopt/scripts/xgb_model_features_0'\n",
    "data_path = '/home/ymm/kaggle/bosch_data/bosch_processed_data'                                                                                 \n",
    "train_file_name = 'bosch_combined_train_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data is (50000, 1558), using 0.49 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## subsample training data                                                                                                                     \n",
    "tot_row_num = 1183747\n",
    "num_rows = 50000                                                                                                                              \n",
    "skip = sorted(random.sample(xrange(1,tot_row_num + 1),tot_row_num - num_rows))\n",
    "train = pd.read_csv(join(data_path, train_file_name), index_col='Id', skiprows=skip)                                                           \n",
    "print 'shape of training data is {}, using {} minutes'.format(train.shape, round((time.time() - start_time)/60, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'bosch_feature_dict.yml'), 'r') as yml_stream:\n",
    "    models_dict = yaml.load(yml_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1152, 2)\n",
      "(1209, 2)\n",
      "(1216, 2)\n",
      "(1168, 2)\n",
      "(1204, 2)\n",
      "['date', 'station', 'num', 'cat']\n"
     ]
    }
   ],
   "source": [
    "combined_feature_importance = get_combinedFeaImp_fromProj(feature_data_path)\n",
    "selected_features = combined_feature_importance.index.tolist()\n",
    "\n",
    "print models_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_selected_features(selected_features, feature_set, train_features):\n",
    "    selected_subset_feature = [col for col in feature_set if col in selected_features]\n",
    "    for col in selected_subset_feature:\n",
    "        if col not in train_features:\n",
    "            print 'column {} does not exist in train'.format(col)\n",
    "    return selected_subset_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "station_features = get_selected_features(selected_features, models_dict['station'], train.columns.tolist())\n",
    "num_features = get_selected_features(selected_features, models_dict['num'], train.columns.tolist())\n",
    "cat_features = get_selected_features(selected_features, models_dict['cat'], train.columns.tolist())\n",
    "dat_features = get_selected_features(selected_features, models_dict['date'], train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_stat = train[station_features]\n",
    "train_cat = train[cat_features]\n",
    "train_num = train[num_features]\n",
    "train_dat = train[dat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 774) (50000, 16) (50000, 624) (50000, 143)\n"
     ]
    }
   ],
   "source": [
    "print train_stat.shape, train_cat.shape, train_num.shape, train_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print train_stat.max().max(), train_stat.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3111968 23131423 375874 12818619\n"
     ]
    }
   ],
   "source": [
    "print train_dat.isnull().sum().sum(), train_num.isnull().sum().sum(), train_cat.isnull().sum().sum(), train_stat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_missing_value= -1.5\n",
    "dat_missing_value = -1.\n",
    "station_fillna_value = 9999999\n",
    "\n",
    "train_stat = train_stat.fillna(station_fillna_value)\n",
    "train_num = train_num.fillna(num_missing_value)\n",
    "train_dat = train_dat.fillna(dat_missing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/ymm/.virtualenvs/kaggle/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/mnt/home/ymm/.virtualenvs/kaggle/local/lib/python2.7/site-packages/pandas/core/frame.py:2762: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/home/ymm/kaggle/xgboost_hyperopt/utils/feature_engineering.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  train[col_name] = train[col_name].replace(dep_var_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish encoding categorical features using 1.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/ymm/.virtualenvs/kaggle/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_cat['Response'] = train['Response']\n",
    "encode_columns_dict = encode_categorical_by_dep_var(train_cat, dep_var_column='Response', fill_missing=True, fill_missing_value = 9999999)\n",
    "train_cat.drop('Response', axis=1, inplace=True)\n",
    "\n",
    "print 'finish encoding categorical features using {} seconds'.format(round(time.time() - start_time, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print train_dat.isnull().sum().sum(), train_num.isnull().sum().sum(), train_cat.isnull().sum().sum(), train_stat.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train = pd.concat([train_dat, train_num, train_cat, train_stat], axis=1)\n",
    "combined_train[dep_var_name] = train[dep_var_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1558) (50000, 1558)\n"
     ]
    }
   ],
   "source": [
    "print combined_train.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############## Section of regular validation #######################\n",
    "train_index, valid_index = create_validation_index(combined_train, 0.3, dep_var_name, True)\n",
    "valid_data = combined_train.ix[valid_index]\n",
    "tmp_train  = combined_train.ix[train_index]\n",
    "\n",
    "y = tmp_train[dep_var_name].values\n",
    "X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "valid_y = valid_data[dep_var_name].values\n",
    "valid_X = valid_data.drop(dep_var_name, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"eta\"]                      = 0.0075\n",
    "params[\"subsample\"]                = 0.8\n",
    "params[\"colsample_bytree\"]         = 0.8\n",
    "params[\"num_round\"]                = 501\n",
    "params[\"max_depth\"]                = 5\n",
    "params[\"gamma\"]                    = 0\n",
    "params[\"metrics\"]                  = 'auc'\n",
    "params['eval_metric']              = 'auc'\n",
    "params[\"seed\"]                     = 999\n",
    "params['verbose_eval']             = 50\n",
    "## whether to use weights\n",
    "params['use_base_score']           = True\n",
    "params['use_weights']              = True\n",
    "#params['use_scale_pos_weight']     = True\n",
    "params[\"val\"]                      = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 167.274038462\n",
      "a base_score 0.00594268735179 is used in the xgboost model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "####################\n",
      " train the xgboost without early stopping\n",
      "####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.895148\n",
      "[50]\ttrain-auc:0.961153\n",
      "[100]\ttrain-auc:0.969305\n",
      "[150]\ttrain-auc:0.97737\n",
      "[200]\ttrain-auc:0.984385\n",
      "[250]\ttrain-auc:0.988474\n",
      "[300]\ttrain-auc:0.991049\n",
      "[350]\ttrain-auc:0.99259\n",
      "[400]\ttrain-auc:0.994035\n",
      "[450]\ttrain-auc:0.995422\n",
      "[500]\ttrain-auc:0.996536\n",
      "the xgboost fit is finished by using 8.7 minutes, saved into bosch_xgb_model\n",
      "in the prediction step, dep_var_name is not provided....\n",
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00586705780385\n",
      "threshold for preds: 0.111308638462\n",
      "0.405603550765\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.4284298364314721, 0.177175372838974)\n"
     ]
    }
   ],
   "source": [
    "model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='bosch_xgb_model')\n",
    "model.fit(tmp_train, dep_var_name)\n",
    "\n",
    "pred = model.predict(valid_X)\n",
    "\n",
    "print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_params = {'random_state' : 9999, 'n_estimators' : 2000, 'max_depth' : 7, 'criterion' : 'gini', 'n_jobs' : -1}\n",
    "et_params = {'random_state' : 9999, 'n_estimators' : 200, 'max_depth' : 18, 'criterion' : 'gini', 'n_jobs' : -1}\n",
    "rf_clf = RandomForestClassifier(**rf_params)\n",
    "rf_clf = rf_clf.fit(X, y)\n",
    "\n",
    "et_clf = RandomForestClassifier(**et_params)\n",
    "et_clf = et_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result from using constant fraction: \n",
      "mean of groud truth: 0.00586705780385\n",
      "threshold for preds: 0.134773146856\n",
      "0.337019345084 mean of groud truth: 0.00586705780385\n",
      "threshold for preds: 0.300734622164\n",
      "0.302727242243\n",
      "\n",
      "\n",
      "result from using flexsible threshold: (0.39552983420609317, 0.20865927876708792) (0.38484222456887607, 0.42587428133674543)\n"
     ]
    }
   ],
   "source": [
    "rf_pred = rf_clf.predict_proba(valid_X)[:, 1]\n",
    "et_pred = et_clf.predict_proba(valid_X)[:, 1]\n",
    "\n",
    "print 'result from using constant fraction: \\n'\n",
    "print score_MCC(valid_y, rf_pred)\n",
    "print score_MCC(valid_y, et_pred)\n",
    "print '\\n'\n",
    "print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, rf_pred), CombinedModel.mcc_eval_func(valid_y, et_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.36064602607579765, 0.4279625149738292)\n"
     ]
    }
   ],
   "source": [
    "et_params = {'random_state' : 9999, 'n_estimators' : 200, 'max_depth' : 20, 'criterion' : 'gini', 'n_jobs' : -1}\n",
    "\n",
    "et_clf = RandomForestClassifier(**et_params)\n",
    "et_clf = et_clf.fit(X, y)\n",
    "\n",
    "et_pred = et_clf.predict_proba(valid_X)[:, 1]\n",
    "print  CombinedModel.mcc_eval_func(valid_y, et_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(combined_train[dep_var_name], 3)\n",
    "\n",
    "for train_index, valid_index in skf:\n",
    "    valid_data = combined_train.iloc[valid_index]\n",
    "    tmp_train  = combined_train.iloc[train_index]\n",
    "\n",
    "    y = tmp_train[dep_var_name].values\n",
    "    X = tmp_train.drop(dep_var_name, axis=1)\n",
    "\n",
    "    valid_y = valid_data[dep_var_name].values\n",
    "    valid_X = valid_data.drop(dep_var_name, axis=1)\n",
    "    \n",
    "    model = xgboost_classifier(label_name = dep_var_name, params = params, model_file='test_bosch_xgb_model')\n",
    "    model.fit(tmp_train, dep_var_name)\n",
    "    \n",
    "    pred = model.predict(valid_X)\n",
    "    print 'result from using constant fraction: \\n', score_MCC(valid_y, pred)\n",
    "    print '\\n'\n",
    "    print 'result from using flexsible threshold:', CombinedModel.mcc_eval_func(valid_y, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
