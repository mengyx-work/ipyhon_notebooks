{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as ssp\n",
    "import pylab as plt\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD,NMF,PCA,FactorAnalysis\n",
    "from sklearn.feature_selection import SelectFromModel,SelectPercentile,f_classif\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,Flatten, Dropout, merge,Convolution1D,MaxPooling1D,Lambda,AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.advanced_activations import PReLU,LeakyReLU,ELU,SReLU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neural net initialized with weigths w0: 0.09, w1: 0.00'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "np.random.seed(0)\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=1, input_dim=1, init=\"normal\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "# print initial weigths\n",
    "weights = model.layers[0].get_weights()\n",
    "w0 = weights[0][0][0]\n",
    "w1 = weights[1][0]\n",
    "'neural net initialized with weigths w0: {w0:.2f}, w1: {w1:.2f}'.format(**locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.08820262]], dtype=float32), array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_points = 200\n",
    "x = np.linspace(0, 2, n_points)\n",
    "y = np.array([0] * int(n_points / 2) + list(x[:int(n_points / 2)])) * 2\n",
    "\n",
    "X_train = np.array(x, ndmin=2).T\n",
    "Y_train = np.array(y, ndmin=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "[ 0.          0.01005025  0.0201005   0.03015075  0.04020101  0.05025126\n",
      "  0.06030151  0.07035176  0.08040201  0.09045226]\n"
     ]
    }
   ],
   "source": [
    "print x.shape\n",
    "print x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [ 0.01005025],\n",
       "       [ 0.0201005 ],\n",
       "       [ 0.03015075],\n",
       "       [ 0.04020101],\n",
       "       [ 0.05025126],\n",
       "       [ 0.06030151],\n",
       "       [ 0.07035176],\n",
       "       [ 0.08040201],\n",
       "       [ 0.09045226]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_train.shape\n",
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "new_labels = to_categorical(labels, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print new_labels.shape\n",
    "type(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 2.7 on Jupyter\n",
    "# Libraries: Keras, pandas, numpy, matplotlib, seaborn\n",
    "\n",
    "# For compatibility\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "# For manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils # For y values\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# For Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "\n",
    "# Set data\n",
    "data = np.array([\n",
    "    [0, 0, 0],\n",
    "    [1, 1, 0],\n",
    "    [2, 2, 0],\n",
    "    [3, 3, 0],\n",
    "    [4, 4, 0],\n",
    "    [5, 5, 1],\n",
    "    [6, 6, 1],\n",
    "    [7, 7, 1],\n",
    "    [8, 8, 1],\n",
    "    [9, 9, 1],\n",
    "])\n",
    "data = np.vstack((data, data, data, data)) # Just for sufficient input\n",
    "data = pd.DataFrame(data, columns=['x', 'y', 'class'])\n",
    "\n",
    "# Split X and y\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1:].values\n",
    "\n",
    "# Get dimensions of input and output\n",
    "dimof_input = X.shape[1]\n",
    "dimof_output = np.max(y) + 1\n",
    "print('dimof_input: ', dimof_input)\n",
    "print('dimof_output: ', dimof_output)\n",
    "\n",
    "# Set y categorical\n",
    "y = np_utils.to_categorical(y, dimof_output)\n",
    "\n",
    "# Set constants\n",
    "batch_size = 128\n",
    "dimof_middle = 100\n",
    "dropout = 0.2\n",
    "countof_epoch = 100\n",
    "verbose = 0\n",
    "print('batch_size: ', batch_size)\n",
    "print('dimof_middle: ', dimof_middle)\n",
    "print('dropout: ', dropout)\n",
    "print('countof_epoch: ', countof_epoch)\n",
    "print('verbose: ', verbose)\n",
    "print()\n",
    "\n",
    "# Set model\n",
    "model = Sequential()\n",
    "model.add(Dense(dimof_middle, input_dim=dimof_input, init='uniform', activation='tanh'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(dimof_middle, init='uniform', activation='tanh'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(dimof_output, init='uniform', activation='softmax'))\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(\n",
    "    X, y,\n",
    "    validation_split=0.2,\n",
    "    batch_size=batch_size, nb_epoch=countof_epoch, verbose=verbose)\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X, y, verbose=verbose)\n",
    "print('loss: ', loss)\n",
    "print('accuracy: ', accuracy)\n",
    "print()\n",
    "\n",
    "# Predict\n",
    "# model.predict_classes(X, verbose=verbose)\n",
    "print('prediction of [1, 1]: ', model.predict_classes(np.array([[1, 1]]), verbose=verbose))\n",
    "print('prediction of [8, 8]: ', model.predict_classes(np.array([[8, 8]]), verbose=verbose))\n",
    "\n",
    "# Plot\n",
    "sns.lmplot('x', 'y', data, 'class', fit_reg=False).set(title='Data')\n",
    "data_ = data.copy()\n",
    "data_['class'] = model.predict_classes(X, verbose=0)\n",
    "sns.lmplot('x', 'y', data_, 'class', fit_reg=False).set(title='Trained Result')\n",
    "data_['class'] = [ 'Error' if is_error else 'Non Error' for is_error in data['class'] != data_['class']]\n",
    "sns.lmplot('x', 'y', data_, 'class', fit_reg=False).set(title='Errors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
