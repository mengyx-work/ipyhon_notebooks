{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "import yaml\n",
    "import cPickle as pickle\n",
    "\n",
    "data_path = '/home/ymm/bosch/'\n",
    "\n",
    "train_num_file   = 'train_numeric.csv'\n",
    "train_cat_file   = 'train_categorical.csv'\n",
    "train_date_file  = 'train_date.csv'\n",
    "test_num_file    = 'test_numeric.csv'\n",
    "test_cat_file    = 'test_categorical.csv'\n",
    "test_date_file   = 'test_date.csv'\n",
    "\n",
    "sample_submission_file   = 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This section loads a fraction of categorical data and save the columns\n",
    "names into a pickle file named by 'pickle_column_names_file'.\n",
    "So that the following categorical data loading can directly use explicitly types\n",
    "'''\n",
    "def create_categorical_column_name_pickle(train_cat_file, pickle_column_names_file):\n",
    "\n",
    "    tmp_train_cat = pd.read_csv(data_path + train_cat_file, index_col='Id', nrows=1000)\n",
    "\n",
    "    #for col, dtype in zip(tmp_train_cat.columns, tmp_train_cat.dtypes):\n",
    "    #    print len(train_cat[col].unique()), dtype\n",
    "\n",
    "    ## save the column names to pickle file\n",
    "    col_names = tmp_train_cat.columns.tolist()\n",
    "    with open(pickle_column_names_file, 'wb') as pickle_file:\n",
    "        pickle.dump(col_names, pickle_file)\n",
    "\n",
    "\n",
    "pickle_column_names_file = data_path + 'cat_col_names.pkl'\n",
    "start_time_column_name = 'L0_S0_D1'\n",
    "id_column_name = 'Id'\n",
    "dep_var_name = 'Response'\n",
    "bin_num = 15 ## number of bins to separate data by start_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading takes  57.5  seconds.\n"
     ]
    }
   ],
   "source": [
    "## load the labels and start_time column for train and test data\n",
    "start_time = time.time()\n",
    "train_labels = pd.read_csv(data_path + train_num_file, index_col='Id', usecols=['Id', dep_var_name])\n",
    "train_date_start_columm = pd.read_csv(data_path + train_date_file, index_col='Id', usecols=['Id', start_time_column_name])\n",
    "test_date_start_columm = pd.read_csv(data_path + test_date_file, index_col='Id', usecols=['Id', start_time_column_name])\n",
    "end_time = time.time()\n",
    "print 'data loading takes ', round((end_time - start_time), 1), ' seconds.'\n",
    "\n",
    "## join the start_time with labels, then drop the NaN in start_time\n",
    "labeled_start_time = pd.merge(train_labels, train_date_start_columm, how='left', left_index=True, right_index=True)\n",
    "## this labeled_start_time dataFrame doesn't contain the NaN\n",
    "## can be directly used for calculating the mquantiles\n",
    "labeled_start_time = labeled_start_time[~labeled_start_time[start_time_column_name].isnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "section to subset the data by start_time\n",
    "'''\n",
    "from scipy.stats.mstats import mquantiles\n",
    "\n",
    "prob_list = [1.*i/bin_num for i in range(1, bin_num)]\n",
    "quantile_values = mquantiles(labeled_start_time[start_time_column_name], prob=prob_list)\n",
    "\n",
    "bins = [labeled_start_time[start_time_column_name].min()]\n",
    "bins.extend(quantile_values)\n",
    "bins.append(labeled_start_time[start_time_column_name].max())\n",
    "bin_names = [str(i) for i in range(len(bins)-1)]\n",
    "\n",
    "## cut the entire dataframe into different time_windows by start_time\n",
    "tmp_train = train_date_start_columm.copy()\n",
    "tmp_test = test_date_start_columm.copy()\n",
    "\n",
    "tmp_train['time_window_num'] = pd.cut(tmp_train[start_time_column_name], bins, labels=bin_names)\n",
    "tmp_test['time_window_num'] = pd.cut(tmp_test[start_time_column_name], bins, labels=bin_names)\n",
    "## create a row number column, start index is 1\n",
    "tmp_train['row_num'] = range(1, (tmp_train.shape[0] + 1))\n",
    "tmp_test['row_num'] = range(1, (tmp_test.shape[0] + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_categorical_data(train, test, fill_missing = False):\n",
    "    '''\n",
    "    encoding is an extemely slow process\n",
    "    So only use the training data to trian the encoder\n",
    "    '''\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    ## new dataFrame is created from here\n",
    "    if fill_missing:\n",
    "        train = train.fillna(value='missing')\n",
    "        test = test.fillna(value='missing')\n",
    "\n",
    "    ## idealy combine the train and test\n",
    "    #combined = pd.concat([train, test], axis=0)\n",
    "    counter = 0\n",
    "    start_time = time.time()\n",
    "    for col in train.columns:\n",
    "        combined_df = pd.concat([train[col], test[col]], axis=0)\n",
    "        le.fit(combined_df)\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "        #print train[col].unique()\n",
    "        #print test[col].unique()\n",
    "        counter += 1\n",
    "        if counter % 20 == 0:\n",
    "            print '{} out of {} is process...'.format(str(counter), str(train.shape[1]))\n",
    "\n",
    "    for col in train.columns:\n",
    "        print col, train[col].unique()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print 'encoding process takes ', round((end_time - start_time)), 'seconds'\n",
    "\n",
    "    return train, test\n",
    "    \n",
    "    \n",
    "def process_date_data(train_date, test_date, start_time_column_name):\n",
    "    print 'raw date data dimension: ', train_date.shape, test_date.shape\n",
    "    train_date['start_time'] = train_date[start_time_column_name]\n",
    "    test_date['start_time'] = test_date[start_time_column_name]\n",
    "    single_value_column_names = []\n",
    "\n",
    "    for column in train_date.columns:\n",
    "        if column != 'start_time':\n",
    "            train_date[column] = train_date[column] - train_date['start_time']\n",
    "            test_date[column] = test_date[column] - test_date['start_time']\n",
    "        if len(train_date[column].unique()) == 1:\n",
    "            single_value_column_names.append(column)\n",
    "\n",
    "    ## drop single-valued columns\n",
    "    train_date.drop(single_value_column_names, axis=1, inplace=True)\n",
    "    test_date.drop(single_value_column_names, axis=1, inplace=True)\n",
    "    print 'processed date data dimension: ', train_date.shape, test_date.shape\n",
    "\n",
    "\n",
    "\n",
    "def remove_single_value_categorical_columns(train, test):\n",
    "    print 'raw categorical data dimension: ', train.shape, test.shape\n",
    "    single_value_column_names = []\n",
    "    for col in train.columns:\n",
    "        if len(train[col].unique()) == 1:\n",
    "            single_value_column_names.append(col)\n",
    "\n",
    "    train.drop(single_value_column_names, axis=1, inplace=True)\n",
    "    test.drop(single_value_column_names, axis=1, inplace=True)\n",
    "    print 'processed categorical data dimension: ', train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_bin_name = '0'\n",
    "none_selected_window_num = bin_names[:]\n",
    "none_selected_window_num.append(np.NaN)\n",
    "none_selected_window_num.remove(selected_bin_name)\n",
    "skipped_test_row_num = tmp_test.loc[tmp_test['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\n",
    "skipped_train_row_num = tmp_train.loc[tmp_train['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading takes  88.94 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "##### section to load column names for categorical data  ##########\n",
    "if not os.path.isfile(pickle_column_names_file):\n",
    "    print 'create new column name pickle file ...'\n",
    "    create_categorical_column_name_pickle(train_cat_file, pickle_column_names_file)\n",
    "\n",
    "with open(pickle_column_names_file, 'rb') as pickle_file:\n",
    "    cat_column_names = pickle.load(pickle_file)\n",
    "\n",
    "column_types = [np.object] * len(cat_column_names)\n",
    "column_types_dict = dict(zip(cat_column_names, column_types))\n",
    "################\n",
    "\n",
    "train_date = pd.read_csv(data_path + train_date_file, index_col='Id', skiprows=skipped_train_row_num)\n",
    "train_num = pd.read_csv(data_path + train_num_file, index_col='Id', skiprows=skipped_train_row_num)\n",
    "train_cat = pd.read_csv(data_path + train_cat_file, index_col='Id', skiprows=skipped_train_row_num)\n",
    "\n",
    "test_date = pd.read_csv(data_path + test_date_file, index_col='Id', skiprows=skipped_test_row_num)\n",
    "test_num = pd.read_csv(data_path + test_num_file, index_col='Id', skiprows=skipped_test_row_num)\n",
    "test_cat = pd.read_csv(data_path + test_cat_file, index_col='Id', skiprows=skipped_test_row_num)\n",
    "\n",
    "end_time = time.time()\n",
    "print 'data loading takes ', round((end_time - start_time), 2), 'seconds'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('/home/ymm/kaggle/xgboost_hyperopt')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__', '__doc__', '__file__', '__name__', '__package__', 'aa', 'bb']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoderEncoderelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make a copy of the original data\n",
    "tmp_train_date = train_date.copy()\n",
    "tmp_train_num = train_num.copy()\n",
    "tmp_train_cat = train_cat.copy()\n",
    "\n",
    "tmp_test_date = test_date.copy()\n",
    "tmp_test_num = test_num.copy()\n",
    "tmp_test_cat = test_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw date data dimension:  (44923, 1156) (45340, 1156)\n",
      "processed date data dimension:  (44923, 546) (45340, 546)\n",
      "finish processing date data ...\n"
     ]
    }
   ],
   "source": [
    "## process the date data\n",
    "process_date_data(tmp_train_date, tmp_test_date, start_time_column_name)\n",
    "print 'finish processing date data ...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data quality check:\n",
    "## expect all the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp_train_num.dtypes[tmp_train_num.dtypes != 'float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(tmp_test_date.dtypes == 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw categorical data dimension:  (44923, 2140) (45340, 2140)\n",
      "processed categorical data dimension:  (44923, 343) (45340, 343)\n",
      "20 out of 343 is process...\n",
      "40 out of 343 is process...\n",
      "60 out of 343 is process...\n",
      "80 out of 343 is process...\n",
      "100 out of 343 is process...\n",
      "120 out of 343 is process...\n",
      "140 out of 343 is process...\n",
      "160 out of 343 is process...\n",
      "180 out of 343 is process...\n",
      "200 out of 343 is process...\n",
      "220 out of 343 is process...\n",
      "240 out of 343 is process...\n",
      "260 out of 343 is process...\n",
      "280 out of 343 is process...\n",
      "300 out of 343 is process...\n",
      "320 out of 343 is process...\n",
      "340 out of 343 is process...\n",
      "encoding process takes  61.0 seconds\n",
      "finish processing categorical data ...\n"
     ]
    }
   ],
   "source": [
    "## process categorical data\n",
    "remove_single_value_categorical_columns(tmp_train_cat, tmp_test_cat)\n",
    "encode_categorical_data(tmp_train_cat, tmp_test_cat, True)\n",
    "print 'finish processing categorical data ...'\n",
    "\n",
    "## combine the data and save into csv files\n",
    "#combined_train = pd.concat([train_cat, train_num, train_date], axis=1)\n",
    "#combined_test = pd.concat([test_cat, test_num, test_date], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 out of 343 is process...\n",
      "40 out of 343 is process...\n",
      "60 out of 343 is process...\n",
      "80 out of 343 is process...\n",
      "100 out of 343 is process...\n",
      "120 out of 343 is process...\n",
      "140 out of 343 is process...\n",
      "160 out of 343 is process...\n",
      "180 out of 343 is process...\n",
      "200 out of 343 is process...\n",
      "220 out of 343 is process...\n",
      "240 out of 343 is process...\n",
      "260 out of 343 is process...\n",
      "280 out of 343 is process...\n",
      "300 out of 343 is process...\n",
      "320 out of 343 is process...\n",
      "340 out of 343 is process...\n",
      "L0_S2_F33 [1 0]\n",
      "L0_S2_F35 [3 1 2]\n",
      "L0_S2_F37 [1 0]\n",
      "L0_S2_F39 [3 1 2]\n",
      "L0_S2_F41 [1 0]\n",
      "L0_S2_F43 [3 1 2]\n",
      "L0_S2_F45 [1 0]\n",
      "L0_S2_F47 [3 1 2]\n",
      "L0_S2_F49 [1 0]\n",
      "L0_S2_F51 [3 1 2]\n",
      "L0_S2_F53 [1 0]\n",
      "L0_S2_F55 [3 1 2]\n",
      "L0_S2_F57 [1 0]\n",
      "L0_S2_F59 [3 1 2]\n",
      "L0_S2_F61 [1 0]\n",
      "L0_S2_F63 [3 1 2]\n",
      "L0_S2_F65 [1 0]\n",
      "L0_S2_F67 [3 1 2]\n",
      "L0_S6_F119 [1 0]\n",
      "L0_S6_F121 [1 0]\n",
      "L0_S6_F123 [1 0]\n",
      "L0_S6_F125 [1 0]\n",
      "L0_S6_F126 [1 0]\n",
      "L0_S6_F128 [1 0]\n",
      "L0_S6_F129 [1 0]\n",
      "L0_S6_F131 [1 0]\n",
      "L0_S6_F133 [1 0]\n",
      "L0_S6_F135 [1 0]\n",
      "L0_S9_F151 [1 0]\n",
      "L0_S9_F153 [1 0]\n",
      "L0_S9_F154 [9 4 7 6 5 8 3 1]\n",
      "L0_S9_F156 [1 0]\n",
      "L0_S9_F158 [1 0]\n",
      "L0_S9_F159 [5 3 4 2 0]\n",
      "L0_S9_F161 [1 0]\n",
      "L0_S9_F163 [1 0]\n",
      "L0_S9_F164 [9 4 7 6 5 8 3 1]\n",
      "L0_S9_F166 [1 0]\n",
      "L0_S9_F168 [1 0]\n",
      "L0_S9_F169 [6 3 4 5 2 0]\n",
      "L0_S9_F171 [1 0]\n",
      "L0_S9_F173 [1 0]\n",
      "L0_S9_F174 [9 4 7 6 5 8 3 1]\n",
      "L0_S9_F176 [1 0]\n",
      "L0_S9_F178 [1 0]\n",
      "L0_S9_F179 [5 3 4 2 0]\n",
      "L0_S9_F181 [1 0]\n",
      "L0_S9_F183 [1 0]\n",
      "L0_S9_F184 [5 3 4 2 0]\n",
      "L0_S9_F186 [1 0]\n",
      "L0_S9_F188 [1 0]\n",
      "L0_S9_F189 [5 3 4 2 0]\n",
      "L0_S9_F191 [1 0]\n",
      "L0_S9_F193 [1 0]\n",
      "L0_S9_F194 [5 3 4 2 0]\n",
      "L0_S9_F196 [1 0]\n",
      "L0_S9_F198 [1 0]\n",
      "L0_S9_F199 [5 3 4 2 0]\n",
      "L0_S9_F201 [1 0]\n",
      "L0_S9_F203 [1 0]\n",
      "L0_S9_F204 [5 3 4 2 0]\n",
      "L0_S9_F206 [1 0]\n",
      "L0_S9_F208 [1 0]\n",
      "L0_S9_F209 [5 3 4 2 0]\n",
      "L0_S9_F211 [1 0]\n",
      "L0_S9_F213 [1 0]\n",
      "L0_S9_F214 [5 3 4 2 0]\n",
      "L0_S10_F215 [1 0]\n",
      "L0_S10_F217 [1 0]\n",
      "L0_S10_F218 [8 3 6 2 4 5 0]\n",
      "L0_S10_F220 [1 0]\n",
      "L0_S10_F222 [1 0]\n",
      "L0_S10_F223 [8 3 6 2 4 5 0]\n",
      "L0_S10_F225 [1 0]\n",
      "L0_S10_F227 [1 0]\n",
      "L0_S10_F228 [8 3 6 2 4 5 0]\n",
      "L0_S10_F230 [1 0]\n",
      "L0_S10_F232 [1 0]\n",
      "L0_S10_F233 [8 3 6 2 4 5 0]\n",
      "L0_S10_F235 [1 0]\n",
      "L0_S10_F237 [1 0]\n",
      "L0_S10_F238 [8 3 6 2 4 5 0]\n",
      "L0_S10_F240 [1 0]\n",
      "L0_S10_F242 [1 0]\n",
      "L0_S10_F243 [8 3 6 2 4 5 0]\n",
      "L0_S10_F245 [1 0]\n",
      "L0_S10_F247 [1 0]\n",
      "L0_S10_F248 [8 3 6 2 4 5 0]\n",
      "L0_S10_F250 [1 0]\n",
      "L0_S10_F252 [1 0]\n",
      "L0_S10_F253 [8 3 6 2 4 5 0]\n",
      "L0_S10_F255 [1 0]\n",
      "L0_S10_F257 [1 0]\n",
      "L0_S10_F258 [8 3 6 2 4 5 0]\n",
      "L0_S10_F260 [1 0]\n",
      "L0_S10_F262 [1 0]\n",
      "L0_S10_F263 [8 3 6 2 4 5 0]\n",
      "L0_S10_F265 [1 0]\n",
      "L0_S10_F267 [1 0]\n",
      "L0_S10_F268 [8 3 6 2 4 5 0]\n",
      "L0_S10_F270 [1 0]\n",
      "L0_S10_F272 [1 0]\n",
      "L0_S10_F273 [8 3 6 2 4 5 0]\n",
      "L0_S10_F275 [1 0]\n",
      "L0_S10_F277 [1 0]\n",
      "L0_S10_F278 [8 3 6 2 4 5 0]\n",
      "L1_S24_F675 [2 0]\n",
      "L1_S24_F703 [1 0]\n",
      "L1_S24_F705 [2 0]\n",
      "L1_S24_F708 [1 0]\n",
      "L1_S24_F710 [2 0]\n",
      "L1_S24_F713 [1 0]\n",
      "L1_S24_F726 [1 0]\n",
      "L1_S24_F731 [1 0]\n",
      "L1_S24_F736 [1 0]\n",
      "L1_S24_F740 [1 0]\n",
      "L1_S24_F744 [1 0]\n",
      "L1_S24_F773 [1 0]\n",
      "L1_S24_F819 [1 0]\n",
      "L1_S24_F823 [1 0]\n",
      "L1_S24_F827 [1 0]\n",
      "L1_S24_F832 [1 0]\n",
      "L1_S24_F837 [1 0]\n",
      "L1_S24_F842 [1 0]\n",
      "L1_S24_F847 [1 0]\n",
      "L1_S24_F851 [1 0]\n",
      "L1_S24_F855 [1 0]\n",
      "L1_S24_F860 [1 0]\n",
      "L1_S24_F865 [1 0]\n",
      "L1_S24_F870 [1 0]\n",
      "L1_S24_F875 [1 0]\n",
      "L1_S24_F880 [1 0]\n",
      "L1_S24_F885 [1 0]\n",
      "L1_S24_F890 [1 0]\n",
      "L1_S24_F895 [1 0]\n",
      "L1_S24_F900 [1 0]\n",
      "L1_S24_F905 [1 0]\n",
      "L1_S24_F1064 [1 0]\n",
      "L2_S26_F3038 [1 0]\n",
      "L2_S26_F3042 [1 0]\n",
      "L2_S26_F3045 [1 0]\n",
      "L2_S26_F3049 [1 0]\n",
      "L2_S26_F3053 [1 0]\n",
      "L2_S26_F3057 [1 0]\n",
      "L2_S26_F3060 [1 0]\n",
      "L2_S26_F3064 [1 0]\n",
      "L2_S26_F3067 [1 0]\n",
      "L2_S26_F3071 [1 0]\n",
      "L2_S26_F3075 [1 0]\n",
      "L2_S26_F3079 [1 0]\n",
      "L2_S26_F3082 [1 0]\n",
      "L2_S26_F3085 [1 0]\n",
      "L2_S26_F3088 [1 0]\n",
      "L2_S26_F3091 [1 0]\n",
      "L2_S26_F3094 [1 0]\n",
      "L2_S26_F3097 [1 0]\n",
      "L2_S26_F3099 [1 0]\n",
      "L2_S26_F3101 [1 0]\n",
      "L2_S26_F3104 [1 0]\n",
      "L2_S26_F3108 [1 0]\n",
      "L2_S26_F3111 [1 0]\n",
      "L2_S26_F3115 [1 0]\n",
      "L2_S26_F3119 [1 0]\n",
      "L2_S26_F3123 [1 0]\n",
      "L2_S26_F3127 [1 0]\n",
      "L2_S27_F3131 [1 0]\n",
      "L2_S27_F3135 [1 0]\n",
      "L2_S27_F3138 [1 0]\n",
      "L2_S27_F3142 [1 0]\n",
      "L2_S27_F3146 [1 0]\n",
      "L2_S27_F3150 [1 0]\n",
      "L2_S27_F3153 [1 0]\n",
      "L2_S27_F3157 [1 0]\n",
      "L2_S27_F3160 [1 0]\n",
      "L2_S27_F3164 [1 0]\n",
      "L2_S27_F3168 [1 0]\n",
      "L2_S27_F3172 [1 0]\n",
      "L2_S27_F3175 [1 0]\n",
      "L2_S27_F3178 [1 0]\n",
      "L2_S27_F3181 [1 0]\n",
      "L2_S27_F3184 [1 0]\n",
      "L2_S27_F3187 [1 0]\n",
      "L2_S27_F3190 [1 0]\n",
      "L2_S27_F3192 [1 0]\n",
      "L2_S27_F3194 [1 0]\n",
      "L2_S27_F3197 [1 0]\n",
      "L2_S27_F3201 [1 0]\n",
      "L2_S27_F3204 [1 0]\n",
      "L2_S27_F3208 [1 0]\n",
      "L2_S27_F3212 [1 0]\n",
      "L2_S27_F3216 [1 0]\n",
      "L2_S27_F3220 [1 0]\n",
      "L2_S28_F3224 [1 0]\n",
      "L2_S28_F3225 [1 0]\n",
      "L2_S28_F3228 [1 0]\n",
      "L2_S28_F3229 [1 0]\n",
      "L2_S28_F3231 [1 0]\n",
      "L2_S28_F3232 [1 0]\n",
      "L2_S28_F3235 [1 0]\n",
      "L2_S28_F3236 [1 0]\n",
      "L2_S28_F3239 [1 0]\n",
      "L2_S28_F3240 [1 0]\n",
      "L2_S28_F3243 [1 0]\n",
      "L2_S28_F3244 [1 0]\n",
      "L2_S28_F3246 [1 0]\n",
      "L2_S28_F3247 [1 0]\n",
      "L2_S28_F3250 [1 0]\n",
      "L2_S28_F3251 [1 0]\n",
      "L2_S28_F3253 [1 0]\n",
      "L2_S28_F3254 [1 0]\n",
      "L2_S28_F3257 [1 0]\n",
      "L2_S28_F3258 [1 0]\n",
      "L2_S28_F3261 [1 0]\n",
      "L2_S28_F3262 [1 0]\n",
      "L2_S28_F3265 [1 0]\n",
      "L2_S28_F3266 [1 0]\n",
      "L2_S28_F3268 [1 0]\n",
      "L2_S28_F3269 [1 0]\n",
      "L2_S28_F3271 [1 0]\n",
      "L2_S28_F3272 [1 0]\n",
      "L2_S28_F3274 [1 0]\n",
      "L2_S28_F3275 [1 0]\n",
      "L2_S28_F3277 [1 0]\n",
      "L2_S28_F3278 [1 0]\n",
      "L2_S28_F3280 [1 0]\n",
      "L2_S28_F3281 [1 0]\n",
      "L2_S28_F3283 [1 0]\n",
      "L2_S28_F3284 [1 0]\n",
      "L2_S28_F3285 [1 0]\n",
      "L2_S28_F3287 [1 0]\n",
      "L2_S28_F3288 [1 0]\n",
      "L2_S28_F3290 [1 0]\n",
      "L2_S28_F3291 [1 0]\n",
      "L2_S28_F3294 [1 0]\n",
      "L2_S28_F3295 [1 0]\n",
      "L2_S28_F3297 [1 0]\n",
      "L2_S28_F3298 [1 0]\n",
      "L2_S28_F3301 [1 0]\n",
      "L2_S28_F3302 [1 0]\n",
      "L2_S28_F3305 [1 0]\n",
      "L2_S28_F3306 [1 0]\n",
      "L2_S28_F3309 [1 0]\n",
      "L2_S28_F3310 [1 0]\n",
      "L2_S28_F3313 [1 0]\n",
      "L2_S28_F3314 [1 0]\n",
      "L3_S29_F3317 [1 0]\n",
      "L3_S29_F3320 [1 0]\n",
      "L3_S29_F3323 [1 0]\n",
      "L3_S29_F3326 [1 0]\n",
      "L3_S29_F3329 [1 0]\n",
      "L3_S29_F3332 [1 0]\n",
      "L3_S29_F3335 [1 0]\n",
      "L3_S29_F3338 [1 0]\n",
      "L3_S29_F3341 [1 0]\n",
      "L3_S29_F3344 [1 0]\n",
      "L3_S29_F3347 [1 0]\n",
      "L3_S29_F3350 [1 0]\n",
      "L3_S29_F3353 [1 0]\n",
      "L3_S29_F3356 [1 0]\n",
      "L3_S29_F3359 [1 0]\n",
      "L3_S29_F3362 [1 0]\n",
      "L3_S29_F3364 [1 0]\n",
      "L3_S29_F3366 [1 0]\n",
      "L3_S29_F3369 [1 0]\n",
      "L3_S29_F3372 [1 0]\n",
      "L3_S29_F3375 [1 0]\n",
      "L3_S29_F3378 [1 0]\n",
      "L3_S29_F3381 [1 0]\n",
      "L3_S29_F3384 [1 0]\n",
      "L3_S29_F3387 [1 0]\n",
      "L3_S29_F3390 [1 0]\n",
      "L3_S29_F3392 [1 0]\n",
      "L3_S29_F3394 [1 0]\n",
      "L3_S29_F3397 [1 0]\n",
      "L3_S29_F3400 [1 0]\n",
      "L3_S29_F3403 [1 0]\n",
      "L3_S29_F3406 [1 0]\n",
      "L3_S29_F3409 [1 0]\n",
      "L3_S29_F3411 [1 0]\n",
      "L3_S29_F3414 [1 0]\n",
      "L3_S29_F3416 [1 0]\n",
      "L3_S29_F3418 [1 0]\n",
      "L3_S29_F3420 [1 0]\n",
      "L3_S29_F3423 [1 0]\n",
      "L3_S29_F3426 [1 0]\n",
      "L3_S29_F3429 [1 0]\n",
      "L3_S29_F3432 [1 0]\n",
      "L3_S29_F3435 [1 0]\n",
      "L3_S29_F3438 [1 0]\n",
      "L3_S29_F3441 [1 0]\n",
      "L3_S29_F3444 [1 0]\n",
      "L3_S29_F3446 [1 0]\n",
      "L3_S29_F3448 [1 0]\n",
      "L3_S29_F3451 [1 0]\n",
      "L3_S29_F3454 [1 0]\n",
      "L3_S29_F3457 [1 0]\n",
      "L3_S29_F3460 [1 0]\n",
      "L3_S29_F3463 [1 0]\n",
      "L3_S29_F3466 [1 0]\n",
      "L3_S29_F3469 [1 0]\n",
      "L3_S29_F3472 [1 0]\n",
      "L3_S29_F3475 [1 0]\n",
      "L3_S29_F3478 [1 0]\n",
      "L3_S29_F3481 [1 0]\n",
      "L3_S29_F3484 [1 0]\n",
      "L3_S29_F3487 [1 0]\n",
      "L3_S29_F3490 [1 0]\n",
      "L3_S29_F3493 [1 0]\n",
      "L3_S31_F3835 [1 0]\n",
      "L3_S31_F3837 [1 0]\n",
      "L3_S31_F3839 [1 0]\n",
      "L3_S31_F3841 [1 0]\n",
      "L3_S31_F3843 [1 0]\n",
      "L3_S31_F3845 [1 0]\n",
      "L3_S31_F3847 [1 0]\n",
      "L3_S31_F3849 [1 0]\n",
      "L3_S32_F3851 [1 0]\n",
      "L3_S32_F3854 [17 16  5  7  9 14 13 10  8  3  6  2 12  4  1  0]\n",
      "L3_S35_F3899 [1 0]\n",
      "L3_S35_F3902 [2 0 1]\n",
      "L3_S35_F3904 [1 0]\n",
      "L3_S35_F3907 [2 0 1]\n",
      "L3_S35_F3909 [1 0]\n",
      "L3_S35_F3912 [2 0 1]\n",
      "L3_S35_F3914 [1 0]\n",
      "L3_S35_F3917 [2 0 1]\n",
      "L3_S38_F3954 [1 0]\n",
      "L3_S38_F3955 [1 0]\n",
      "L3_S38_F3958 [1 0]\n",
      "L3_S38_F3959 [1 0]\n",
      "L3_S38_F3962 [1 0]\n",
      "L3_S38_F3963 [1 0]\n",
      "L3_S47_F4141 [1 0]\n",
      "L3_S47_F4146 [1 0]\n",
      "L3_S47_F4151 [1 0]\n",
      "L3_S47_F4156 [1 0]\n",
      "L3_S47_F4161 [1 0]\n",
      "L3_S47_F4166 [1 0]\n",
      "L3_S47_F4171 [1 0]\n",
      "L3_S47_F4176 [1 0]\n",
      "L3_S47_F4181 [1 0]\n",
      "L3_S47_F4186 [1 0]\n",
      "L3_S47_F4191 [1 0]\n",
      "encoding process takes  60.0 seconds\n"
     ]
    }
   ],
   "source": [
    "encode_categorical_data(tmp_train_cat, tmp_test_cat, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'T128'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train_cat['L3_S31_F3841'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T32' 'T96']\n",
      "[nan 'T1']\n",
      "[nan 'T16']\n",
      "[nan 'T1']\n",
      "[nan 'T16']\n",
      "[nan 'T1']\n",
      "[nan 'T16']\n",
      "[nan 'T1']\n",
      "[nan 'T16']\n",
      "[nan 'T1']\n",
      "[nan 'T16']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T65536' 'T6553' 'T96' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T65536' 'T6553' 'T96' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T96' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T65536' 'T6553' 'T96' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T48576' 'T8' 'T16777557' 'T16777232']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T16777248' 'T48576' 'T16777232' 'T32' 'T48' 'T12582912']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T3']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T145']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T145']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T145']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T2']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T128']\n",
      "[nan 'T1']\n",
      "[nan 'T128']\n",
      "[nan 'T1']\n",
      "[nan 'T128']\n",
      "[nan 'T1']\n",
      "[nan 'T128']\n",
      "[nan 'T1']\n",
      "[nan 'T8' 'T1' 'T128' 'T2' 'T512' 'T4' 'T256' 'T16' 'T-2147483648' 'T1152'\n",
      " 'T-2147482688' 'T36992' 'T-21474872' 'T-2147482432' 'T-2147481664']\n",
      "[nan 'T1']\n",
      "[nan 'T2' 'T8']\n",
      "[nan 'T1']\n",
      "[nan 'T2' 'T8']\n",
      "[nan 'T1']\n",
      "[nan 'T2' 'T8']\n",
      "[nan 'T1']\n",
      "[nan 'T2' 'T8']\n",
      "[nan 'T1']\n",
      "[nan 'T514']\n",
      "[nan 'T1']\n",
      "[nan 'T514']\n",
      "[nan 'T1']\n",
      "[nan 'T514']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n",
      "[nan 'T1']\n"
     ]
    }
   ],
   "source": [
    "for col in tmp_train_cat.columns:\n",
    "    print tmp_train_cat[col].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
