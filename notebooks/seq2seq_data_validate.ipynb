{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import os, sys, random\n",
    "sys.path.append('/Users/matt.meng/dev/seq2seq_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_preprocess import tokenize_title_column, \\\n",
    "process_title_column_by_spacy, create_selected_vocab_dict, process_title_with_token_dict, create_crambled_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the title processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_data_file_name = 'meta_title_data.csv'\n",
    "delimiter = '\\t\\t'\n",
    "data_path = '/Users/matt.meng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt.meng/.virtualenvs/kaggle/lib/python2.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128155, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt.meng/dev/seq2seq_model/data_preprocess.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  data['title_word_counts'], data[processed_column_name] = zip(*data[title_column_name].map(basic_tokenizer))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish the tokenization...\n",
      "finish processing 10000 titles with spaCy, using 8.29 seconds\n",
      "finish processing 20000 titles with spaCy, using 14.19 seconds\n",
      "finish processing 30000 titles with spaCy, using 20.48 seconds\n",
      "finish processing 40000 titles with spaCy, using 28.20 seconds\n",
      "finish processing 50000 titles with spaCy, using 35.06 seconds\n",
      "finish processing 60000 titles with spaCy, using 43.13 seconds\n",
      "finish processing 70000 titles with spaCy, using 52.38 seconds\n",
      "finish processing 80000 titles with spaCy, using 61.76 seconds\n",
      "finish processing 90000 titles with spaCy, using 70.30 seconds\n",
      "finish processing 100000 titles with spaCy, using 80.57 seconds\n",
      "finish processing 110000 titles with spaCy, using 92.72 seconds\n",
      "total 29594 tokens are identified...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, meta_data_file_name), index_col='url', delimiter=delimiter, encoding='utf-8')\n",
    "\n",
    "data.dropna(how='any', inplace=True)\n",
    "data['publisherId'] = data['publisherId'].astype(int).astype(str)\n",
    "valid_publisher_ids = ['1001082', '1023406', '1003264', '1040522', '782', '1006541',\n",
    "                           '1168', '1038583', '1021516', '580', '1020689', '1031851', '1001264',\n",
    "                           '1039208', '1054980', '1018671', '1031841', '1031842', '1031852',\n",
    "                           '1008941', '1003764', '1068057', '1038711', '1002628', '1031853',\n",
    "                           '1021578', '1043813', '1010748', '1040526', '1005092', '612',\n",
    "                           '1003870', '1001156', '1012083', '1017946', '1041479', '1027016',\n",
    "                           '1010488', '1017947', '1010497', '1038582', '1045821', '1020968',\n",
    "                           '1037842', '1029984', '723', '196', '1030941']\n",
    "\n",
    "filtered_data = data.loc[data['publisherId'].isin(valid_publisher_ids), :]\n",
    "unique_filtered_data = filtered_data[~filtered_data.index.duplicated(keep='first')]\n",
    "print unique_filtered_data.shape\n",
    "\n",
    "processed_column_name = 'processed_title'\n",
    "pageView_column_name = 'traffic'\n",
    "filtered_data = tokenize_title_column(unique_filtered_data, processed_column_name, pageView_column_name)\n",
    "\n",
    "    #all_titles, vocab_dict = process_title_column(filtered_data, 'processed_title', 'traffic')\n",
    "all_titles, vocab_dict = process_title_column_by_spacy(filtered_data, 'processed_title', 'traffic', skip_stop_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the `vocab_ditc` content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_pairs = sorted(vocab_dict.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the `token_dict` and the scrambled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UKN_index = len(TOKEN_DICT) - 1\n",
    "token_dict, reverse_token_dict = create_selected_vocab_dict(vocab_dict, UKN_index, token_freq_threshold=4)\n",
    "selected_content = process_title_with_token_dict(all_titles, token_dict, reverse_token_dict, UKN_index, UKN_frac_threshold=0.2)\n",
    "processed_content = create_crambled_training(selected_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the processed pickle and check the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/matt.meng'\n",
    "#pickle_file = 'processed_titles_data.pkl'\n",
    "pickle_file = 'lemmanized_no_stop_words_CBOW_data.pkl'\n",
    "with open(os.path.join(data_path, pickle_file), 'r') as input_file:\n",
    "     data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reverse_token_dict', 'training_list', 'target_list', 'token_dict']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_list = data['training_list']\n",
    "target_list = data['target_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553544\n"
     ]
    }
   ],
   "source": [
    "print len(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[138, 109], [11821, 161], [2425, 279], [872, 28]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = data['titles']\n",
    "token_dict = data['token_dict']\n",
    "reverse_token_dict = data['reverse_token_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_dict.keys()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 50\n",
    "map(reverse_token_dict.get, titles[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "training_titles = data['training_titles']\n",
    "target_titles = data['target_titles']\n",
    "\n",
    "index = 20000\n",
    "print training_titles[index]\n",
    "print target_titles[index]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate the DataGenerator with dual outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preprocess import TOKEN_DICT, _GO, _EOS\n",
    "from data import DataGenerator, process_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'scramble_titles_data.pkl'\n",
    "batch_size = 32\n",
    "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), pickle_file)\n",
    "\n",
    "## the dual_output test\n",
    "#dataGen = DataGenerator(pickle_file_path)\n",
    "dataGen = DataGenerator(pickle_file_path, True)\n",
    "batches = dataGen.generate_sequence(batch_size)\n",
    "training_batch, target_batch = next(batches)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs_, encoder_inputs_length = process_batch([sequence + [TOKEN_DICT[_EOS]] for sequence in training_batch])\n",
    "decoder_inputs_, decoder_inputs_length = process_batch([[TOKEN_DICT[_GO]] + sequence for sequence in target_batch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder_inputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
