{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import time, math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessedTitle(object):\n",
    "    \n",
    "    def __init__(self, index_title, url, pageView):\n",
    "        self.index_title = index_title\n",
    "        self.url = url\n",
    "        self.pageView = pageView\n",
    "        title_array = map(ProcessedTitle.reverse_token_dict.get, self.index_title)\n",
    "        self.title = \" \".join(title_array) \n",
    "        \n",
    "    def create_seq2seq_model_embeddings(self, model):\n",
    "        embedded_input_sets, encode_ouput_sets, hidden_state_sets = model.eval_by_batch([self.index_title])\n",
    "        self.embeddings = []\n",
    "        \n",
    "        # mean_embedded_inputs_, max_embedded_inputs_, min_embedded_inputs_\n",
    "        for embedding in embedded_input_sets:\n",
    "            self.embeddings.append(embedding[0])\n",
    "        # mean_encoder_outputs, max_encoder_outputs, min_encoder_outputs\n",
    "        for embedding in encode_ouput_sets:\n",
    "            self.embeddings.append(embedding[0])\n",
    "        # final_cell_state_, final_hidden_state_\n",
    "        for embedding in hidden_state_sets:\n",
    "            self.embeddings.append(embedding[0])\n",
    "            \n",
    "def get_embedding_vector(sorted_titles, article_index):\n",
    "    sample_vector = sorted_titles[article_index].embeddings[6][:]\n",
    "    sample_vector = np.append(sample_vector, sorted_titles[article_index].embeddings[0][:])    \n",
    "    return sample_vector\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    numerator = sum(a*b for a, b in zip(x,y))\n",
    "    denominator = square_rooted(x) * square_rooted(y)\n",
    "    return numerator / denominator\n",
    "\n",
    "def square_rooted(x):\n",
    "    return math.sqrt(sum([a*a for a in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_titles_pickle_file = 'processed_titles_data.pkl'\n",
    "\n",
    "with open(processed_titles_pickle_file, 'rb') as output_stream:\n",
    "    sorted_titles = pickle.load(output_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 200000 articles are processed...\n"
     ]
    }
   ],
   "source": [
    "tot_counts = len(sorted_titles)\n",
    "print 'total {} articles are processed...'.format(tot_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose the articles index, between [0, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "espn announcer makes insensitive deondre francois reference\n",
      "http://www.msn.com/en-us/sports/ncaafb/espn-announcer-makes-insensitive-deondre-francois-reference/ar-AArAF6O\n",
      "embedding size:  8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print '\\n', sorted_titles[index].title\n",
    "print sorted_titles[index].url\n",
    "\n",
    "embeddings = sorted_titles[index].embeddings\n",
    "print \"embedding size: \", len(embeddings), '\\n'\n",
    "#embeddings[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare the target article with all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL:  http://www.msn.com/en-us/sports/ncaafb/espn-announcer-makes-insensitive-deondre-francois-reference/ar-AArAF6O\n",
      "title:  espn announcer makes insensitive deondre francois reference\n",
      "pageView:  350269\n",
      "\n",
      "\n",
      "all the process takes 17.17 seconds...\n"
     ]
    }
   ],
   "source": [
    "cosine_results, euclidean_results = [], []\n",
    "start_time = time.time()\n",
    "article_index = index\n",
    "print 'URL: ', sorted_titles[article_index].url\n",
    "print 'title: ', sorted_titles[article_index].title\n",
    "print 'pageView: ', sorted_titles[article_index].pageView\n",
    "\n",
    "sample_vector = get_embedding_vector(sorted_titles, article_index)\n",
    "expected_length = len(sample_vector)\n",
    "print \"\\n\"\n",
    "\n",
    "for i in xrange(min(len(sorted_titles), 50000)):\n",
    "    cur_vector = get_embedding_vector(sorted_titles, i)\n",
    "    assert len(cur_vector) == expected_length\n",
    "    \n",
    "    cosine_result = cosine_similarity(cur_vector, sample_vector)\n",
    "    sorted_titles[i].cosine_similarity = cosine_result\n",
    "    cosine_results.append(cosine_result)\n",
    "print 'all the process takes {:.2f} seconds...'.format(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show articlse ranked by the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "http://www.msn.com/en-us/sports/ncaafb/espn-announcer-makes-insensitive-deondre-francois-reference/ar-AArAF6O\n",
      "espn announcer makes insensitive deondre francois reference\n",
      "\n",
      "\n",
      "0.858626555105\n",
      "http://floridastate.247sports.com/ContentGallery/Media-reacts-to-FSU-QB-Deondre-Francois-injury-106872662/2\n",
      "media reacts to fsu qb deondre francois injury\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_threshold = 0.85\n",
    "euclidean_threshold = 4\n",
    "\n",
    "total_counts = 0\n",
    "relevant_titles = []\n",
    "for i in xrange(len(cosine_results)):\n",
    "    if sorted_titles[i].cosine_similarity > cosine_threshold:\n",
    "        total_counts += 1\n",
    "        relevant_titles.append(sorted_titles[i])\n",
    "\n",
    "# sort the titles by the `cosine_similarity`\n",
    "selected_titles = sorted(relevant_titles, key=lambda elem: elem.cosine_similarity, reverse=True)\n",
    "\n",
    "for title in selected_titles:\n",
    "    print title.cosine_similarity\n",
    "    print title.url\n",
    "    print title.title\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
