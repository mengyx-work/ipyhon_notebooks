{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "",
  "signature": "sha256:3ab45149b7b2bd308b0b516a7dc264ab5fdd0b9771f61ef22c144228b42c30d9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "import os, sys, multiprocessing, time, math\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "sys.path.append('/home/matt.meng/seq2seq_model')\n",
      "from graph_model import Seq2SeqModel\n",
      "from utils import create_local_model_path, create_local_log_path\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_seq2seq_model(model_name):\n",
      "    \n",
      "    NUM_THREADS = 2*multiprocessing.cpu_count()-1\n",
      "    COMMON_PATH = os.path.join(os.path.expanduser(\"~\"), 'local_tensorflow_content')\n",
      "    \n",
      "    model_config = {}\n",
      "    model_config['model_name'] = model_name\n",
      "    model_config['restore_model'] = True\n",
      "    model_config['eval_mode'] = True\n",
      "    model_config['model_path'] = create_local_model_path(COMMON_PATH, model_config['model_name'])\n",
      "    model_config['log_path'] = create_local_log_path(COMMON_PATH, model_config['model_name'])\n",
      "    \n",
      "    use_gpu = False\n",
      "    if use_gpu:\n",
      "        model_config['sess_config'] = tf.ConfigProto(log_device_placement=False,\n",
      "                                                     gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5))\n",
      "    else:\n",
      "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # the only way to completely not use GPU\n",
      "        model_config['sess_config'] = tf.ConfigProto(intra_op_parallelism_threads=NUM_THREADS)\n",
      "\n",
      "    model = Seq2SeqModel(**model_config)\n",
      "    return model\n",
      "\n",
      "def collect_key_from_pickle_file(titles_pickle_file, title_key):\n",
      "    pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "    with open(pickle_file_path, 'rb') as input_stream:\n",
      "        data = pickle.load(input_stream)\n",
      "    return data[title_key]\n",
      "\n",
      "\n",
      "def collect_multi_keys_from_pickle_file(titles_pickle_file, key_dict):\n",
      "    pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "    with open(pickle_file_path, 'rb') as input_stream:\n",
      "        data = pickle.load(input_stream)\n",
      "        \n",
      "    content_dict = {}\n",
      "    for key in key_dict.keys():\n",
      "        content_dict[key] = data[key_dict[key]]\n",
      "    return content_dict\n",
      "\n",
      "\n",
      "class ProcessedTitle(object):\n",
      "    \n",
      "    def __init__(self, index_title, url, pageView):\n",
      "        self.index_title = index_title\n",
      "        self.url = url\n",
      "        self.pageView = pageView\n",
      "        title_array = map(ProcessedTitle.reverse_token_dict.get, self.index_title)\n",
      "        self.title = \" \".join(title_array) \n",
      "        \n",
      "    def create_seq2seq_model_embeddings(self, word2vec_model):\n",
      "        embedded_input_sets, encode_ouput_sets, hidden_state_sets = word2vec_model.eval_by_batch([self.index_title])\n",
      "        self.embeddings = []\n",
      "        \n",
      "        for embedding in embedded_input_sets:\n",
      "            self.embeddings.append(embedding[0])\n",
      "        for embedding in encode_ouput_sets:\n",
      "            self.embeddings.append(embedding[0])\n",
      "        for embedding in hidden_state_sets:\n",
      "            self.embeddings.append(embedding[0])\n",
      "        '''\n",
      "        self.mean_embedded_inputs = embedded_input_sets[0]\n",
      "        self.max_embedded_inputs = embedded_input_sets[1]\n",
      "        self.min_embedded_inputs = embedded_input_sets[2]\n",
      "        '''\n",
      "        \n",
      "\n",
      "def predict_titles_with_seq2seq(content_dict, model, display_couner=1000, count_limit=None):\n",
      "    processed_titles = []\n",
      "    cur_time = time.time()\n",
      "    if count_limit is None:\n",
      "        count_limit = len(content_dict['titles'])\n",
      "    else:\n",
      "        count_limit = min(count_limit, len(content_dict['titles']))\n",
      "    ProcessedTitle.reverse_token_dict = content_dict['reverse_token_dict']\n",
      "    for i in xrange(count_limit):\n",
      "        title = ProcessedTitle(index_title=content_dict['titles'][i],\n",
      "                               url=content_dict['url'][i],\n",
      "                               pageView=content_dict['pageView'][i])\n",
      "        title.create_seq2seq_model_embeddings(model)\n",
      "        processed_titles.append(title)\n",
      "        if i != 0 and i % display_couner == 0:\n",
      "            print \"processing {} titles using {:.2f} seconds\".format(display_couner, time.time() - cur_time)\n",
      "            cur_time = time.time()\n",
      "    return processed_titles\n",
      "\n",
      "\n",
      "def square_rooted(x):\n",
      "    return math.sqrt(sum([a*a for a in x]))\n",
      " \n",
      "def euclidean_distance(x,y):\n",
      "     return math.sqrt(sum(math.pow(a - b, 2) for a, b in zip(x, y)))\n",
      "\n",
      "def manhattan_distance(x,y): \n",
      "    return sum(abs(a - b) for a,b in zip(x,y))\n",
      "\n",
      "def cosine_similarity(x, y):\n",
      "    numerator = sum(a*b for a, b in zip(x,y))\n",
      "    denominator = square_rooted(x) * square_rooted(y)\n",
      "    #denominator = (square_rooted(x) + square_rooted(y))\n",
      "    return numerator / denominator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "\n",
      "titles_pickle_file = 'scramble_titles_data.pkl'\n",
      "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "with open(pickle_file_path, 'rb') as input_stream:\n",
      "    data = pickle.load(input_stream)\n",
      "data.keys()\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "'\\n\\ntitles_pickle_file = \\'scramble_titles_data.pkl\\'\\npickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\\n\\nwith open(pickle_file_path, \\'rb\\') as input_stream:\\n    data = pickle.load(input_stream)\\ndata.keys()\\n'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles_pickle_file = 'scramble_titles_data.pkl'\n",
      "model_name = 'seq2seq_model'\n",
      "#expected_keys = {\"titles\": 'titles', \"url\": 'url', 'pageView': \"pageViw\", 'reverse_token_dict': 'reverse_token_dict'}\n",
      "dual_output_expected_keys = {\"titles\": 'target_titles', \"url\": 'url', 'pageView': \"pageViw\", 'reverse_token_dict': 'reverse_token_dict'}\n",
      "\n",
      "content_dict = collect_multi_keys_from_pickle_file(titles_pickle_file, dual_output_expected_keys)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seq2seq_model = build_seq2seq_model(model_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "warning, more than one model meta file is found in /home/matt.meng/local_tensorflow_content/seq2seq_model\n",
        "INFO:tensorflow:Restoring parameters from /home/matt.meng/local_tensorflow_content/seq2seq_model/models-410000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:tensorflow:Restoring parameters from /home/matt.meng/local_tensorflow_content/seq2seq_model/models-410000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "restore eval models from /home/matt.meng/local_tensorflow_content/seq2seq_model\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processed_titles = predict_titles_with_seq2seq(content_dict, seq2seq_model, count_limit=10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing 1000 titles using 4.86 seconds\n",
        "processing 1000 titles using 4.73 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 4.96 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 5.07 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 4.97 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 4.97 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 5.31 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 5.26 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 5.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sorted_titles = sorted(processed_titles, key=lambda x: x.pageView, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 390\n",
      "print sorted_titles[index].title\n",
      "#print sorted_titles[index].max_vector\n",
      "#print sorted_titles[index].min_vector\n",
      "embeddings = sorted_titles[index].embeddings\n",
      "print len(embeddings)\n",
      "embeddings[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bob schieffer calls scaramucci interview embarrassing\n",
        "8\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 201,
       "text": [
        "array([ -1.85343230e+00,  -8.16075981e-01,  -1.90038070e-01,\n",
        "        -7.90299952e-01,  -9.70073938e-01,  -2.83473253e-01,\n",
        "        -4.80699003e-01,  -1.19032264e+00,  -2.61046678e-01,\n",
        "         1.00955996e-03,  -7.56273150e-01,  -1.05577600e+00,\n",
        "        -1.39350760e+00,  -7.47439146e-01,  -1.09556758e+00,\n",
        "        -1.94705343e+00,  -7.47598588e-01,  -1.15458870e+00,\n",
        "        -9.42326128e-01,  -2.12097239e+00,  -1.44768703e+00,\n",
        "        -3.41636688e-02,  -6.21033788e-01,  -1.11036623e+00,\n",
        "        -2.55732834e-01,  -1.07366848e+00,  -2.26967978e+00,\n",
        "        -5.77315629e-01,  -8.33563805e-01,  -1.92762852e+00,\n",
        "        -1.71288168e+00,  -1.80406523e+00,  -9.18705225e-01,\n",
        "        -3.34353507e-01,  -1.82067478e+00,  -1.80552614e+00,\n",
        "        -1.19437671e+00,  -1.01218235e+00,   2.85271741e-03,\n",
        "        -1.29465115e+00,  -1.34766746e+00,  -1.30234897e+00,\n",
        "        -1.19480479e+00,  -1.61043465e+00,  -1.32773328e+00,\n",
        "        -1.95099330e+00,  -2.97922909e-01,  -1.40397286e+00,\n",
        "        -1.45350587e+00,  -1.57106614e+00,  -1.22346973e+00,\n",
        "        -6.67289793e-02,  -7.62235105e-01,  -3.34936589e-01,\n",
        "        -1.70138109e+00,  -4.82228369e-01,  -3.74977082e-01,\n",
        "        -3.88996392e-01,  -5.43156564e-01,  -1.09780121e+00,\n",
        "        -2.20722437e+00,  -5.85240424e-01,  -1.20351136e+00,\n",
        "        -1.09893882e+00,  -2.65813375e+00,  -7.06579924e-01,\n",
        "        -8.04276168e-01,  -8.77398849e-01,   1.57831446e-03,\n",
        "        -1.88382196e+00,  -7.01957345e-01,  -1.23316967e+00,\n",
        "        -1.37585735e+00,  -1.35275185e-01,  -1.19281852e+00,\n",
        "        -2.04449892e+00,  -9.73890185e-01,  -1.86155176e+00,\n",
        "        -1.72983360e+00,  -1.07065105e+00,  -1.21404797e-01,\n",
        "        -7.39609778e-01,  -4.93123114e-01,  -7.65483081e-01,\n",
        "        -1.87238610e+00,  -5.14093697e-01,  -5.07013984e-02,\n",
        "        -1.33324391e-03,  -1.40351725e+00,  -1.94898510e+00,\n",
        "        -1.89455032e+00,  -1.03907776e+00,  -5.14772773e-01,\n",
        "        -3.74516010e-01,  -6.44794583e-01,  -2.07292700e+00,\n",
        "        -1.18577206e+00,  -8.61096382e-01,  -2.09281635e+00,\n",
        "        -1.08388817e+00,  -3.30878079e-01,  -3.89142036e-01,\n",
        "        -3.63444149e-01,  -1.68345594e+00,  -7.79469609e-01,\n",
        "        -1.93015420e+00,  -1.12560463e+00,  -1.17272937e+00,\n",
        "        -7.11001575e-01,  -1.69962513e+00,  -1.58068454e+00,\n",
        "        -7.96132147e-01,  -1.47723007e+00,  -1.50354993e+00,\n",
        "        -1.82155991e+00,  -5.03077125e-03,  -1.10868657e+00,\n",
        "        -1.27684307e+00,  -1.46177065e+00,  -9.67050195e-01,\n",
        "        -1.14978766e+00,  -9.93068278e-01,  -1.04072642e+00,\n",
        "        -2.71055967e-01,  -2.31186056e+00,  -1.30699599e+00,\n",
        "        -1.32385850e+00,  -1.63201535e+00], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_embedding_vector(sorted_titles, article_index):\n",
      "    embedding_index = 6\n",
      "    #sample_vector = sorted_titles[article_index].embeddings[embedding_index]\n",
      "\n",
      "    sample_vector = sorted_titles[article_index].embeddings[embedding_index][:]\n",
      "    sample_vector = np.append(sample_vector, sorted_titles[article_index].embeddings[embedding_index+1][:])\n",
      "    sample_vector = np.append(sample_vector, sorted_titles[article_index].embeddings[0][:])\n",
      "    \n",
      "    return sample_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "cosine_results, euclidean_results = [], []\n",
      "start_time = time.time()\n",
      "article_index = 390\n",
      "print sorted_titles[article_index].url\n",
      "print sorted_titles[article_index].title\n",
      "print len(sample_vector)\n",
      "print \"\\n\"\n",
      "sample_vector = get_embedding_vector(sorted_titles, article_index)\n",
      "expected_length = len(sample_vector)\n",
      "\n",
      "#sample_vector = np.append(sample_vector, sorted_titles[index].min_vector[:])\n",
      "#sample_vector = np.append(sample_vector, sorted_titles[index].mean_vector[:])\n",
      "#sample_vector = sorted_titles[index].mean_vector[:]\n",
      "\n",
      "\n",
      "#sample_vector = sorted_titles[index].mean_vector[:]\n",
      "for i in xrange(min(len(sorted_titles), 10000)):\n",
      "    cur_vector = get_embedding_vector(sorted_titles, i)\n",
      "    assert len(cur_vector) == expected_length\n",
      "    \n",
      "    cosine_result = cosine_similarity(cur_vector, sample_vector)\n",
      "    euclidean_result = euclidean_distance(cur_vector, sample_vector)\n",
      "    sorted_titles[i].cosine_similarity = cosine_result\n",
      "    cosine_results.append(cosine_result)\n",
      "    euclidean_results.append(euclidean_result)\n",
      "print 'all the process takes {:.2f} seconds...'.format(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.cbsnews.com/news/bob-schieffer-anthony-scaramucci-interview-embarrassing/\n",
        "bob schieffer calls scaramucci interview embarrassing\n",
        "256\n",
        "\n",
        "\n",
        "all the process takes 6.45 seconds..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "plt.hist(cosine_results, bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 197,
       "text": [
        "(array([   3.,    0.,    0.,    0.,    3.,    0.,    4.,    1.,    4.,\n",
        "           3.,    4.,    3.,   10.,    7.,   16.,   28.,   32.,   37.,\n",
        "          42.,   38.,   51.,   81.,  110.,   93.,  100.,  144.,  156.,\n",
        "         169.,  248.,  211.,  182.,  212.,  306.,  255.,  324.,  318.,\n",
        "         309.,  290.,  284.,  338.,  325.,  316.,  330.,  391.,  313.,\n",
        "         358.,  372.,  349.,  293.,  294.,  284.,  283.,  214.,  224.,\n",
        "         242.,  181.,  126.,  148.,  115.,   83.,   69.,   53.,   56.,\n",
        "          55.,   39.,   15.,   14.,   10.,   18.,    4.,    4.,    2.,\n",
        "           1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
        "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
        "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    3.]),\n",
        " array([ 0.2896598 ,  0.2967632 ,  0.3038666 ,  0.31097   ,  0.31807341,\n",
        "         0.32517681,  0.33228021,  0.33938361,  0.34648701,  0.35359042,\n",
        "         0.36069382,  0.36779722,  0.37490062,  0.38200402,  0.38910743,\n",
        "         0.39621083,  0.40331423,  0.41041763,  0.41752103,  0.42462444,\n",
        "         0.43172784,  0.43883124,  0.44593464,  0.45303804,  0.46014145,\n",
        "         0.46724485,  0.47434825,  0.48145165,  0.48855506,  0.49565846,\n",
        "         0.50276186,  0.50986526,  0.51696866,  0.52407207,  0.53117547,\n",
        "         0.53827887,  0.54538227,  0.55248567,  0.55958908,  0.56669248,\n",
        "         0.57379588,  0.58089928,  0.58800268,  0.59510609,  0.60220949,\n",
        "         0.60931289,  0.61641629,  0.62351969,  0.6306231 ,  0.6377265 ,\n",
        "         0.6448299 ,  0.6519333 ,  0.6590367 ,  0.66614011,  0.67324351,\n",
        "         0.68034691,  0.68745031,  0.69455371,  0.70165712,  0.70876052,\n",
        "         0.71586392,  0.72296732,  0.73007072,  0.73717413,  0.74427753,\n",
        "         0.75138093,  0.75848433,  0.76558773,  0.77269114,  0.77979454,\n",
        "         0.78689794,  0.79400134,  0.80110474,  0.80820815,  0.81531155,\n",
        "         0.82241495,  0.82951835,  0.83662175,  0.84372516,  0.85082856,\n",
        "         0.85793196,  0.86503536,  0.87213876,  0.87924217,  0.88634557,\n",
        "         0.89344897,  0.90055237,  0.90765577,  0.91475918,  0.92186258,\n",
        "         0.92896598,  0.93606938,  0.94317278,  0.95027619,  0.95737959,\n",
        "         0.96448299,  0.97158639,  0.97868979,  0.9857932 ,  0.9928966 ,  1.        ]),\n",
        " <a list of 100 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff351647b90>"
       ]
      }
     ],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "cosine_threshold = 0.79\n",
      "euclidean_threshold = 4\n",
      "\n",
      "'''\n",
      "for i in xrange(len(euclidean_results)):\n",
      "    if euclidean_results[i] < euclidean_threshold:\n",
      "        print euclidean_results[i]\n",
      "        print sorted_vecor[i][0], sorted_vecor[i][1]['title_string']\n",
      "'''\n",
      "print '\\n \\n'\n",
      "\n",
      "#'''        \n",
      "for i in xrange(len(cosine_results)):\n",
      "    if sorted_titles[i].cosine_similarity > cosine_threshold:\n",
      "        print sorted_titles[i].cosine_similarity\n",
      "        print sorted_titles[i].url\n",
      "        print sorted_titles[i].title\n",
      "#'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " \n",
        "\n",
        "1.0\n",
        "http://www.chicagotribune.com/lifestyles/askamy/ct-ask-amy-ae-0725-20170724-story.html\n",
        "restaurant friends have a score to settle\n",
        "0.795831787805\n",
        "http://metro.co.uk/2016/05/24/masturbation-month-how-to-have-better-orgasms-5900837/\n",
        "masturbation month how to have better orgasms\n",
        "0.805968024477\n",
        "http://articles.latimes.com/2012/sep/27/opinion/la-ed-carmageddon-20120927\n",
        "l a drivers do not _UNK _UNK\n",
        "1.0\n",
        "http://www.freep.com/story/life/advice/2017/07/23/ask-amy-restaurants/103944710/\n",
        "restaurant friends have a score to settle\n",
        "1.0\n",
        "http://www.chicagotribune.com/lifestyles/askamy/ct-ask-amy-ae-0725-20170724-story,amp.html\n",
        "restaurant friends have a score to settle\n",
        "0.793406513811\n",
        "https://www.usatoday.com/story/tech/talkingtech/2017/06/21/new-snapchat-maps-find-friends/103070952/\n",
        "new on snapchat maps to find friends\n",
        "0.794868777785\n",
        "http://www.huffingtonpost.com/chrystal-bougon/do-not-settle-curvy-girls_b_4715263.html\n",
        "do not settle curvy girls\n"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processed_titles[2].title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word2vec_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles_pickle_file = 'lemmanized_no_stop_words_processed_titles.pkl'\n",
      "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "with open(pickle_file_path, 'rb') as input_stream:\n",
      "    data = pickle.load(input_stream)\n",
      "\n",
      "print data.keys()\n",
      "titles = data['titles']\n",
      "reverse_token_dict = data['reverse_token_dict']\n",
      "title_urls = data['url']\n",
      "title_pageViews = data['pageViw']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(titles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "work on the scrambled data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles_pickle_file = 'lemmanized_no_stop_words_scrambled_titles.pkl'\n",
      "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "with open(pickle_file_path, 'rb') as input_stream:\n",
      "    tmp_data = pickle.load(input_stream)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "content_dict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tmp_data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(tmp_data['target_titles'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp_data['target_titles'][:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}