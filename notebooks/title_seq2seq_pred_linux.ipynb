{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "",
  "signature": "sha256:5f1a03e03bda723c85ac91d509fd29702fc2a57a77c20c4d77c3a8b9c59268d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "import os, sys, multiprocessing, time, math\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "sys.path.append('/home/matt.meng/seq2seq_model')\n",
      "from graph_model import Seq2SeqModel\n",
      "from utils import create_local_model_path, create_local_log_path\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline  \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_seq2seq_model(model_name):\n",
      "    \n",
      "    NUM_THREADS = 2*multiprocessing.cpu_count()-1\n",
      "    COMMON_PATH = os.path.join(os.path.expanduser(\"~\"), 'local_tensorflow_content')\n",
      "    \n",
      "    model_config = {}\n",
      "    model_config['model_name'] = model_name\n",
      "    model_config['restore_model'] = True\n",
      "    model_config['eval_mode'] = True\n",
      "    model_config['model_path'] = create_local_model_path(COMMON_PATH, model_config['model_name'])\n",
      "    model_config['log_path'] = create_local_log_path(COMMON_PATH, model_config['model_name'])\n",
      "    \n",
      "    use_gpu = False\n",
      "    if use_gpu:\n",
      "        model_config['sess_config'] = tf.ConfigProto(log_device_placement=False,\n",
      "                                                     gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5))\n",
      "    else:\n",
      "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # the only way to completely not use GPU\n",
      "        model_config['sess_config'] = tf.ConfigProto(intra_op_parallelism_threads=NUM_THREADS)\n",
      "\n",
      "    model = Seq2SeqModel(**model_config)\n",
      "    return model\n",
      "\n",
      "def collect_key_from_pickle_file(titles_pickle_file, title_key):\n",
      "    pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "    with open(pickle_file_path, 'rb') as input_stream:\n",
      "        data = pickle.load(input_stream)\n",
      "    return data[title_key]\n",
      "\n",
      "\n",
      "def collect_multi_keys_from_pickle_file(titles_pickle_file, key_dict):\n",
      "    pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "    with open(pickle_file_path, 'rb') as input_stream:\n",
      "        data = pickle.load(input_stream)\n",
      "        \n",
      "    content_dict = {}\n",
      "    for key in key_dict.keys():\n",
      "        content_dict[key] = data[key_dict[key]]\n",
      "    return content_dict\n",
      "\n",
      "\n",
      "class ProcessedTitle(object):\n",
      "    \n",
      "    def __init__(self, index_title, url, pageView):\n",
      "        self.index_title = index_title\n",
      "        self.url = url\n",
      "        self.pageView = pageView\n",
      "        title_array = map(ProcessedTitle.reverse_token_dict.get, self.index_title)\n",
      "        self.title = \" \".join(title_array) \n",
      "        \n",
      "    def create_seq2seq_model_embeddings(self, word2vec_model):\n",
      "        embedded_input_sets, encode_ouput_sets, hidden_state_sets = word2vec_model.eval_by_batch([self.index_title])\n",
      "        self.embeddings = []\n",
      "        \n",
      "        # mean_embedded_inputs_, max_embedded_inputs_, min_embedded_inputs_\n",
      "        for embedding in embedded_input_sets:\n",
      "            self.embeddings.append(embedding[0])\n",
      "        # mean_encoder_outputs, max_encoder_outputs, min_encoder_outputs\n",
      "        for embedding in encode_ouput_sets:\n",
      "            self.embeddings.append(embedding[0])\n",
      "        # final_cell_state_, final_hidden_state_\n",
      "        for embedding in hidden_state_sets:\n",
      "            self.embeddings.append(embedding[0])\n",
      "        '''\n",
      "        self.mean_embedded_inputs = embedded_input_sets[0]\n",
      "        self.max_embedded_inputs = embedded_input_sets[1]\n",
      "        self.min_embedded_inputs = embedded_input_sets[2]\n",
      "        '''\n",
      "        \n",
      "\n",
      "def predict_titles_with_seq2seq(content_dict, model, display_couner=1000, count_limit=None):\n",
      "    processed_titles = []\n",
      "    cur_time = time.time()\n",
      "    if count_limit is None:\n",
      "        count_limit = len(content_dict['titles'])\n",
      "    else:\n",
      "        count_limit = min(count_limit, len(content_dict['titles']))\n",
      "    ProcessedTitle.reverse_token_dict = content_dict['reverse_token_dict']\n",
      "    for i in xrange(count_limit):\n",
      "        title = ProcessedTitle(index_title=content_dict['titles'][i],\n",
      "                               url=content_dict['url'][i],\n",
      "                               pageView=content_dict['pageView'][i])\n",
      "        title.create_seq2seq_model_embeddings(model)\n",
      "        processed_titles.append(title)\n",
      "        if i != 0 and i % display_couner == 0:\n",
      "            print \"processing {} titles using {:.2f} seconds\".format(display_couner, time.time() - cur_time)\n",
      "            cur_time = time.time()\n",
      "    return processed_titles\n",
      "\n",
      "\n",
      "def get_dict_keys(titles_pickle_file):\n",
      "    pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "    with open(pickle_file_path, 'rb') as input_stream:\n",
      "        data = pickle.load(input_stream)\n",
      "    for key in data:\n",
      "        print \"for the key: {}, totale {} entries\".format(key, len(data[key]))\n",
      "        \n",
      "        \n",
      "def square_rooted(x):\n",
      "    return math.sqrt(sum([a*a for a in x]))\n",
      " \n",
      "def euclidean_distance(x,y):\n",
      "     return math.sqrt(sum(math.pow(a - b, 2) for a, b in zip(x, y)))\n",
      "\n",
      "def manhattan_distance(x,y): \n",
      "    return sum(abs(a - b) for a,b in zip(x,y))\n",
      "\n",
      "def cosine_similarity(x, y):\n",
      "    numerator = sum(a*b for a, b in zip(x,y))\n",
      "    denominator = square_rooted(x) * square_rooted(y)\n",
      "    #denominator = (square_rooted(x) + square_rooted(y))\n",
      "    return numerator / denominator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "\n",
      "titles_pickle_file = 'scramble_titles_data.pkl'\n",
      "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "with open(pickle_file_path, 'rb') as input_stream:\n",
      "    data = pickle.load(input_stream)\n",
      "data.keys()\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "'\\n\\ntitles_pickle_file = \\'scramble_titles_data.pkl\\'\\npickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\\n\\nwith open(pickle_file_path, \\'rb\\') as input_stream:\\n    data = pickle.load(input_stream)\\ndata.keys()\\n'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles_pickle_file = 'full_dedup_scrambled_1_token_thres_8_titles.pkl'\n",
      "model_name = 'seq2seq_full_dedup_raw_rnn_scramble_1_token_thres_8'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_dict_keys(titles_pickle_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "for the key: url, totale 548966 entries\n",
        "for the key: target_titles, totale 548966 entries\n",
        "for the key: token_dict, totale 104824 entries\n",
        "for the key: training_titles, totale 548966 entries\n",
        "for the key: reverse_token_dict, totale 28601 entries\n",
        "for the key: titles, totale 548966 entries\n",
        "for the key: pageViw, totale 548966 entries\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#expected_keys = {\"titles\": 'titles', \"url\": 'url', 'pageView': \"pageViw\", 'reverse_token_dict': 'reverse_token_dict'}\n",
      "dual_output_expected_keys = {\"titles\": 'target_titles', \"url\": 'url', 'pageView': \"pageViw\", 'reverse_token_dict': 'reverse_token_dict'}\n",
      "\n",
      "content_dict = collect_multi_keys_from_pickle_file(titles_pickle_file, dual_output_expected_keys)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seq2seq_model = build_seq2seq_model(model_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "warning, more than one model meta file is found in /home/matt.meng/local_tensorflow_content/seq2seq_full_dedup_raw_rnn_scramble_1_token_thres_8\n",
        "INFO:tensorflow:Restoring parameters from /home/matt.meng/local_tensorflow_content/seq2seq_full_dedup_raw_rnn_scramble_1_token_thres_8/models-640000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:tensorflow:Restoring parameters from /home/matt.meng/local_tensorflow_content/seq2seq_full_dedup_raw_rnn_scramble_1_token_thres_8/models-640000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "restore eval models from /home/matt.meng/local_tensorflow_content/seq2seq_full_dedup_raw_rnn_scramble_1_token_thres_8\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processed_titles = predict_titles_with_seq2seq(content_dict, seq2seq_model, display_couner=5000, count_limit=50000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processing 1000 titles using 3.15 seconds\n",
        "processing 1000 titles using 3.10 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.09 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.09 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.08 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.09 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.08 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.40 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.09 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.08 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.09 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.33 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.39 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.39 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.38 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.38 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.38 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.36 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.39 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.38 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.36 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.37 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.36 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.34 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.34 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.35 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.35 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.34 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.34 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.35 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.35 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.35 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.43 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.61 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.64 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.64 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.62 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.61 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.62 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.64 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "processing 1000 titles using 3.64 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "sorted_titles = sorted(processed_titles, key=lambda x: x.pageView, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "index = 40\n",
      "print sorted_titles[index].title\n",
      "#print sorted_titles[index].max_vector\n",
      "#print sorted_titles[index].min_vector\n",
      "embeddings = sorted_titles[index].embeddings\n",
      "print len(embeddings)\n",
      "#embeddings[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "htc u## review more than just gimmicks\n",
        "8\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_embedding_vector(sorted_titles, article_index):\n",
      "    embedding_index = 6\n",
      "    #sample_vector = sorted_titles[article_index].embeddings[0][:]\n",
      "\n",
      "    sample_vector = sorted_titles[article_index].embeddings[embedding_index][:]\n",
      "    sample_vector = np.append(sample_vector, sorted_titles[article_index].embeddings[embedding_index+1][:])\n",
      "    sample_vector = np.append(sample_vector, sorted_titles[article_index].embeddings[0][:])\n",
      "    \n",
      "    return sample_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(sorted_titles[20].embeddings)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 58,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "cosine_results, euclidean_results = [], []\n",
      "start_time = time.time()\n",
      "article_index = index\n",
      "print sorted_titles[article_index].url\n",
      "print sorted_titles[article_index].title\n",
      "sample_vector = get_embedding_vector(sorted_titles, article_index)\n",
      "expected_length = len(sample_vector)\n",
      "print \"sample vector length:\", len(sample_vector)\n",
      "print \"\\n\"\n",
      "\n",
      "#sample_vector = np.append(sample_vector, sorted_titles[index].min_vector[:])\n",
      "#sample_vector = np.append(sample_vector, sorted_titles[index].mean_vector[:])\n",
      "#sample_vector = sorted_titles[index].mean_vector[:]\n",
      "\n",
      "\n",
      "#sample_vector = sorted_titles[index].mean_vector[:]\n",
      "for i in xrange(min(len(sorted_titles), 10000)):\n",
      "    cur_vector = get_embedding_vector(sorted_titles, i)\n",
      "    assert len(cur_vector) == expected_length\n",
      "    \n",
      "    cosine_result = cosine_similarity(cur_vector, sample_vector)\n",
      "    euclidean_result = euclidean_distance(cur_vector, sample_vector)\n",
      "    sorted_titles[i].cosine_similarity = cosine_result\n",
      "    cosine_results.append(cosine_result)\n",
      "    euclidean_results.append(euclidean_result)\n",
      "print 'all the process takes {:.2f} seconds...'.format(time.time() - start_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "https://www.engadget.com/2017/07/29/htc-u11-review/\n",
        "htc u## review more than just gimmicks\n",
        "sample vector length: 768\n",
        "\n",
        "\n",
        "all the process takes 9.80 seconds..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "plt.hist(cosine_results, bins=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "(array([   2.,    3.,    2.,    4.,    4.,    8.,    3.,   12.,   14.,\n",
        "          11.,   23.,   21.,   30.,   36.,   45.,   75.,  105.,  106.,\n",
        "         156.,  175.,  222.,  231.,  305.,  341.,  366.,  401.,  423.,\n",
        "         436.,  474.,  442.,  486.,  483.,  497.,  451.,  437.,  429.,\n",
        "         421.,  382.,  348.,  289.,  283.,  227.,  181.,  157.,  127.,\n",
        "          90.,   69.,   54.,   41.,   17.,   17.,    5.,   12.,    8.,\n",
        "           4.,    1.,    2.,    1.,    2.,    1.,    0.,    0.,    1.,\n",
        "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
        "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
        "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
        "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.]),\n",
        " array([ 0.34982946,  0.35633117,  0.36283287,  0.36933458,  0.37583628,\n",
        "         0.38233799,  0.3888397 ,  0.3953414 ,  0.40184311,  0.40834481,\n",
        "         0.41484652,  0.42134822,  0.42784993,  0.43435163,  0.44085334,\n",
        "         0.44735504,  0.45385675,  0.46035845,  0.46686016,  0.47336187,\n",
        "         0.47986357,  0.48636528,  0.49286698,  0.49936869,  0.50587039,\n",
        "         0.5123721 ,  0.5188738 ,  0.52537551,  0.53187721,  0.53837892,\n",
        "         0.54488062,  0.55138233,  0.55788404,  0.56438574,  0.57088745,\n",
        "         0.57738915,  0.58389086,  0.59039256,  0.59689427,  0.60339597,\n",
        "         0.60989768,  0.61639938,  0.62290109,  0.62940279,  0.6359045 ,\n",
        "         0.6424062 ,  0.64890791,  0.65540962,  0.66191132,  0.66841303,\n",
        "         0.67491473,  0.68141644,  0.68791814,  0.69441985,  0.70092155,\n",
        "         0.70742326,  0.71392496,  0.72042667,  0.72692837,  0.73343008,\n",
        "         0.73993179,  0.74643349,  0.7529352 ,  0.7594369 ,  0.76593861,\n",
        "         0.77244031,  0.77894202,  0.78544372,  0.79194543,  0.79844713,\n",
        "         0.80494884,  0.81145054,  0.81795225,  0.82445396,  0.83095566,\n",
        "         0.83745737,  0.84395907,  0.85046078,  0.85696248,  0.86346419,\n",
        "         0.86996589,  0.8764676 ,  0.8829693 ,  0.88947101,  0.89597271,\n",
        "         0.90247442,  0.90897612,  0.91547783,  0.92197954,  0.92848124,\n",
        "         0.93498295,  0.94148465,  0.94798636,  0.95448806,  0.96098977,\n",
        "         0.96749147,  0.97399318,  0.98049488,  0.98699659,  0.99349829,  1.        ]),\n",
        " <a list of 100 Patch objects>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxkfpnG4AAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f29a7d2a390>"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "cosine_threshold = 0.7\n",
      "euclidean_threshold = 4\n",
      "\n",
      "'''\n",
      "for i in xrange(len(euclidean_results)):\n",
      "    if euclidean_results[i] < euclidean_threshold:\n",
      "        print euclidean_results[i]\n",
      "        print sorted_vecor[i][0], sorted_vecor[i][1]['title_string']\n",
      "'''\n",
      "print '\\n \\n'\n",
      "\n",
      "#'''\n",
      "total_counts = 0\n",
      "for i in xrange(len(cosine_results)):\n",
      "    if sorted_titles[i].cosine_similarity > cosine_threshold:\n",
      "        total_counts += 1\n",
      "        print sorted_titles[i].cosine_similarity\n",
      "        print sorted_titles[i].url\n",
      "        print sorted_titles[i].title\n",
      "        print \"\\n\"\n",
      "#'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        " \n",
        "\n",
        "1.0\n",
        "https://www.engadget.com/2017/07/29/htc-u11-review/\n",
        "htc u## review more than just gimmicks\n",
        "\n",
        "\n",
        "0.713412767144\n",
        "http://www.msn.com/en-us/news/politics/polls-show-trump-cratering-not-so-fast/ar-AAqxMuI\n",
        "polls show trump _UNK not so fast\n",
        "\n",
        "\n",
        "0.706127685168\n",
        "http://www.vulture.com/2017/08/best-podcasts-of-2017-so-far.html\n",
        "the best podcasts of ## so far\n",
        "\n",
        "\n",
        "0.702204946637\n",
        "https://www.bloomberg.com/news/articles/2017-09-01/senate-official-complicates-any-new-obamacare-repeal-effort\n",
        "repealing obamacare just got even more complicated\n",
        "\n",
        "\n",
        "0.730702219353\n",
        "http://www.complex.com/pop-culture/netflix-new-releases-this-month\n",
        "all the netflix new releases for may\n",
        "\n",
        "\n",
        "0.719002460093\n",
        "https://www.usatoday.com/story/money/cars/2017/08/19/mercedes-benz-debuts-new-concept-30-s-flair/582785001/\n",
        "mercedes-benz debuts new concept with ##s flair\n",
        "\n",
        "\n",
        "0.754153605646\n",
        "https://www.engadget.com/2017/08/31/sony-wh-1000xm2-wireless-headphones/\n",
        "sony made its best headphones even better\n",
        "\n",
        "\n",
        "0.727733254749\n",
        "http://pix11.com/2017/08/30/more-than-711-million-email-addresses-leaked/\n",
        "more than ## million email addresses leaked\n",
        "\n",
        "\n",
        "0.719637996627\n",
        "https://www.engadget.com/2017/06/26/amazon-echo-show-review/\n",
        "amazon echo show review seeing is believing\n",
        "\n",
        "\n",
        "0.704690144878\n",
        "https://www.engadget.com/2017/09/12/apple-watch-heart-rate-tracking-update/\n",
        "apple details new _UNK features for watch\n",
        "\n",
        "\n",
        "0.700500810298\n",
        "http://www.businessinsider.com/stock-market-news-4-charts-that-should-scare-you-2017-8\n",
        "## stock charts that should scare you\n",
        "\n",
        "\n",
        "0.737048896524\n",
        "https://www.sny.tv/mets/news/teams-reportedly-showing-more-interest-in-cabrera/249674584\n",
        "teams reportedly showing more interest in cabrera\n",
        "\n",
        "\n",
        "0.702076044093\n",
        "http://www.businessinsider.com/amazon-and-apple-both-want-james-bond-2017-9\n",
        "amazon and apple both want james bond\n",
        "\n",
        "\n",
        "0.721604313917\n",
        "http://www.hollywoodreporter.com/review/better-things-season-2-review-1038153\n",
        "better things season ## tv review\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print total_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "67\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "processed_titles[2].title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word2vec_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles_pickle_file = 'lemmanized_no_stop_words_processed_titles.pkl'\n",
      "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "with open(pickle_file_path, 'rb') as input_stream:\n",
      "    data = pickle.load(input_stream)\n",
      "\n",
      "print data.keys()\n",
      "titles = data['titles']\n",
      "reverse_token_dict = data['reverse_token_dict']\n",
      "title_urls = data['url']\n",
      "title_pageViews = data['pageViw']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(titles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "work on the scrambled data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles_pickle_file = 'lemmanized_no_stop_words_scrambled_titles.pkl'\n",
      "pickle_file_path = os.path.join(os.path.expanduser(\"~\"), titles_pickle_file)\n",
      "\n",
      "with open(pickle_file_path, 'rb') as input_stream:\n",
      "    tmp_data = pickle.load(input_stream)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "content_dict.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print tmp_data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(tmp_data['target_titles'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp_data['target_titles'][:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}