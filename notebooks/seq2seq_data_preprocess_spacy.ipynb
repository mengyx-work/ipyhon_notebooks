{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, json, time, re\n",
    "import random, collections, cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matp    title_df = process_raw_data(os.path.join(data_path, file_name))\n",
    "lotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "import spacy\n",
    "sys.path.append('/Users/matt.meng/dev/seq2seq_model/')\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/matt.meng'\n",
    "file_name = 'insights_article_data_title_only_20170719_20170728.json'\n",
    "meta_data_file_name = 'meta_title_data.csv'\n",
    "output_pickle_file = 'new_processed_titles_data.pkl'\n",
    "delimiter = '\\t\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def convert_text_JSON_to_csv(data_path, csv_path, delimiter='\\t'):\n",
    "    start_time = time.time()\n",
    "    batch_size = 2000\n",
    "    raw_content = \"\"\n",
    "    expected_keys = ['title', 'url', 'traffic', 'publisherId']\n",
    "    with open(data_path, 'r') as raw_input:\n",
    "        with open(csv_path, 'w') as raw_output:\n",
    "            counter = 0\n",
    "            raw_output.write(delimiter.join(expected_keys) + \"\\n\")\n",
    "            for line in raw_input:\n",
    "                json_doc = json.loads(line)\n",
    "                if not all([key in json_doc.keys() for key in expected_keys]):\n",
    "                    continue\n",
    "                elem_list = [json_doc['title'], json_doc['url'], json_doc['traffic'], json_doc['publisherId']]\n",
    "                if not all([isEnglish(elem) for elem in elem_list]):\n",
    "                    continue\n",
    "                raw_content += delimiter.join(elem_list) + \"\\n\"\n",
    "                counter += 1\n",
    "                if counter % batch_size == 0:\n",
    "                    raw_output.write(raw_content)\n",
    "                    raw_content = \"\"\n",
    "                if counter % (20 * batch_size) == 0:\n",
    "                    print 'finished processing {} rows using {:.2f} seconds'.format(counter, time.time() - start_time)\n",
    "    print 'finished processing all the data using {:.2f} seconds'.format(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing 50000 rows using 9.17 seconds\n",
      "finished processing 100000 rows using 19.03 seconds\n",
      "finished processing 150000 rows using 31.11 seconds\n",
      "finished processing 200000 rows using 41.11 seconds\n",
      "finished processing 250000 rows using 51.13 seconds\n",
      "finished processing 300000 rows using 61.70 seconds\n",
      "finished processing 350000 rows using 70.90 seconds\n",
      "finished processing 400000 rows using 79.73 seconds\n",
      "finished processing 450000 rows using 90.69 seconds\n",
      "finished processing 500000 rows using 101.28 seconds\n",
      "finished processing 550000 rows using 109.95 seconds\n",
      "finished processing 600000 rows using 118.42 seconds\n",
      "finished processing 650000 rows using 126.84 seconds\n",
      "finished processing all the data using 134.92 seconds\n"
     ]
    }
   ],
   "source": [
    "convert_text_JSON_to_csv(os.path.join(data_path, file_name), os.path.join(data_path, meta_data_file_name), delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matt.meng/.virtualenvs/kaggle/lib/python2.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, meta_data_file_name), index_col='url', delimiter=delimiter, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695007, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>traffic</th>\n",
       "      <th>publisherId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://pix11.com/2017/07/17/iconic-lower-east-side-cup-and-saucer-diner-closes-its-doors-for-food-after-rent-nearly-doubles/</th>\n",
       "      <td>Iconic Lower East Side Cup and Saucer diner cl...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1002700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.cbsnews.com/news/ulysha-renee-hall-first-female-chief-dallas-police-department/?ftag=COS-05-10aaa0h&amp;utm_campaign=trueAnthem: Trending Content&amp;utm_content=5970682c00bd470007264f17&amp;utm_medium=trueAnthem&amp;utm_source=facebook</th>\n",
       "      <td>Ulysha Hall makes history as Dallas Police Dep...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1038583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.abante-tonite.com/student-lumaklak-ng-asido.htm</th>\n",
       "      <td>UP STUDENT LUMAKLAK NG ASIDO! - Abante Tonite</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1062055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.jsonline.com/story/news/2017/06/17/paul-nehlen-challenge-paul-ryan-after-losing-68-points-last-year/405597001/</th>\n",
       "      <td>Paul Nehlen to challenge Paul Ryan after losin...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1053378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.msn.com/en-us/lifestyle/family-relationships/what-is-it-like-to-be-in-an-open-marriage-1-woman-shares-her-story/ar-BBC6STn</th>\n",
       "      <td>What Is It Like to Be in an Open Marriage? 1 W...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1023406.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                title  \\\n",
       "url                                                                                                     \n",
       "http://pix11.com/2017/07/17/iconic-lower-east-s...  Iconic Lower East Side Cup and Saucer diner cl...   \n",
       "http://www.cbsnews.com/news/ulysha-renee-hall-f...  Ulysha Hall makes history as Dallas Police Dep...   \n",
       "http://www.abante-tonite.com/student-lumaklak-n...      UP STUDENT LUMAKLAK NG ASIDO! - Abante Tonite   \n",
       "http://www.jsonline.com/story/news/2017/06/17/p...  Paul Nehlen to challenge Paul Ryan after losin...   \n",
       "http://www.msn.com/en-us/lifestyle/family-relat...  What Is It Like to Be in an Open Marriage? 1 W...   \n",
       "\n",
       "                                                    traffic  publisherId  \n",
       "url                                                                       \n",
       "http://pix11.com/2017/07/17/iconic-lower-east-s...    240.0    1002700.0  \n",
       "http://www.cbsnews.com/news/ulysha-renee-hall-f...    116.0    1038583.0  \n",
       "http://www.abante-tonite.com/student-lumaklak-n...    384.0    1062055.0  \n",
       "http://www.jsonline.com/story/news/2017/06/17/p...    352.0    1053378.0  \n",
       "http://www.msn.com/en-us/lifestyle/family-relat...    219.0    1023406.0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          Finding PlayerUnknown, the my\n",
       "traffic                                 3895\n",
       "publisherId                      1.03858e+06\n",
       "Name: https://www.cnet.com/news/pubg-playerunknown-brendan-greene-interview-july-2017/, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.cnet.com/news/pubg-playerunknown-brendan-greene-interview-july-2017/'\n",
    "data.loc[url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128154, 3)\n"
     ]
    }
   ],
   "source": [
    "data.dropna(how='any', inplace=True)\n",
    "data['publisherId'] = data['publisherId'].astype(int).astype(str)\n",
    "valid_publisher_ids = ['1001082', '1023406', '1003264', '1040522', '782', '1006541',\n",
    "                        '1168', '1038583', '1021516', '580', '1020689', '1031851', '1001264',\n",
    "                        '1039208', '1054980', '1018671', '1031841', '1031842', '1031852',\n",
    "                        '1008941', '1003764', '1068057', '1038711', '1002628', '1031853',\n",
    "                        '1021578', '1043813', '1010748', '1040526', '1005092', '612',\n",
    "                        '1003870', '1001156', '1012083', '1017946', '1041479', '1027016',\n",
    "                        '1010488', '1017947', '1010497', '1038582', '1045821', '1020968',\n",
    "                        '1037842', '1029984', '723', '196', '1030941', '1038154']\n",
    "\n",
    "filtered_data = data.loc[data['publisherId'].isin(valid_publisher_ids), :]\n",
    "unique_filtered_data = filtered_data[~filtered_data.index.duplicated(keep='first')]\n",
    "print unique_filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128154, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>traffic</th>\n",
       "      <th>publisherId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://www.cbsnews.com/news/ulysha-renee-hall-first-female-chief-dallas-police-department/?ftag=COS-05-10aaa0h&amp;utm_campaign=trueAnthem: Trending Content&amp;utm_content=5970682c00bd470007264f17&amp;utm_medium=trueAnthem&amp;utm_source=facebook</th>\n",
       "      <td>Ulysha Hall makes history as Dallas Police Dep...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1038583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.msn.com/en-us/lifestyle/family-relationships/what-is-it-like-to-be-in-an-open-marriage-1-woman-shares-her-story/ar-BBC6STn</th>\n",
       "      <td>What Is It Like to Be in an Open Marriage? 1 W...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1023406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.msn.com/en-us/foodanddrink/recipes/add-excitement-to-your-scrambled-eggs-with-one-clever-ingredient/ar-AAos3oX</th>\n",
       "      <td>Add Excitement to Your Scrambled Eggs with One...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1068057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.msn.com/en-us/movies/celebrity/valerians-dane-dehaan-says-his-love-for-new-baby-led-to-his-car-being-stolen/ar-AAot0bP</th>\n",
       "      <td>Valerian's Dane DeHaan Says His Love for New B...</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1023406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.ajc.com/news/health-med-fit-science/will-low-calorie-sugar-substitutes-artificial-sweeteners-actually-help-you-lose-weight/RsYQtTQo8BIE5HFbswtOTI/</th>\n",
       "      <td>Will low-calorie sugar substitutes, artificial...</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1041479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                title  \\\n",
       "url                                                                                                     \n",
       "http://www.cbsnews.com/news/ulysha-renee-hall-f...  Ulysha Hall makes history as Dallas Police Dep...   \n",
       "http://www.msn.com/en-us/lifestyle/family-relat...  What Is It Like to Be in an Open Marriage? 1 W...   \n",
       "https://www.msn.com/en-us/foodanddrink/recipes/...  Add Excitement to Your Scrambled Eggs with One...   \n",
       "http://www.msn.com/en-us/movies/celebrity/valer...  Valerian's Dane DeHaan Says His Love for New B...   \n",
       "http://www.ajc.com/news/health-med-fit-science/...  Will low-calorie sugar substitutes, artificial...   \n",
       "\n",
       "                                                    traffic publisherId  \n",
       "url                                                                      \n",
       "http://www.cbsnews.com/news/ulysha-renee-hall-f...    116.0     1038583  \n",
       "http://www.msn.com/en-us/lifestyle/family-relat...    219.0     1023406  \n",
       "https://www.msn.com/en-us/foodanddrink/recipes/...    114.0     1068057  \n",
       "http://www.msn.com/en-us/movies/celebrity/valer...    113.0     1023406  \n",
       "http://www.ajc.com/news/health-med-fit-science/...    384.0     1041479  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print unique_filtered_data.shape\n",
    "unique_filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the content:  Tulane's goal in Year 2 under Willie Fritz: 'We want to get in a bowl game'\n",
      "-------------\n",
      "Tulane ORG\n",
      "Year 2 DATE\n",
      "Willie Fritz PERSON\n",
      "-------------\n",
      "Tulane PROPN NNP tulane False\n",
      "'s PART POS 's False\n",
      "goal NOUN NN goal False\n",
      "in ADP IN in True\n",
      "Year PROPN NNP year False\n",
      "2 NUM CD 2 False\n",
      "under ADP IN under True\n",
      "Willie PROPN NNP willie False\n",
      "Fritz PROPN NNP fritz False\n",
      ": PUNCT : : False\n",
      "' PUNCT `` ' False\n",
      "We PRON PRP -PRON- True\n",
      "want VERB VBP want False\n",
      "to PART TO to True\n",
      "get VERB VB get True\n",
      "in ADP IN in True\n",
      "a DET DT a True\n",
      "bowl NOUN NN bowl False\n",
      "game NOUN NN game False\n",
      "' PUNCT '' ' False\n"
     ]
    }
   ],
   "source": [
    "index = 40\n",
    "title_content = data['title'][index].decode('ascii')\n",
    "doc1 = nlp(title_content)\n",
    "print 'the content: ', title_content\n",
    "print '-------------'\n",
    "for ent in doc1.ents:\n",
    "    print ent, ent.label_\n",
    "print '-------------'\n",
    "for token in doc1:\n",
    "    print token, token.pos_, token.tag_, token.lemma_, token.is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### customize the processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def basic_tokenizer(line, normalize_digits=True):\n",
    "    line = line.replace(\"'s\", '')\n",
    "    line = re.sub(r\"\\'ve\", \" have \", line)\n",
    "    line = re.sub(r\"can't\", \"can not \", line)\n",
    "    line = re.sub(r\"n't\", \" not \", line)\n",
    "    line = re.sub(r\"I'm\", \"I am\", line)\n",
    "    line = re.sub(r\" m \", \" am \", line)\n",
    "    line = re.sub(r\"\\'re\", \" are \", line)\n",
    "    line = re.sub(r\"\\'d\", \" would \", line)\n",
    "    line = re.sub(r\"\\'ll\", \" will \", line)\n",
    "    line = re.sub(r\"-\", \" ? \", line)\n",
    "    #line = re.sub(r\"!\", \" ! \", line)\n",
    "    #line = re.sub(r\":\", \" : \", line)\n",
    "#,:\\.-,\n",
    "    line = re.sub('[\\.,;\\?\"#%\\'()*+/;<=>@\\[\\]^_{|}~\\\\\\]', ' ', line)\n",
    "    line = re.sub('[\\n\\t ]+', ' ', line)\n",
    "    words = []\n",
    "    _DIGIT_RE = re.compile(r\"\\d\")\n",
    "    for token in line.strip().lower().split():\n",
    "        if not token:\n",
    "            continue\n",
    "        if normalize_digits:\n",
    "            token = re.sub(_DIGIT_RE, b'#', token)\n",
    "        words.append(token)\n",
    "    return len(words), ' '.join(words)\n",
    "\n",
    "\n",
    "def tokenize_title_column(data, processed_column_name, pageView_column_name='pageView', title_column_name='title'):\n",
    "    data['title_word_counts'], data[processed_column_name] = zip(*data[title_column_name].map(basic_tokenizer))\n",
    "    # sort by the title word counts and filter them\n",
    "    sorted_data = data.sort_values(by=['title_word_counts', pageView_column_name], ascending=[True, False])\n",
    "    index = (sorted_data['title_word_counts'] >= 5) & (sorted_data['title_word_counts'] <= 15)\n",
    "    filtered_data = sorted_data.loc[index, :]\n",
    "    print 'finish the tokenization...'\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "_PAD = b\"_PAD\"\n",
    "_GO = b\"_GO\"\n",
    "_EOS = b\"_EOS\"\n",
    "_UNK = b\"_UNK\"\n",
    "_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n",
    "\n",
    "TOKEN_DICT = {}\n",
    "REVERSE_TOKEN_DICT = {}\n",
    "for i in xrange(len(_START_VOCAB)):\n",
    "    TOKEN_DICT[_START_VOCAB[i]] = i\n",
    "    REVERSE_TOKEN_DICT[i] = _START_VOCAB[i]\n",
    "\n",
    "\n",
    "def create_vocab_dict(data, column_name, pageView_column_name='pageView', token_freq_threshold=5, UKN_frac_threshold=0.3):\n",
    "    vocab_dict = {}\n",
    "    all_titles = []\n",
    "    selected_titles = []\n",
    "    selected_title_urls = []\n",
    "    selected_title_pageView = []\n",
    "\n",
    "    for title, url, pageView in zip(data[column_name], data.index, data[pageView_column_name]):\n",
    "        words = []\n",
    "        for token in title.split(' '):\n",
    "            words.append(token)\n",
    "            if token not in vocab_dict:\n",
    "                vocab_dict[token] = 0\n",
    "            vocab_dict[token] += 1\n",
    "        all_titles.append((words, url, pageView))\n",
    "    print 'total {} tokens are identified...'.format(len(vocab_dict))\n",
    "\n",
    "    token_dict, reverse_token_dict = TOKEN_DICT.copy(), REVERSE_TOKEN_DICT.copy()\n",
    "    UKN_index = len(token_dict) - 1\n",
    "    unique_counts = 0\n",
    "    sorted_pairs = sorted(vocab_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, pair in enumerate(sorted_pairs):\n",
    "        if pair[1] >= token_freq_threshold:\n",
    "            unique_counts += 1\n",
    "            token_dict[pair[0]] = i + 1 + UKN_index\n",
    "            reverse_token_dict[(i + 1 + UKN_index)] = pair[0]\n",
    "        else:\n",
    "            token_dict[pair[0]] = UKN_index\n",
    "    print 'total {} unique tokens are included in the token dictionary...'.format(unique_counts)\n",
    "\n",
    "    for i in xrange(len(all_titles)):\n",
    "        indexed_title = map(token_dict.get, all_titles[i][0])\n",
    "        UKN_count = sum([elem == UKN_index for elem in indexed_title])\n",
    "        if (1. * UKN_count / len(indexed_title)) < UKN_frac_threshold:\n",
    "            selected_titles.append(indexed_title)\n",
    "            selected_title_urls.append(all_titles[i][1])\n",
    "            selected_title_pageView.append(all_titles[i][2])\n",
    "\n",
    "    print 'total {} titles are included...'.format(len(selected_titles))\n",
    "    return token_dict, reverse_token_dict, selected_titles, selected_title_urls, selected_title_pageView\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 'those pointless upper middle class entitlements')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'those pointless upper-middle-class entitlements'\n",
    "basic_tokenizer(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish the tokenization...\n"
     ]
    }
   ],
   "source": [
    "processed_column_name = 'processed_title'\n",
    "pageView_column_name = 'traffic'\n",
    "filtered_data = tokenize_title_column(unique_filtered_data, processed_column_name, pageView_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119077, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>traffic</th>\n",
       "      <th>publisherId</th>\n",
       "      <th>title_word_counts</th>\n",
       "      <th>processed_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>http://www.msn.com/en-us/news/breakingnews/live-coverage-from-cbs-news/ar-BBmYvYY</th>\n",
       "      <td>Live Coverage from CBS News</td>\n",
       "      <td>348010.0</td>\n",
       "      <td>1023406</td>\n",
       "      <td>5</td>\n",
       "      <td>live coverage from cbs news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.politico.com/story/2017/07/28/how-mccain-upended-obamacare-repeal-241070</th>\n",
       "      <td>How McCain upended Obamacare repeal</td>\n",
       "      <td>187020.0</td>\n",
       "      <td>612</td>\n",
       "      <td>5</td>\n",
       "      <td>how mccain upended obamacare repeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.huffingtonpost.com/katie-hurley/theres-nothing-selfish-about-suicide_b_5672519.html</th>\n",
       "      <td>There's Nothing Selfish About Suicide</td>\n",
       "      <td>104351.0</td>\n",
       "      <td>1040522</td>\n",
       "      <td>5</td>\n",
       "      <td>there nothing selfish about suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.nbcnews.com/politics/white-house/can-president-pardon-himself-n785181</th>\n",
       "      <td>Can the president pardon himself?</td>\n",
       "      <td>95782.0</td>\n",
       "      <td>1010748</td>\n",
       "      <td>5</td>\n",
       "      <td>can the president pardon himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://www.huffingtonpost.com/entry/why-im-a-racist_us_57893b9ee4b0e7c873500382</th>\n",
       "      <td>Why I'm A Racist</td>\n",
       "      <td>81273.0</td>\n",
       "      <td>1040522</td>\n",
       "      <td>5</td>\n",
       "      <td>why i am a racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    title  \\\n",
       "url                                                                                         \n",
       "http://www.msn.com/en-us/news/breakingnews/live...            Live Coverage from CBS News   \n",
       "http://www.politico.com/story/2017/07/28/how-mc...    How McCain upended Obamacare repeal   \n",
       "http://www.huffingtonpost.com/katie-hurley/ther...  There's Nothing Selfish About Suicide   \n",
       "http://www.nbcnews.com/politics/white-house/can...      Can the president pardon himself?   \n",
       "http://www.huffingtonpost.com/entry/why-im-a-ra...                       Why I'm A Racist   \n",
       "\n",
       "                                                     traffic publisherId  \\\n",
       "url                                                                        \n",
       "http://www.msn.com/en-us/news/breakingnews/live...  348010.0     1023406   \n",
       "http://www.politico.com/story/2017/07/28/how-mc...  187020.0         612   \n",
       "http://www.huffingtonpost.com/katie-hurley/ther...  104351.0     1040522   \n",
       "http://www.nbcnews.com/politics/white-house/can...   95782.0     1010748   \n",
       "http://www.huffingtonpost.com/entry/why-im-a-ra...   81273.0     1040522   \n",
       "\n",
       "                                                    title_word_counts  \\\n",
       "url                                                                     \n",
       "http://www.msn.com/en-us/news/breakingnews/live...                  5   \n",
       "http://www.politico.com/story/2017/07/28/how-mc...                  5   \n",
       "http://www.huffingtonpost.com/katie-hurley/ther...                  5   \n",
       "http://www.nbcnews.com/politics/white-house/can...                  5   \n",
       "http://www.huffingtonpost.com/entry/why-im-a-ra...                  5   \n",
       "\n",
       "                                                                        processed_title  \n",
       "url                                                                                      \n",
       "http://www.msn.com/en-us/news/breakingnews/live...          live coverage from cbs news  \n",
       "http://www.politico.com/story/2017/07/28/how-mc...  how mccain upended obamacare repeal  \n",
       "http://www.huffingtonpost.com/katie-hurley/ther...  there nothing selfish about suicide  \n",
       "http://www.nbcnews.com/politics/white-house/can...     can the president pardon himself  \n",
       "http://www.huffingtonpost.com/entry/why-im-a-ra...                    why i am a racist  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print filtered_data.shape\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#titles = filtered_data['processed_title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(['msn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_vocab_dictionary(data, title_column_name, pageView_column_name):\n",
    "    '''function to create the vocabulary dictionary and collect\n",
    "    the titles according to the selection rules (include only the nourns.)\n",
    "    '''\n",
    "    all_titles, vocab_dict = [], {}\n",
    "    count, start_time = 0, time.time()\n",
    "    for title, url, pageView in zip(data[title_column_name], data.index, data[pageView_column_name]):\n",
    "        words = []\n",
    "        title_content = title.decode('ascii')\n",
    "        doc = nlp(title_content)\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print 'finish {} using {:.2f} seconds'.format(count, time.time() - start_time)\n",
    "        if count == 50000:\n",
    "            break\n",
    "        for token in doc:\n",
    "            word = token.lemma_.encode('ascii')\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            if (token.pos_ == u'NOUN' or token.pos_ == u'PROPN') and not token.is_stop:\n",
    "                if word not in words:\n",
    "                    # the title is restricted to contain only only entities\n",
    "                    # and exlude the duplicate words\n",
    "                    words.append(word) \n",
    "                if word not in vocab_dict:\n",
    "                    vocab_dict[word] = 0\n",
    "                vocab_dict[word] += 1\n",
    "        all_titles.append((words, url, pageView))\n",
    "    print 'total {} tokens are identified...'.format(len(vocab_dict))\n",
    "    return all_titles, vocab_dict\n",
    "\n",
    "_PAD = b\"_PAD\"\n",
    "_GO = b\"_GO\"\n",
    "_EOS = b\"_EOS\"\n",
    "_UNK = b\"_UNK\"\n",
    "_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n",
    "\n",
    "TOKEN_DICT = {}\n",
    "REVERSE_TOKEN_DICT = {}\n",
    "for i in xrange(len(_START_VOCAB)):\n",
    "    TOKEN_DICT[_START_VOCAB[i]] = i\n",
    "    REVERSE_TOKEN_DICT[i] = _START_VOCAB[i]\n",
    "    \n",
    "def create_selected_vocab_dict(vocab_dict, UKN_index, token_freq_threshold):\n",
    "    token_dict, reverse_token_dict = TOKEN_DICT.copy(), REVERSE_TOKEN_DICT.copy()\n",
    "    unique_counts = 0\n",
    "    sorted_pairs = sorted(vocab_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, pair in enumerate(sorted_pairs):\n",
    "        if pair[1] >= token_freq_threshold:\n",
    "            unique_counts += 1\n",
    "            token_dict[pair[0]] = i + 1 + UKN_index\n",
    "            reverse_token_dict[(i + 1 + UKN_index)] = pair[0]\n",
    "        else:\n",
    "            token_dict[pair[0]] = UKN_index\n",
    "    print 'total {} unique tokens are included in the token dictionary...'.format(unique_counts)\n",
    "    return token_dict, reverse_token_dict\n",
    "\n",
    "\n",
    "def process_title_with_token_dict(all_titles, token_dict, UKN_index, UKN_frac_threshold):\n",
    "    selected_titles = []\n",
    "    selected_title_urls = []\n",
    "    selected_title_pageView = []\n",
    "    for i in xrange(len(all_titles)):\n",
    "        indexed_title = map(token_dict.get, all_titles[i][0])\n",
    "        if len(indexed_title) == 0:\n",
    "            continue\n",
    "        UKN_count = sum([elem == UKN_index for elem in indexed_title])\n",
    "        if (1. * UKN_count / len(indexed_title)) < UKN_frac_threshold:\n",
    "            selected_titles.append(indexed_title)\n",
    "            selected_title_urls.append(all_titles[i][1])\n",
    "            selected_title_pageView.append(all_titles[i][2])\n",
    "\n",
    "    print 'total {} titles are included...'.format(len(selected_titles))\n",
    "    #return token_dict, reverse_token_dict, selected_titles, selected_title_urls, selected_title_pageView\n",
    "    return {'url': selected_title_urls,\n",
    "            'titles': selected_titles,\n",
    "            'pageViw': selected_title_pageView,\n",
    "            'token_dict': token_dict,\n",
    "            'reverse_token_dict': reverse_token_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UKN_index = len(TOKEN_DICT) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish 10000 using 4.19 seconds\n",
      "finish 20000 using 8.73 seconds\n",
      "finish 30000 using 13.66 seconds\n",
      "finish 40000 using 18.54 seconds\n",
      "finish 50000 using 23.75 seconds\n",
      "total 14637 tokens are identified...\n"
     ]
    }
   ],
   "source": [
    "all_titles, vocab_dict = create_vocab_dictionary(filtered_data, 'processed_title', 'traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the topK entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('#', 15293)\n",
      "('trump', 2596)\n",
      "('man', 1632)\n",
      "('woman', 1285)\n",
      "('police', 1250)\n",
      "('year', 826)\n",
      "('horoscope', 762)\n",
      "('death', 656)\n",
      "('health', 646)\n",
      "('house', 630)\n",
      "('report', 585)\n",
      "('home', 569)\n",
      "('city', 528)\n",
      "('state', 516)\n",
      "('thing', 509)\n",
      "('video', 504)\n",
      "('photo', 495)\n",
      "('crash', 479)\n",
      "('world', 475)\n",
      "('bill', 464)\n"
     ]
    }
   ],
   "source": [
    "sorted_pairs = sorted(vocab_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in xrange(20):\n",
    "    print sorted_pairs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creat the token dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6331 unique tokens are included in the token dictionary...\n"
     ]
    }
   ],
   "source": [
    "token_dict, reverse_token_dict = create_selected_vocab_dict(vocab_dict, UKN_index, token_freq_threshold=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creat the content dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44915 titles are included...\n"
     ]
    }
   ],
   "source": [
    "content = process_title_with_token_dict(all_titles, token_dict, UKN_index, UKN_frac_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url', 'reverse_token_dict', 'pageViw', 'titles', 'token_dict']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_token_dict = content['reverse_token_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.usatoday.com/videos/sports/mlb/2017/07/19/2017-mlb-trade-deadline-tracker/103821462/\n",
      "['#', 'mlb', 'trade', 'deadline', 'tracker']\n",
      "http://dailymail.co.uk/news/article-4720086\n",
      "['chris', '_UNK', 'concert', 'promoter']\n",
      "http://www.cnbc.com/video/3000639134\n",
      "['alphabet', 'beat', 'line']\n",
      "https://www.usatoday.com/videos/sports/2017/07/23/jordan-spieth-wins-british-open/103940834/\n",
      "['jordan', 'british']\n",
      "https://www.bloomberg.com/news/articles/2017-07-20/how-to-fix-social-security\n",
      "['security']\n",
      "http://myfox8.com/2017/07/27/alamance-county-kidnapping-victim-located/\n",
      "['alamance', 'county', 'victim']\n",
      "http://www.msn.com/en-us/sports/nba/mcgee-reportedly-unhappy-with-warriors/ar-BBEuKmF\n",
      "['mcgee', 'warrior']\n",
      "http://www.msn.com/g00/en-us/news/video/live-news-coverage-from-cbs-news/ar-BBmYvYY\n",
      "['coverage', 'news']\n",
      "http://www.msnbc.com/morning-joe/watch/inside-jeff-sessions-unending-nightmare-1011158595755\n",
      "['jeff', 'session', 'nightmare']\n",
      "http://www.msn.com/en-us/travel/article/little-ross?a-tiny-island-in-scotland-with-a-murderous-history?can-be-yours-for-dollar425000/ar-AAorung\n",
      "['travel']\n",
      "http://www.politico.com/story/2017/07/23/liberal-scientists-trump-climate-change-240852\n",
      "['lab', 'coat', 'liberal']\n",
      "http://www.chicagotribune.com/news/opinion/huppke/ct-trump-sessions-ohio-boy-scout-huppke-20170726-story,amp.html\n",
      "['donald', 'trump', 'behavior']\n",
      "https://a.msn.com/r/2/AAoSqjT?m=en-us\n",
      "['opinion', 'trump', 'transgender', 'patriot']\n",
      "http://www.freep.com/story/life/2016/07/19/braless-millenials-bralette/87111292/?utm_source=usatn&utm_medium=front&utm_campaign=usatn-pv-evergreen\n",
      "['millennial']\n",
      "http://www.cnbc.com/2017/07/25/adobe-is-killing-flash.html\n",
      "['adobe', 'flash']\n",
      "http://www.msn.com/en-us/news/us/secret-service?s-alabama-bet-it-looks-a-lot-like-middle-school/ar-AAovmo9\n",
      "['service', 'news']\n",
      "http://www.wsbtv.com/news/local/clayton-county/gas-leak-forces-neighborhood-evacuation/564785998\n",
      "['gas', 'leak', 'force', 'neighborhood', 'evacuation']\n",
      "http://www.chicagotribune.com/news/opinion/commentary/ct-michael-madigan-destroy-illinois-perspec-20170724-story.html\n",
      "['mike', 'madigan']\n",
      "http://www.huffingtonpost.com/entry/what-is-a-hate-group_us_596b8009e4b022bb9372b284\n",
      "['hate', 'group']\n",
      "https://www.usatoday.com/videos/news/politics/2017/07/24/kushner-releases-russia-meeting/103947446/\n",
      "['kushner', 'release', 'russia', 'meeting']\n"
     ]
    }
   ],
   "source": [
    "for index in xrange(50 ,70):\n",
    "    print content['url'][index]\n",
    "    print map(reverse_token_dict.get, content['titles'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visually check the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_titles[50:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alloway'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict.keys()[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['#', '#', 'spectacular', 'pool', 'fail'],\n",
       " 'http://a.msn.com/09/en-us/BBDVavm',\n",
       " 8505.0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['siri', 'trick', '#'], 'https://www.usatoday.com/story/tech/talkingtech/2017/07/21/silly-siri-tricks-part-7/500360001/', 31026.0)\n",
      "[2855, 406, 4]\n"
     ]
    }
   ],
   "source": [
    "print all_titles[index]\n",
    "print map(token_dict.get, all_titles[index][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(counter.values(), bins=100)\n",
    "#plt.yscale('log')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,20])\n",
    "#axes.set_ylim([ymin,ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = {'url': selected_title_urls,\n",
    "               'titles': titles,\n",
    "               'pageViw': selected_title_pageView,\n",
    "               'token_dict': token_dict,\n",
    "               'reverse_token_dict': reverse_token_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/matt.meng/Downloads'\n",
    "file_name = 'small_articles.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bad_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = 'processed_title_data.pkl'\n",
    "\n",
    "content = {'url' : selected_title_urls, \n",
    "           'titles' : titles, \n",
    "           'pageViw' : selected_title_pageView,\n",
    "           'token_dict' : token_dict,\n",
    "           'reverse_token_dict' : reverse_token_dict}\n",
    "\n",
    "with open(pickle_file, 'wb') as handle:\n",
    "    cPickle.dump(content, handle, protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
