{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "import os, sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "sys.path.append('/home/ymm/kaggle/xgboost_hyperopt')\n",
    "import utils.bosch_functions as bosch_functions\n",
    "\n",
    "data_path = '/home/ymm/bosch/'\n",
    "\n",
    "train_num_file   = 'train_numeric.csv'\n",
    "train_cat_file   = 'train_categorical.csv'\n",
    "train_date_file  = 'train_date.csv'\n",
    "test_num_file    = 'test_numeric.csv'\n",
    "test_cat_file    = 'test_categorical.csv'\n",
    "test_date_file   = 'test_date.csv'\n",
    "\n",
    "sample_submission_file   = 'sample_submission.csv'\n",
    "\n",
    "\n",
    "start_time_column_name = 'L0_S0_D1'\n",
    "id_column_name = 'Id'\n",
    "dep_var_name = 'Response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading takes  73.6  seconds.\n"
     ]
    }
   ],
   "source": [
    "bin_num = 1 ## number of bins to separate data by start_time\n",
    "tmp_train, tmp_test, bins, bin_names = bosch_functions.create_grouped_index_df(bin_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## create the skipped row numbers\n",
    "\n",
    "## select 19 features based on the LR model trained with NaN data, a threshold of 0.25 \n",
    "## is used to select 19 features as listed below\n",
    "LR_selected_features = ['L3_S38_F3952', 'L0_S23_F619',  'L1_S25_F1855', 'L1_S25_F2799',\n",
    "                        'L3_S29_F3379', 'L1_S24_F1808', 'L1_S24_F679',  'L1_S25_F2498',\n",
    "                        'L1_S24_F1118', 'L3_S49_F4206', 'L0_S22_F546',  'L3_S31_F3834',\n",
    "                        'L3_S29_F3464', 'L3_S50_F4243', 'L2_S28_F3222', 'L1_S25_F2231',\n",
    "                        'L1_S24_F1581', 'L1_S24_F1672', 'L3_S32_F3850']\n",
    "\n",
    "none_selected_window_num = ['0']\n",
    "skipped_test_row_num = tmp_test.loc[tmp_test['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\n",
    "skipped_train_row_num = tmp_train.loc[tmp_train['time_window_num'].isin(none_selected_window_num), 'row_num'].tolist()\n",
    "\n",
    "train_cat_cols  = pd.read_csv(join(data_path, train_cat_file), index_col=id_column_name, nrows=0)\n",
    "train_date_cols = pd.read_csv(join(data_path, train_date_file), index_col=id_column_name, nrows=0)\n",
    "train_num_cols  = pd.read_csv(join(data_path, train_num_file), index_col=id_column_name, nrows=0)\n",
    "\n",
    "bin_nan_data_path = '/home/ymm/kaggle/bosch/data_2_bins_xgb_combined_models/data_bin_NaN_models'\n",
    "\n",
    "def collect_feature_names(data_path, fea_name='feature', thres_name = None, thres = 10):\n",
    "    csv_files = [f for f in os.listdir(data_path) if '.csv' in f]\n",
    "    feature_names = set()\n",
    "    for file_name in csv_files:\n",
    "        data = pd.read_csv(join(data_path, file_name), index_col=0)\n",
    "        if thres_name is None:\n",
    "            feature_names = feature_names.union(data[fea_name])\n",
    "        else:\n",
    "            feature_names = feature_names.union(data.loc[data[thres_name] > thres, fea_name])\n",
    "    return feature_names\n",
    "\n",
    "## collect feature names based on the fscore\n",
    "bin_nan_selected_col_name = collect_feature_names(bin_nan_data_path, 'feature', 'fscore', 10)\n",
    "\n",
    "## based on the selected features from xgboost to create column list\n",
    "selected_num_col_names =  train_num_cols.columns[train_num_cols.columns.isin(bin_nan_selected_col_name)].tolist()\n",
    "\n",
    "## add LR important features into the NUMERICAL column set\n",
    "for feature_name in LR_selected_features:\n",
    "    if feature_name not in selected_num_col_names:\n",
    "        selected_num_col_names.append(feature_name)\n",
    "\n",
    "selected_cat_col_names =  train_cat_cols.columns[train_cat_cols.columns.isin(bin_nan_selected_col_name)].tolist()\n",
    "selected_dat_col_names =  train_date_cols.columns[train_date_cols.columns.isin(bin_nan_selected_col_name)].tolist()\n",
    "test_num_col_names     =  selected_num_col_names[:]\n",
    "        \n",
    "selected_cat_col_names.extend([id_column_name])\n",
    "selected_num_col_names.extend([id_column_name, dep_var_name])\n",
    "test_num_col_names.extend([id_column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 560 0 15\n"
     ]
    }
   ],
   "source": [
    "print len(test_num_col_names), len(selected_num_col_names), len(selected_dat_col_names), len(selected_cat_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading data by columns selected using xgboost feature importance, using 117.32 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_cat  = pd.read_csv(join(data_path, train_cat_file),   index_col='Id', skiprows=skipped_train_row_num, usecols=selected_cat_col_names)\n",
    "test_cat   = pd.read_csv(join(data_path, test_cat_file),    index_col='Id', skiprows=skipped_test_row_num,  usecols=selected_cat_col_names)\n",
    "train_num  = pd.read_csv(join(data_path, train_num_file),   index_col='Id', skiprows=skipped_train_row_num, usecols=selected_num_col_names)\n",
    "test_num   = pd.read_csv(join(data_path, test_num_file),    index_col='Id', skiprows=skipped_test_row_num,  usecols=test_num_col_names)\n",
    "\n",
    "print 'finish reading data by columns selected using xgboost feature importance, using {} seconds.'.format(round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 14) (509886, 559)\n"
     ]
    }
   ],
   "source": [
    "print train_cat.shape, train_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509245, 14) (509245, 558)\n"
     ]
    }
   ],
   "source": [
    "print test_cat.shape, test_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_num_train = train_num.copy()\n",
    "tmp_num_test = test_num.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 559) (509245, 558)\n",
      "(509886, 559) (509245, 558)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S8_F144</th>\n",
       "      <th>L0_S12_F330</th>\n",
       "      <th>L0_S12_F332</th>\n",
       "      <th>L0_S12_F334</th>\n",
       "      <th>L0_S12_F336</th>\n",
       "      <th>L0_S12_F338</th>\n",
       "      <th>L0_S12_F340</th>\n",
       "      <th>L0_S12_F342</th>\n",
       "      <th>L0_S12_F344</th>\n",
       "      <th>L0_S12_F346</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S47_F4138</th>\n",
       "      <th>L3_S47_F4143</th>\n",
       "      <th>L3_S47_F4153</th>\n",
       "      <th>L3_S47_F4158</th>\n",
       "      <th>L3_S47_F4163</th>\n",
       "      <th>L3_S48_F4196</th>\n",
       "      <th>L3_S48_F4198</th>\n",
       "      <th>L3_S49_F4206</th>\n",
       "      <th>L3_S50_F4243</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.223</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S8_F144  L0_S12_F330  L0_S12_F332  L0_S12_F334  L0_S12_F336  \\\n",
       "Id                                                                   \n",
       "6          NaN        0.096        0.076       -0.065       -0.136   \n",
       "14         NaN       -0.051       -0.082       -0.181       -0.481   \n",
       "16         NaN          NaN          NaN          NaN          NaN   \n",
       "23         NaN       -0.008       -0.003       -0.065       -0.136   \n",
       "41         NaN        0.041        0.062        0.081        0.140   \n",
       "\n",
       "    L0_S12_F338  L0_S12_F340  L0_S12_F342  L0_S12_F344  L0_S12_F346    ...     \\\n",
       "Id                                                                     ...      \n",
       "6         0.169        0.231       -0.014       -0.072       -0.039    ...      \n",
       "14        0.113        0.154       -0.010       -0.072       -0.054    ...      \n",
       "16          NaN          NaN          NaN          NaN          NaN    ...      \n",
       "23       -0.053       -0.154       -0.006       -0.041       -0.049    ...      \n",
       "41        0.002        0.000        0.002       -0.010        0.223    ...      \n",
       "\n",
       "    L3_S47_F4138  L3_S47_F4143  L3_S47_F4153  L3_S47_F4158  L3_S47_F4163  \\\n",
       "Id                                                                         \n",
       "6            NaN           NaN           NaN           NaN           NaN   \n",
       "14           NaN           NaN           NaN           NaN           NaN   \n",
       "16           NaN           NaN           NaN           NaN           NaN   \n",
       "23           NaN           NaN           NaN           NaN           NaN   \n",
       "41           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "    L3_S48_F4196  L3_S48_F4198  L3_S49_F4206  L3_S50_F4243  Response  \n",
       "Id                                                                    \n",
       "6            NaN           NaN           NaN           NaN         0  \n",
       "14           NaN           NaN           NaN           NaN         0  \n",
       "16           NaN           NaN           NaN           NaN         0  \n",
       "23           NaN           NaN           NaN           NaN         0  \n",
       "41           NaN           NaN           NaN           NaN         0  \n",
       "\n",
       "[5 rows x 559 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_num.shape, test_num.shape\n",
    "print tmp_num_train.shape, tmp_num_test.shape\n",
    "tmp_num_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering on the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_columns_feature_engineering(df, col_ignore = ['Response']):\n",
    "    #tmp_df = df.loc[:, df.columns != 'start_time']\n",
    "    tmp_df = df.loc[:, ~df.columns.isin(col_ignore)]\n",
    "    new_fea_df = pd.DataFrame()\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    new_fea_df['num_sum'] = tmp_df.sum(axis=1)\n",
    "    new_fea_df['num_max'] = tmp_df.max(axis=1)\n",
    "    new_fea_df['num_min'] = tmp_df.min(axis=1)\n",
    "    new_fea_df['mun_max_min_ratio'] = new_fea_df['num_max'] / new_fea_df['num_min']\n",
    "    new_fea_df['num_nan_col_count'] = tmp_df.isnull().sum(axis=1)\n",
    "    new_fea_df['num_reg_col_count'] = tmp_df.shape[1] - tmp_df.isnull().sum(axis=1)\n",
    "    new_fea_df['idxmax'] = tmp_df.idxmax(axis=1)\n",
    "    new_fea_df['idxmax'] = encoder.fit_transform(new_fea_df['idxmax'])\n",
    "    new_fea_df['idxmin'] = tmp_df.idxmin(axis=1)\n",
    "    new_fea_df['idxmin'] = encoder.fit_transform(new_fea_df['idxmin'])\n",
    "    #new_fea_df = pd.merge(new_fea_df, pd.get_dummies(idmax, prefix='oneHot'), how='left', left_index=True, right_index=True)\n",
    "    return new_fea_df\n",
    "\n",
    "\n",
    "## generic function to encode categorical features\n",
    "def sweep_up_categorical_encode_by_dep_var(df, fea_name, test_df = None, dep_var_name='Response', count_thres = 10, nan_fill = -1., const_scale = 1.):\n",
    "    tmp_df = df[[fea_name, dep_var_name]]\n",
    "    tmp_df = tmp_df.fillna(nan_fill)\n",
    "    value_counts = tmp_df[fea_name].value_counts()\n",
    "    minor_keys = []\n",
    "    key_dep_var_map = {}\n",
    "    \n",
    "    ## training sweep-up\n",
    "    for counts, key in zip(value_counts.values, value_counts.index):\n",
    "        if counts > count_thres:\n",
    "            mean_dep_var = const_scale * tmp_df.loc[tmp_df[fea_name] == key, dep_var_name].mean()\n",
    "            key_dep_var_map[key] = mean_dep_var\n",
    "        else:\n",
    "            minor_keys.append(key)\n",
    "            \n",
    "    ## mean value of dep_var for all the minor levels\n",
    "    if len(minor_keys) > 0:\n",
    "        minor_key_dep_var_mean = const_scale * tmp_df.loc[tmp_df[fea_name].isin(minor_keys), dep_var_name].mean()\n",
    "        ## update the key_dep_var_map with minor key\n",
    "        for key in minor_keys:\n",
    "            key_dep_var_map[key] = minor_key_dep_var_mean\n",
    "    \n",
    "    encoded_train = tmp_df[fea_name].replace(key_dep_var_map)\n",
    "    overall_mean_dep_var = tmp_df[dep_var_name].mean()\n",
    "    \n",
    "    ## sweep up the test column\n",
    "    if test_df is not None:\n",
    "        test_value_counts = test_df[fea_name].value_counts()\n",
    "        test_minor_keys = []\n",
    "        test_key_dep_var_map = key_dep_var_map.copy()\n",
    "    \n",
    "        for counts, key in zip(test_value_counts.values, test_value_counts.index):\n",
    "            if key not in test_key_dep_var_map:\n",
    "                print 'new level {} with counts {} found in test data'.format(key, counts)\n",
    "                if counts > count_thres:\n",
    "                    print 'warning! new level {} is found in test data!'.format(key)\n",
    "                else:\n",
    "                    test_minor_keys.append(key)\n",
    "        \n",
    "        if len(test_minor_keys) > 0:\n",
    "            for key in test_minor_keys:\n",
    "                test_key_dep_var_map[key] = const_scale * overall_mean_dep_var\n",
    "        \n",
    "        encoded_test = test_df[fea_name].replace(test_key_dep_var_map)\n",
    "        return encoded_train, encoded_test\n",
    "    \n",
    "    else:\n",
    "        return encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tmp_num_dep_var = tmp_num_train[dep_var_name]\n",
    "combined_num = pd.concat([tmp_num_train, tmp_num_test])\n",
    "train_num_index = tmp_num_train.index\n",
    "test_num_index  = tmp_num_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish creating new numerical features using 192.0 seconds\n"
     ]
    }
   ],
   "source": [
    "## feature engineering on the numerical features without filling NaN\n",
    "start_time = time.time()\n",
    "## not fill up NaN with fixed value so that min and max values are correct\n",
    "new_fea_combined_num = num_columns_feature_engineering(combined_num)\n",
    "print 'finish creating new numerical features using {} seconds'.format(round(time.time() - start_time, 0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_num_train = pd.merge(tmp_num_train, new_fea_combined_num.ix[train_num_index], how='left', left_index=True, right_index=True)\n",
    "tmp_num_test  = pd.merge(tmp_num_test,  new_fea_combined_num.ix[test_num_index],  how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 567) (509245, 566)\n"
     ]
    }
   ],
   "source": [
    "print tmp_num_train.shape, tmp_num_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column L0_S8_F144 has #levels 3 if in LR features: False\n",
      "column L0_S14_F358 has #levels 7 if in LR features: False\n",
      "column L0_S15_F394 has #levels 7 if in LR features: False\n",
      "column L3_S29_F3360 has #levels 5 if in LR features: False\n",
      "column L3_S29_F3464 has #levels 3 if in LR features: True\n",
      "column L3_S29_F3470 has #levels 3 if in LR features: False\n",
      "column L3_S35_F3894 has #levels 9 if in LR features: False\n",
      "column L3_S38_F3952 has #levels 9 if in LR features: True\n",
      "column L3_S49_F4206 has #levels 4 if in LR features: True\n"
     ]
    }
   ],
   "source": [
    "categorical_like_columns = []\n",
    "level_num_thres = 10\n",
    "for column in tmp_num_train.columns:\n",
    "    level_num = len(tmp_num_train[column].unique())\n",
    "    if level_num < level_num_thres:\n",
    "        if column != dep_var_name:\n",
    "            categorical_like_columns.append(column)\n",
    "            print 'column {} has #levels {} if in LR features: {}'.format(column, level_num, column in LR_selected_features)\n",
    "        #print combined_num[column].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new level -0.657 with counts 2 found in test data\n",
      "new level 0.333 with counts 1 found in test data\n",
      "new level 0.433 with counts 1 found in test data\n",
      "new level -0.188 with counts 1 found in test data\n",
      "new level -0.021 with counts 1 found in test data\n"
     ]
    }
   ],
   "source": [
    "count_thres = 50\n",
    "const_scale = 100.\n",
    "nan_fill = -2.\n",
    "for fea_name in categorical_like_columns:\n",
    "    new_fea_name = '{}_{}'.format('dep_var_encoded', fea_name)\n",
    "    tmp_num_train[new_fea_name], tmp_num_test[new_fea_name] = sweep_up_categorical_encode_by_dep_var(tmp_num_train, \n",
    "                                                                                                     fea_name, \n",
    "                                                                                                     test_df=tmp_num_test,\n",
    "                                                                                                     count_thres=count_thres,\n",
    "                                                                                                     nan_fill = nan_fill,\n",
    "                                                                                                     const_scale = const_scale)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 576) (509245, 575)\n"
     ]
    }
   ],
   "source": [
    "print tmp_num_train.shape, tmp_num_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S8_F144</th>\n",
       "      <th>L0_S12_F330</th>\n",
       "      <th>L0_S12_F332</th>\n",
       "      <th>L0_S12_F334</th>\n",
       "      <th>L0_S12_F336</th>\n",
       "      <th>L0_S12_F338</th>\n",
       "      <th>L0_S12_F340</th>\n",
       "      <th>L0_S12_F342</th>\n",
       "      <th>L0_S12_F344</th>\n",
       "      <th>L0_S12_F346</th>\n",
       "      <th>...</th>\n",
       "      <th>idxmin</th>\n",
       "      <th>dep_var_encoded_L0_S8_F144</th>\n",
       "      <th>dep_var_encoded_L0_S14_F358</th>\n",
       "      <th>dep_var_encoded_L0_S15_F394</th>\n",
       "      <th>dep_var_encoded_L3_S29_F3360</th>\n",
       "      <th>dep_var_encoded_L3_S29_F3464</th>\n",
       "      <th>dep_var_encoded_L3_S29_F3470</th>\n",
       "      <th>dep_var_encoded_L3_S35_F3894</th>\n",
       "      <th>dep_var_encoded_L3_S38_F3952</th>\n",
       "      <th>dep_var_encoded_L3_S49_F4206</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>...</td>\n",
       "      <td>309</td>\n",
       "      <td>0.642201</td>\n",
       "      <td>0.519173</td>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.629636</td>\n",
       "      <td>0.415067</td>\n",
       "      <td>0.415067</td>\n",
       "      <td>0.532753</td>\n",
       "      <td>0.637246</td>\n",
       "      <td>0.643968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.181</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.642201</td>\n",
       "      <td>0.665993</td>\n",
       "      <td>0.548182</td>\n",
       "      <td>0.653692</td>\n",
       "      <td>0.415067</td>\n",
       "      <td>0.415067</td>\n",
       "      <td>0.532753</td>\n",
       "      <td>0.637246</td>\n",
       "      <td>0.643968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>0.642201</td>\n",
       "      <td>0.665993</td>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.653692</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.830540</td>\n",
       "      <td>0.637246</td>\n",
       "      <td>0.643968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>...</td>\n",
       "      <td>305</td>\n",
       "      <td>0.642201</td>\n",
       "      <td>0.633613</td>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.629636</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.532753</td>\n",
       "      <td>0.637246</td>\n",
       "      <td>0.643968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.223</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.642201</td>\n",
       "      <td>0.519173</td>\n",
       "      <td>0.677625</td>\n",
       "      <td>0.653692</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.840757</td>\n",
       "      <td>0.645993</td>\n",
       "      <td>0.637246</td>\n",
       "      <td>0.643968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L0_S8_F144  L0_S12_F330  L0_S12_F332  L0_S12_F334  L0_S12_F336  \\\n",
       "Id                                                                   \n",
       "6          NaN        0.096        0.076       -0.065       -0.136   \n",
       "14         NaN       -0.051       -0.082       -0.181       -0.481   \n",
       "16         NaN          NaN          NaN          NaN          NaN   \n",
       "23         NaN       -0.008       -0.003       -0.065       -0.136   \n",
       "41         NaN        0.041        0.062        0.081        0.140   \n",
       "\n",
       "    L0_S12_F338  L0_S12_F340  L0_S12_F342  L0_S12_F344  L0_S12_F346  \\\n",
       "Id                                                                    \n",
       "6         0.169        0.231       -0.014       -0.072       -0.039   \n",
       "14        0.113        0.154       -0.010       -0.072       -0.054   \n",
       "16          NaN          NaN          NaN          NaN          NaN   \n",
       "23       -0.053       -0.154       -0.006       -0.041       -0.049   \n",
       "41        0.002        0.000        0.002       -0.010        0.223   \n",
       "\n",
       "                ...               idxmin  dep_var_encoded_L0_S8_F144  \\\n",
       "Id              ...                                                    \n",
       "6               ...                  309                    0.642201   \n",
       "14              ...                    4                    0.642201   \n",
       "16              ...                  143                    0.642201   \n",
       "23              ...                  305                    0.642201   \n",
       "41              ...                   27                    0.642201   \n",
       "\n",
       "    dep_var_encoded_L0_S14_F358  dep_var_encoded_L0_S15_F394  \\\n",
       "Id                                                             \n",
       "6                      0.519173                     0.677625   \n",
       "14                     0.665993                     0.548182   \n",
       "16                     0.665993                     0.677625   \n",
       "23                     0.633613                     0.677625   \n",
       "41                     0.519173                     0.677625   \n",
       "\n",
       "    dep_var_encoded_L3_S29_F3360  dep_var_encoded_L3_S29_F3464  \\\n",
       "Id                                                               \n",
       "6                       0.629636                      0.415067   \n",
       "14                      0.653692                      0.415067   \n",
       "16                      0.653692                      0.840757   \n",
       "23                      0.629636                      0.840757   \n",
       "41                      0.653692                      0.840757   \n",
       "\n",
       "    dep_var_encoded_L3_S29_F3470  dep_var_encoded_L3_S35_F3894  \\\n",
       "Id                                                               \n",
       "6                       0.415067                      0.532753   \n",
       "14                      0.415067                      0.532753   \n",
       "16                      0.840757                      0.830540   \n",
       "23                      0.840757                      0.532753   \n",
       "41                      0.840757                      0.645993   \n",
       "\n",
       "    dep_var_encoded_L3_S38_F3952  dep_var_encoded_L3_S49_F4206  \n",
       "Id                                                              \n",
       "6                       0.637246                      0.643968  \n",
       "14                      0.637246                      0.643968  \n",
       "16                      0.637246                      0.643968  \n",
       "23                      0.637246                      0.643968  \n",
       "41                      0.637246                      0.643968  \n",
       "\n",
       "[5 rows x 576 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_num_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.0 inf\n",
      "-118.5 inf\n"
     ]
    }
   ],
   "source": [
    "#print tmp_num_train.min().min(), tmp_num_train.max().max()\n",
    "#rint tmp_num_test.min().min(), tmp_num_test.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## check the value counts for every features\\nfor feature in LR_selected_features:\\n    print tmp_num_train[feature].value_counts()\\n    \\n## check the distribution\\nfea_name = LR_selected_features[10]\\ntmp_df = tmp_num_train[[fea_name, dep_var_name]]\\ntmp_df[fea_name].hist(bins=50)\\n\\n## way to quantify the continuous distribution\\nfrom scipy.stats.mstats import mquantiles\\nbin_num = 32\\nprob_list = [1.*i/bin_num for i in range(1, bin_num)]\\nquantile_values = mquantiles(tmp_df[fea_name][tmp_df[fea_name].notnull()], prob=prob_list)\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## check the value counts for every features\n",
    "for feature in LR_selected_features:\n",
    "    print tmp_num_train[feature].value_counts()\n",
    "    \n",
    "## check the distribution\n",
    "fea_name = LR_selected_features[10]\n",
    "tmp_df = tmp_num_train[[fea_name, dep_var_name]]\n",
    "tmp_df[fea_name].hist(bins=50)\n",
    "\n",
    "## way to quantify the continuous distribution\n",
    "from scipy.stats.mstats import mquantiles\n",
    "bin_num = 32\n",
    "prob_list = [1.*i/bin_num for i in range(1, bin_num)]\n",
    "quantile_values = mquantiles(tmp_df[fea_name][tmp_df[fea_name].notnull()], prob=prob_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_num_train = tmp_num_train.fillna(nan_fill)\n",
    "tmp_num_test = tmp_num_test.fillna(nan_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 576) (509245, 575) True\n"
     ]
    }
   ],
   "source": [
    "print tmp_num_train.shape, tmp_num_test.shape, dep_var_name in tmp_num_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1019131, 14)\n",
      "shape after OneHot encoding:  (1019131, 103)\n",
      "finish OneHot encoding the categorical columns, using 12.65 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_cat = pd.concat([train_cat, test_cat])\n",
    "print combined_cat.shape\n",
    "## convert to string so that column is categorical\n",
    "combined_cat = combined_cat.astype(str)\n",
    "## One-Hot encode all the categorical columns\n",
    "oneHot_combined_cat = pd.get_dummies(combined_cat, dummy_na=True)\n",
    "print 'shape after OneHot encoding: ', oneHot_combined_cat.shape\n",
    "train_index = train_cat.index\n",
    "test_index  = test_cat.index\n",
    "oneHot_train_cat = oneHot_combined_cat.ix[train_index]\n",
    "oneHot_test_cat  = oneHot_combined_cat.ix[test_index]\n",
    "print 'finish OneHot encoding the categorical columns, using {} seconds'.format(round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_S24_F675_1.0</th>\n",
       "      <th>L1_S24_F675_2.0</th>\n",
       "      <th>L1_S24_F675_3.0</th>\n",
       "      <th>L1_S24_F675_4.0</th>\n",
       "      <th>L1_S24_F675_5.0</th>\n",
       "      <th>L1_S24_F675_nan</th>\n",
       "      <th>L1_S24_F675_nan</th>\n",
       "      <th>L1_S24_F1510_1.0</th>\n",
       "      <th>L1_S24_F1510_2.0</th>\n",
       "      <th>L1_S24_F1510_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S32_F3854_36992.0</th>\n",
       "      <th>L3_S32_F3854_4.0</th>\n",
       "      <th>L3_S32_F3854_48.0</th>\n",
       "      <th>L3_S32_F3854_492.0</th>\n",
       "      <th>L3_S32_F3854_512.0</th>\n",
       "      <th>L3_S32_F3854_55424.0</th>\n",
       "      <th>L3_S32_F3854_63616.0</th>\n",
       "      <th>L3_S32_F3854_8.0</th>\n",
       "      <th>L3_S32_F3854_nan</th>\n",
       "      <th>L3_S32_F3854_nan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L1_S24_F675_1.0  L1_S24_F675_2.0  L1_S24_F675_3.0  L1_S24_F675_4.0  \\\n",
       "Id                                                                       \n",
       "6               0.0              0.0              0.0              0.0   \n",
       "14              0.0              0.0              0.0              0.0   \n",
       "16              0.0              0.0              0.0              0.0   \n",
       "23              0.0              0.0              0.0              0.0   \n",
       "41              0.0              0.0              0.0              0.0   \n",
       "\n",
       "    L1_S24_F675_5.0  L1_S24_F675_nan  L1_S24_F675_nan  L1_S24_F1510_1.0  \\\n",
       "Id                                                                        \n",
       "6               0.0              1.0              0.0               0.0   \n",
       "14              0.0              1.0              0.0               0.0   \n",
       "16              0.0              1.0              0.0               0.0   \n",
       "23              0.0              1.0              0.0               0.0   \n",
       "41              0.0              1.0              0.0               0.0   \n",
       "\n",
       "    L1_S24_F1510_2.0  L1_S24_F1510_3.0        ...         \\\n",
       "Id                                            ...          \n",
       "6                0.0               0.0        ...          \n",
       "14               0.0               0.0        ...          \n",
       "16               0.0               1.0        ...          \n",
       "23               0.0               0.0        ...          \n",
       "41               0.0               0.0        ...          \n",
       "\n",
       "    L3_S32_F3854_36992.0  L3_S32_F3854_4.0  L3_S32_F3854_48.0  \\\n",
       "Id                                                              \n",
       "6                    0.0               0.0                0.0   \n",
       "14                   0.0               0.0                0.0   \n",
       "16                   0.0               0.0                0.0   \n",
       "23                   0.0               0.0                0.0   \n",
       "41                   0.0               0.0                0.0   \n",
       "\n",
       "    L3_S32_F3854_492.0  L3_S32_F3854_512.0  L3_S32_F3854_55424.0  \\\n",
       "Id                                                                 \n",
       "6                  0.0                 0.0                   0.0   \n",
       "14                 0.0                 0.0                   0.0   \n",
       "16                 0.0                 0.0                   0.0   \n",
       "23                 0.0                 0.0                   0.0   \n",
       "41                 0.0                 0.0                   0.0   \n",
       "\n",
       "    L3_S32_F3854_63616.0  L3_S32_F3854_8.0  L3_S32_F3854_nan  L3_S32_F3854_nan  \n",
       "Id                                                                              \n",
       "6                    0.0               0.0               1.0               0.0  \n",
       "14                   0.0               0.0               1.0               0.0  \n",
       "16                   0.0               0.0               1.0               0.0  \n",
       "23                   0.0               0.0               1.0               0.0  \n",
       "41                   0.0               0.0               1.0               0.0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print oneHot_train_cat.shape\n",
    "oneHot_train_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_train = pd.concat([oneHot_train_cat, tmp_num_train], axis=1)\n",
    "combined_test  = pd.concat([oneHot_test_cat,  tmp_num_test],  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509886, 679) (509245, 678)\n"
     ]
    }
   ],
   "source": [
    "print combined_train.shape, combined_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_var_name in combined_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print combined_test.isnull().sum().sum(), '\\n \\n', combined_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    674\n",
      "int64        4\n",
      "dtype: int64 \n",
      " \n",
      "float64    674\n",
      "int64        5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print combined_test.dtypes.value_counts(), '\\n \\n',  combined_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_var_name in combined_train.columns, dep_var_name in combined_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving data using 1310.12 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "combined_train.to_csv('bosch_processed_nan_filled_FE_thres_10_train_data.csv')\n",
    "combined_test.to_csv('bosch_processed_nan_filled_FE_thres_10_test_data.csv')\n",
    "print 'saving data using {} seconds'.format(round(time.time() - start_time, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
