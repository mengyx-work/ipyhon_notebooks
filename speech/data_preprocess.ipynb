{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, math, random\n",
    "import time\n",
    "from scipy.io import wavfile\n",
    "import cPickle as pickle\n",
    "from python_speech_features import logfbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load all the wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_main_path = '/Users/matt.meng/data/speech_competition/train/audio'\n",
    "wav_files = glob.glob(os.path.join(train_main_path, \"*\", \"*.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/matt.meng/data/speech_competition/train/audio/bed/01b4757a_nohash_1.wav'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_name = re.sub(r'_nohash_.*$', '', wav_files[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/matt.meng/data/speech_competition/train/audio/bed/035de8fe_nohash_0.wav'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_name = re.search('/([^/]+)sda', wav_files[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### categorize the file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_wav_files(wav_files, expected_sample_rate=16000, expected_sample_length=16000):\n",
    "    word_dict = {}\n",
    "    for wav_file in wav_files:\n",
    "        sample_rate, samples = wavfile.read(wav_files[20])\n",
    "        word = re.search('.*/([^/]+)/.*.wav', wav_file).group(1).lower()\n",
    "        word_dict[word] = word_dict.get(word, 0) + 1\n",
    "        if sample_rate != expected_sample_rate:\n",
    "            print('for word {} at {}, the sample rate is different'.format(word, sample_rate))\n",
    "        if len(samples) != expected_sample_length:\n",
    "            print('for word {} at {}, the sample is different'.format(word, len(samples)))\n",
    "    return word_dict\n",
    "\n",
    "\n",
    "def categorize_wav_files_by_label(wav_files):\n",
    "    '''\n",
    "    categorize the wave file paths by label and hash.  `_background_noise_` does not have hash,\n",
    "    use the file name.\n",
    "    '''\n",
    "    categorized_wav_files = {}\n",
    "    categorized_sample_num = {}\n",
    "    for wav_file in wav_files:\n",
    "        label = re.search('.*/([^/]+)/.*.wav', wav_file).group(1).lower()\n",
    "        categorized_sample_num[label] = categorized_sample_num.get(label, 0) + 1\n",
    "        if label == '_background_noise_':\n",
    "            hash_name = re.search('/([^/]+).wav', wav_file).group(1).lower()\n",
    "        else:\n",
    "            hash_name = re.search('/([^/]+)_nohash', wav_file).group(1).lower()\n",
    "\n",
    "        if label not in categorized_wav_files:\n",
    "            categorized_wav_files[label] = {}\n",
    "            categorized_wav_files[label][hash_name] = [wav_file]\n",
    "        else:\n",
    "            if hash_name not in categorized_wav_files[label]:\n",
    "                categorized_wav_files[label][hash_name] = [wav_file]\n",
    "            else:\n",
    "                categorized_wav_files[label][hash_name].append(wav_file)\n",
    "    return categorized_wav_files, categorized_sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_dict_ = check_wav_files(wav_files)\n",
    "categorized_wav_files_, categorized_sample_num_ = categorize_wav_files_by_label(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sheila', 'seven', 'right', 'up', 'house', 'one', 'four', 'zero', 'go', 'yes', 'down', 'no', 'wow', 'six', 'three', 'bird', 'happy', 'marvin', 'stop', 'eight', '_background_noise_', 'on', 'off', 'tree', 'dog', 'bed', 'cat', 'nine', 'five', 'two', 'left']\n"
     ]
    }
   ],
   "source": [
    "print categorized_wav_files_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known_labels = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence']\n",
    "unknown_label = 'unknown'\n",
    "label2index, index2label = {}, {}\n",
    "for i, label in enumerate(known_labels):\n",
    "    label2index[label] = i\n",
    "    index2label[i] = label\n",
    "label2index[unknown_label] = len(known_labels)\n",
    "index2label[len(known_labels)] = unknown_label\n",
    "\n",
    "for label in categorized_wav_files_:\n",
    "    if label in known_labels or label == unknown_label:\n",
    "        continue\n",
    "    label2index[label] = label2index[unknown_label]\n",
    "    \n",
    "training_percentage = 0.7\n",
    "validate_percentage = 0.15\n",
    "test_percentage = 0.15\n",
    "\n",
    "assert (training_percentage + validate_percentage + test_percentage) == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sheila': 11, 'two': 11, 'seven': 11, 'right': 5, 'house': 11, 'one': 11, 'four': 11, 'zero': 11, 'go': 9, 'yes': 0, 'down': 3, 'no': 1, 'unknown': 11, 'wow': 11, 'six': 11, 'three': 11, 'bird': 11, 'happy': 11, 'marvin': 11, 'stop': 8, 'eight': 11, '_background_noise_': 11, 'on': 6, 'off': 7, 'dog': 11, 'tree': 11, 'up': 2, 'bed': 11, 'cat': 11, 'nine': 11, 'five': 11, 'silence': 10, 'left': 4} \n",
      "{0: 'yes', 1: 'no', 2: 'up', 3: 'down', 4: 'left', 5: 'right', 6: 'on', 7: 'off', 8: 'stop', 9: 'go', 10: 'silence', 11: 'unknown'}\n"
     ]
    }
   ],
   "source": [
    "print label2index, '\\n', index2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_background_noise_': 6,\n",
       " 'bed': 1713,\n",
       " 'bird': 1731,\n",
       " 'cat': 1733,\n",
       " 'dog': 1746,\n",
       " 'down': 2359,\n",
       " 'eight': 2352,\n",
       " 'five': 2357,\n",
       " 'four': 2372,\n",
       " 'go': 2372,\n",
       " 'happy': 1742,\n",
       " 'house': 1750,\n",
       " 'left': 2353,\n",
       " 'marvin': 1746,\n",
       " 'nine': 2364,\n",
       " 'no': 2375,\n",
       " 'off': 2357,\n",
       " 'on': 2367,\n",
       " 'one': 2370,\n",
       " 'right': 2367,\n",
       " 'seven': 2377,\n",
       " 'sheila': 1734,\n",
       " 'six': 2369,\n",
       " 'stop': 2380,\n",
       " 'three': 2356,\n",
       " 'tree': 1733,\n",
       " 'two': 2373,\n",
       " 'up': 2375,\n",
       " 'wow': 1745,\n",
       " 'yes': 2377,\n",
       " 'zero': 2376}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorized_sample_num_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data into sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_proportional_data_sets(categorized_wav_files, categorized_sample_num, training_percentage=0.7, test_percentage=0.15, validate_percentage=0.15):\n",
    "    excluded_category = ['_background_noise_']\n",
    "    total_file_num = sum([categorized_sample_num[key] for key in categorized_sample_num if key not in excluded_category])\n",
    "    training_samples, test_samples, validate_samles = [], [], []\n",
    "    for category in categorized_wav_files.keys(): \n",
    "        if category in excluded_category:\n",
    "            continue\n",
    "        tot_training_samples = math.ceil(training_percentage * categorized_sample_num[category])\n",
    "        tot_validate_samples = math.ceil(validate_percentage * categorized_sample_num[category])\n",
    "        count = 0\n",
    "        for hash_name in categorized_wav_files[category]:\n",
    "            if count < tot_training_samples:\n",
    "                for wave_file in categorized_wav_files[category][hash_name]:\n",
    "                    training_samples.append((wave_file, label2index[category]))\n",
    "                    count += 1\n",
    "            elif count < (tot_training_samples + tot_validate_samples):\n",
    "                for wave_file in categorized_wav_files[category][hash_name]:\n",
    "                    validate_samles.append((wave_file, label2index[category]))\n",
    "                    count += 1\n",
    "            else:\n",
    "                for wave_file in categorized_wav_files[category][hash_name]:\n",
    "                    test_samples.append((wave_file, label2index[category]))\n",
    "                    count += 1\n",
    "    return training_samples, test_samples, validate_samles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples_, test_samples_, validate_samles_ = generate_proportional_data_sets(categorized_wav_files_, categorized_sample_num_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45331 9659 9731\n"
     ]
    }
   ],
   "source": [
    "print len(training_samples_), len(test_samples_), len(validate_samles_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007454187804120509"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. * (9659 - 9731) / 9659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_chunks(wav_files, chunk_size=2000, prefix='training', data_path='/Users/matt.meng/data/speech_competition/processed_data'):\n",
    "    random.shuffle(wav_files)\n",
    "    chunk_num = math.ceil(1. * len(wav_files) / chunk_size)\n",
    "    chunk_data, chunk_counter, sample_counter = [], 0, 0\n",
    "    start_time = time.time()\n",
    "    chunk_start_time = start_time\n",
    "    def dump_chunk_data(chunk_data_, chunk_counter, chunk_start_time):\n",
    "        with open(os.path.join(data_path, 'speech_{}_{}.pkl'.format(prefix, chunk_counter)), 'wb') as f:\n",
    "            pickle.dump(chunk_data_, f)\n",
    "        print('finish processing {} raw audio waveforms using {:.2f} seconds'.format(i, (time.time()-chunk_start_time)))\n",
    "    \n",
    "    for i in range(len(wav_files)):\n",
    "        if sample_counter >= chunk_size:\n",
    "            dump_chunk_data(chunk_data, chunk_counter, chunk_start_time)\n",
    "            chunk_data, sample_counter, chunk_start_time = [], 0, time.time()\n",
    "            chunk_counter += 1\n",
    "        sample_rate, samples = wavfile.read(wav_files[i][0])\n",
    "        fbank_features = logfbank(samples, sample_rate)\n",
    "        chunk_data.append((fbank_features, wav_files[i][1]))\n",
    "        sample_counter += 1\n",
    "    if len(chunk_data) > 0:\n",
    "        dump_chunk_data(chunk_data, chunk_counter, chunk_start_time)\n",
    "\n",
    "    print('processed all {} wav_files using {:.2f} seconds'.format(len(wav_files), (time.time()-start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing 2000 raw audio waveforms using 7.30 seconds\n",
      "finish processing 4000 raw audio waveforms using 7.07 seconds\n",
      "finish processing 6000 raw audio waveforms using 7.01 seconds\n",
      "finish processing 8000 raw audio waveforms using 7.17 seconds\n",
      "finish processing 10000 raw audio waveforms using 7.04 seconds\n",
      "finish processing 12000 raw audio waveforms using 6.96 seconds\n",
      "finish processing 14000 raw audio waveforms using 7.04 seconds\n",
      "finish processing 16000 raw audio waveforms using 7.12 seconds\n",
      "finish processing 18000 raw audio waveforms using 7.01 seconds\n",
      "finish processing 20000 raw audio waveforms using 6.97 seconds\n",
      "finish processing 22000 raw audio waveforms using 6.97 seconds\n",
      "finish processing 24000 raw audio waveforms using 7.15 seconds\n",
      "finish processing 26000 raw audio waveforms using 7.08 seconds\n",
      "finish processing 28000 raw audio waveforms using 7.17 seconds\n",
      "finish processing 30000 raw audio waveforms using 7.09 seconds\n",
      "finish processing 32000 raw audio waveforms using 7.14 seconds\n",
      "finish processing 34000 raw audio waveforms using 7.22 seconds\n",
      "finish processing 36000 raw audio waveforms using 7.11 seconds\n",
      "finish processing 38000 raw audio waveforms using 7.15 seconds\n",
      "finish processing 40000 raw audio waveforms using 7.43 seconds\n",
      "finish processing 42000 raw audio waveforms using 7.56 seconds\n",
      "finish processing 44000 raw audio waveforms using 7.43 seconds\n",
      "finish processing 45330 raw audio waveforms using 5.03 seconds\n",
      "processed all 45331 wav_files using 162.23 seconds\n"
     ]
    }
   ],
   "source": [
    "split_data_into_chunks(training_samples_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
